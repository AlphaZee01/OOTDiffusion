[1mdiff --git a/CHANGELOG.md b/CHANGELOG.md[m
[1mnew file mode 100644[m
[1mindex 0000000..1bcedc9[m
[1m--- /dev/null[m
[1m+++ b/CHANGELOG.md[m
[36m@@ -0,0 +1,359 @@[m
[32m+[m[32m# Changelog[m
[32m+[m
[32m+[m[32mAll notable changes to the OOTDiffusion project will be documented in this file.[m
[32m+[m
[32m+[m[32mThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),[m
[32m+[m[32mand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).[m
[32m+[m
[32m+[m[32m## [1.0.0] - 2024-12-19[m
[32m+[m
[32m+[m[32m### 🚀 Production Readiness Release[m
[32m+[m
[32m+[m[32mThis major release transforms OOTDiffusion from a research prototype into a production-ready application with enterprise-grade features.[m
[32m+[m
[32m+[m[32m### Added[m
[32m+[m
[32m+[m[32m#### Configuration Management[m
[32m+[m[32m- **Centralized Configuration System** (`config.py`)[m
[32m+[m[32m  - Environment-specific configurations (development, testing, production)[m
[32m+[m[32m  - Model path management and validation[m
[32m+[m[32m  - Server settings with security parameters[m
[32m+[m[32m  - Processing parameters with validation[m
[32m+[m[32m  - Logging configuration with structured output[m
[32m+[m[32m  - Automatic directory creation and validation[m
[32m+[m
[32m+[m[32m#### Error Handling & Logging[m
[32m+[m[32m- **Comprehensive Error Handling** (`utils/error_handling.py`)[m
[32m+[m[32m  - Custom exception hierarchy (OOTDError, ModelLoadError, ProcessingError, ValidationError, ResourceError)[m
[32m+[m[32m  - Structured logging with context information[m
[32m+[m[32m  - Error tracking and analysis system[m
[32m+[m[32m  - Performance monitoring decorators[m
[32m+[m[32m  - Safe execution utilities[m
[32m+[m[32m  - Automatic cleanup mechanisms[m
[32m+[m
[32m+[m[32m#### Input Validation & Security[m
[32m+[m[32m- **Robust Input Validation** (`utils/validation.py`)[m
[32m+[m[32m  - File type and size validation[m
[32m+[m[32m  - Image dimension and quality checks[m
[32m+[m[32m  - MIME type verification using python-magic[m
[32m+[m[32m  - Parameter validation with detailed error messages[m
[32m+[m[32m  - Filename sanitization for security[m
[32m+[m[32m  - Temporary file management[m
[32m+[m
[32m+[m[32m#### Production API[m
[32m+[m[32m- **FastAPI-based REST API** (`api/app.py`)[m
[32m+[m[32m  - RESTful endpoints for image processing[m
[32m+[m[32m  - File upload handling with validation[m
[32m+[m[32m  - Background task processing[m
[32m+[m[32m  - Health check endpoints[m
[32m+[m[32m  - CORS middleware for cross-origin requests[m
[32m+[m[32m  - GZIP compression for responses[m
[32m+[m[32m  - Static file serving for results[m
[32m+[m[32m  - Comprehensive error responses[m
[32m+[m
[32m+[m[32m#### Containerization[m
[32m+[m[32m- **Docker Support**[m
[32m+[m[32m  - Multi-stage Dockerfile for optimized builds[m
[32m+[m[32m  - Development and production targets[m
[32m+[m[32m  - NVIDIA GPU support[m
[32m+[m[32m  - Health checks and proper signal handling[m
[32m+[m[32m  - Non-root user for security[m
[32m+[m[32m  - Optimized layer caching[m
[32m+[m
[32m+[m[32m#### Docker Compose[m
[32m+[m[32m- **Orchestration** (`docker-compose.yml`)[m
[32m+[m[32m  - Production and development profiles[m
[32m+[m[32m  - Redis caching support[m
[32m+[m[32m  - Nginx reverse proxy configuration[m
[32m+[m[32m  - Volume management for persistent data[m
[32m+[m[32m  - Environment variable configuration[m
[32m+[m[32m  - Service dependencies and health checks[m
[32m+[m
[32m+[m[32m#### Deployment Scripts[m
[32m+[m[32m- **Automated Setup** (`scripts/`)[m
[32m+[m[32m  - Cross-platform setup scripts (Linux/macOS and Windows)[m
[32m+[m[32m  - Environment configuration generation[m
[32m+[m[32m  - Model checkpoint validation[m
[32m+[m[32m  - Service monitoring scripts[m
[32m+[m[32m  - Backup and update automation[m
[32m+[m[32m  - Nginx configuration generation[m
[32m+[m
[32m+[m[32m#### Testing Framework[m
[32m+[m[32m- **Comprehensive Test Suite** (`tests/`)[m
[32m+[m[32m  - API endpoint testing[m
[32m+[m[32m  - Image processing validation[m
[32m+[m[32m  - Error handling verification[m
[32m+[m[32m  - Input validation testing[m
[32m+[m[32m  - Performance testing utilities[m
[32m+[m[32m  - Mock and fixture support[m
[32m+[m
[32m+[m[32m#### Documentation[m
[32m+[m[32m- **Production Documentation**[m
[32m+[m[32m  - Setup and deployment guides[m
[32m+[m[32m  - API documentation with examples[m
[32m+[m[32m  - Configuration reference[m
[32m+[m[32m  - Troubleshooting guides[m
[32m+[m[32m  - Security best practices[m
[32m+[m
[32m+[m[32m### Changed[m
[32m+[m
[32m+[m[32m#### Architecture Improvements[m
[32m+[m[32m- **Modular Design**[m
[32m+[m[32m  - Separated concerns into dedicated modules[m
[32m+[m[32m  - Dependency injection for better testability[m
[32m+[m[32m  - Configuration-driven behavior[m
[32m+[m[32m  - Environment-specific optimizations[m
[32m+[m
[32m+[m[32m#### Performance Enhancements[m
[32m+[m[32m- **Optimized Processing**[m
[32m+[m[32m  - Model caching and reuse[m
[32m+[m[32m  - Memory-efficient image processing[m
[32m+[m[32m  - Background task processing[m
[32m+[m[32m  - Resource cleanup automation[m
[32m+[m[32m  - GPU memory management[m
[32m+[m
[32m+[m[32m#### Security Hardening[m
[32m+[m[32m- **Enhanced Security**[m
[32m+[m[32m  - Input sanitization and validation[m
[32m+[m[32m  - File type verification[m
[32m+[m[32m  - Size limits and rate limiting[m
[32m+[m[32m  - Security headers[m
[32m+[m[32m  - Non-root container execution[m
[32m+[m[32m  - Temporary file cleanup[m
[32m+[m
[32m+[m[32m### Technical Details[m
[32m+[m
[32m+[m[32m#### New Dependencies[m
[32m+[m[32m- **Production Dependencies** (`requirements-prod.txt`)[m
[32m+[m[32m  - FastAPI for REST API[m
[32m+[m[32m  - Uvicorn for ASGI server[m
[32m+[m[32m  - Pydantic for data validation[m
[32m+[m[32m  - Python-magic for file type detection[m
[32m+[m[32m  - Structlog for structured logging[m
[32m+[m[32m  - Prometheus client for monitoring[m
[32m+[m[32m  - Redis for caching[m
[32m+[m[32m  - SQLAlchemy for database support[m
[32m+[m
[32m+[m[32m#### Development Dependencies** (`requirements-dev.txt`)[m
[32m+[m[32m  - Pytest for testing[m
[32m+[m[32m  - Black for code formatting[m
[32m+[m[32m  - Flake8 for linting[m
[32m+[m[32m  - MyPy for type checking[m
[32m+[m[32m  - Pre-commit hooks[m
[32m+[m[32m  - Jupyter for development[m
[32m+[m[32m  - Performance profiling tools[m
[32m+[m
[32m+[m[32m#### Configuration Files[m
[32m+[m[32m- **Environment Configuration** (`.env`)[m
[32m+[m[32m  - Database connections[m
[32m+[m[32m  - API keys and secrets[m
[32m+[m[32m  - Logging levels[m
[32m+[m[32m  - File upload limits[m
[32m+[m[32m  - Security settings[m
[32m+[m
[32m+[m[32m#### Docker Configuration[m
[32m+[m[32m- **Container Setup**[m
[32m+[m[32m  - Multi-stage builds for optimization[m
[32m+[m[32m  - CUDA support for GPU acceleration[m
[32m+[m[32m  - Health checks and monitoring[m
[32m+[m[32m  - Security hardening[m
[32m+[m[32m  - Volume management[m
[32m+[m
[32m+[m[32m### Migration Guide[m
[32m+[m
[32m+[m[32m#### For Existing Users[m
[32m+[m[32m1. **Backup Current Setup**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   cp -r your_current_ootd your_backup[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m2. **Update Dependencies**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   pip install -r requirements-prod.txt[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m3. **Run Setup Script**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   # Linux/macOS[m
[32m+[m[32m   ./scripts/setup.sh[m
[32m+[m[41m   [m
[32m+[m[32m   # Windows[m
[32m+[m[32m   scripts\setup.bat[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m4. **Configure Environment**[m
[32m+[m[32m   - Update `.env` file with your settings[m
[32m+[m[32m   - Download model checkpoints to `checkpoints/` directory[m
[32m+[m
[32m+[m[32m5. **Deploy with Docker**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   docker-compose up -d[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m#### API Changes[m
[32m+[m[32m- **New Endpoints**[m
[32m+[m[32m  - `GET /` - API information[m
[32m+[m[32m  - `GET /health` - Health check[m
[32m+[m[32m  - `POST /process` - Image processing[m
[32m+[m[32m  - `GET /results/{filename}` - Download results[m
[32m+[m
[32m+[m[32m- **Request Format**[m
[32m+[m[32m  ```json[m
[32m+[m[32m  {[m
[32m+[m[32m    "model_type": "hd",[m
[32m+[m[32m    "category": 0,[m
[32m+[m[32m    "samples": 1,[m
[32m+[m[32m    "steps": 20,[m
[32m+[m[32m    "scale": 2.0,[m
[32m+[m[32m    "seed": -1[m
[32m+[m[32m  }[m
[32m+[m[32m  ```[m
[32m+[m
[32m+[m[32m- **Response Format**[m
[32m+[m[32m  ```json[m
[32m+[m[32m  {[m
[32m+[m[32m    "success": true,[m
[32m+[m[32m    "message": "Images processed successfully",[m
[32m+[m[32m    "result_paths": ["/static/results/result_20241219_143022_0.png"],[m
[32m+[m[32m    "processing_time": 15.2[m
[32m+[m[32m  }[m
[32m+[m[32m  ```[m
[32m+[m
[32m+[m[32m### Breaking Changes[m
[32m+[m
[32m+[m[32m#### Configuration[m
[32m+[m[32m- **Environment Variables**[m
[32m+[m[32m  - New required environment variables[m
[32m+[m[32m  - Changed default values for some settings[m
[32m+[m[32m  - Removed hardcoded paths[m
[32m+[m
[32m+[m[32m#### API Interface[m
[32m+[m[32m- **Request Format**[m
[32m+[m[32m  - Changed from Gradio interface to REST API[m
[32m+[m[32m  - New parameter validation[m
[32m+[m[32m  - Different error response format[m
[32m+[m
[32m+[m[32m#### File Structure[m
[32m+[m[32m- **New Directories**[m
[32m+[m[32m  - `api/` - API implementation[m
[32m+[m[32m  - `utils/` - Utility modules[m
[32m+[m[32m  - `tests/` - Test suite[m
[32m+[m[32m  - `scripts/` - Deployment scripts[m
[32m+[m[32m  - `outputs/` - Generated results[m
[32m+[m[32m  - `temp/` - Temporary files[m
[32m+[m
[32m+[m[32m### Security Considerations[m
[32m+[m
[32m+[m[32m#### Input Validation[m
[32m+[m[32m- File type verification using MIME type detection[m
[32m+[m[32m- File size limits to prevent DoS attacks[m
[32m+[m[32m- Image dimension validation[m
[32m+[m[32m- Parameter range checking[m
[32m+[m
[32m+[m[32m#### Container Security[m
[32m+[m[32m- Non-root user execution[m
[32m+[m[32m- Minimal base images[m
[32m+[m[32m- Security headers[m
[32m+[m[32m- Resource limits[m
[32m+[m
[32m+[m[32m#### API Security[m
[32m+[m[32m- Rate limiting[m
[32m+[m[32m- CORS configuration[m
[32m+[m[32m- Input sanitization[m
[32m+[m[32m- Error message sanitization[m
[32m+[m
[32m+[m[32m### Performance Improvements[m
[32m+[m
[32m+[m[32m#### Model Loading[m
[32m+[m[32m- Lazy loading of models[m
[32m+[m[32m- Model caching and reuse[m
[32m+[m[32m- Memory-efficient processing[m
[32m+[m[32m- GPU memory management[m
[32m+[m
[32m+[m[32m#### Processing[m
[32m+[m[32m- Background task processing[m
[32m+[m[32m- Async file handling[m
[32m+[m[32m- Optimized image processing[m
[32m+[m[32m- Resource cleanup[m
[32m+[m
[32m+[m[32m#### Monitoring[m
[32m+[m[32m- Health check endpoints[m
[32m+[m[32m- Performance metrics[m
[32m+[m[32m- Error tracking[m
[32m+[m[32m- Resource monitoring[m
[32m+[m
[32m+[m[32m### Known Issues[m
[32m+[m
[32m+[m[32m#### Model Dependencies[m
[32m+[m[32m- Requires specific model checkpoints[m
[32m+[m[32m- GPU memory requirements[m
[32m+[m[32m- CUDA version compatibility[m
[32m+[m
[32m+[m[32m#### Platform Support[m
[32m+[m[32m- Primarily tested on Linux[m
[32m+[m[32m- Windows support via Docker[m
[32m+[m[32m- macOS support via Docker[m
[32m+[m
[32m+[m[32m### Future Roadmap[m
[32m+[m
[32m+[m[32m#### Planned Features[m
[32m+[m[32m- [ ] Kubernetes deployment support[m
[32m+[m[32m- [ ] Horizontal scaling[m
[32m+[m[32m- [ ] Database integration[m
[32m+[m[32m- [ ] User authentication[m
[32m+[m[32m- [ ] Batch processing API[m
[32m+[m[32m- [ ] Model versioning[m
[32m+[m[32m- [ ] A/B testing support[m
[32m+[m[32m- [ ] Metrics dashboard[m
[32m+[m
[32m+[m[32m#### Performance Optimizations[m
[32m+[m[32m- [ ] Model quantization[m
[32m+[m[32m- [ ] TensorRT optimization[m
[32m+[m[32m- [ ] ONNX model support[m
[32m+[m[32m- [ ] Caching improvements[m
[32m+[m[32m- [ ] Load balancing[m
[32m+[m
[32m+[m[32m### Contributors[m
[32m+[m
[32m+[m[32m- **Production Readiness Team**[m
[32m+[m[32m  - Configuration management[m
[32m+[m[32m  - Error handling and logging[m
[32m+[m[32m  - API development[m
[32m+[m[32m  - Containerization[m
[32m+[m[32m  - Testing framework[m
[32m+[m[32m  - Documentation[m
[32m+[m
[32m+[m[32m### Acknowledgments[m
[32m+[m
[32m+[m[32m- Original OOTDiffusion authors for the research implementation[m
[32m+[m[32m- FastAPI team for the excellent web framework[m
[32m+[m[32m- Docker team for containerization support[m
[32m+[m[32m- Open source community for various dependencies[m
[32m+[m
[32m+[m[32m---[m
[32m+[m
[32m+[m[32m## [0.1.0] - 2024-03-17[m
[32m+[m
[32m+[m[32m### Initial Release[m
[32m+[m
[32m+[m[32m- Original OOTDiffusion implementation[m
[32m+[m[32m- Gradio-based demo interface[m
[32m+[m[32m- Half-body and full-body model support[m
[32m+[m[32m- Basic inference pipeline[m
[32m+[m[32m- Research-grade implementation[m
[32m+[m
[32m+[m[32m### Features[m
[32m+[m[32m- Virtual try-on using diffusion models[m
[32m+[m[32m- Support for upper-body, lower-body, and dress categories[m
[32m+[m[32m- OpenPose and human parsing integration[m
[32m+[m[32m- Gradio web interface[m
[32m+[m[32m- Example images and workflows[m
[32m+[m
[32m+[m[32m### Limitations[m
[32m+[m[32m- Research prototype only[m
[32m+[m[32m- No production considerations[m
[32m+[m[32m- Limited error handling[m
[32m+[m[32m- No input validation[m
[32m+[m[32m- Manual setup required[m
[32m+[m[32m- No containerization[m
[32m+[m[32m- No monitoring or logging[m
[1mdiff --git a/DEPLOYMENT.md b/DEPLOYMENT.md[m
[1mnew file mode 100644[m
[1mindex 0000000..9c4c3f9[m
[1m--- /dev/null[m
[1m+++ b/DEPLOYMENT.md[m
[36m@@ -0,0 +1,639 @@[m
[32m+[m[32m# OOTDiffusion Production Deployment Guide[m
[32m+[m
[32m+[m[32mThis guide covers deploying OOTDiffusion in various production environments.[m
[32m+[m
[32m+[m[32m## 🏗️ Architecture Overview[m
[32m+[m
[32m+[m[32m```[m
[32m+[m[32m┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐[m
[32m+[m[32m│   Load Balancer │────│   Nginx Proxy   │────│   FastAPI App   │[m
[32m+[m[32m│   (Optional)    │    │   (Optional)    │    │   (Container)   │[m
[32m+[m[32m└─────────────────┘    └─────────────────┘    └─────────────────┘[m
[32m+[m[32m                                                       │[m
[32m+[m[32m                       ┌─────────────────┐            │[m
[32m+[m[32m                       │   Redis Cache   │────────────┘[m
[32m+[m[32m                       │   (Optional)    │[m
[32m+[m[32m                       └─────────────────┘[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m## 🚀 Quick Deployment[m
[32m+[m
[32m+[m[32m### Single Server Deployment[m
[32m+[m
[32m+[m[32m1. **Prerequisites**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   # Install Docker and Docker Compose[m
[32m+[m[32m   curl -fsSL https://get.docker.com -o get-docker.sh[m
[32m+[m[32m   sh get-docker.sh[m
[32m+[m[32m   sudo usermod -aG docker $USER[m
[32m+[m[41m   [m
[32m+[m[32m   # Install Docker Compose[m
[32m+[m[32m   sudo curl -L "https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose[m
[32m+[m[32m   sudo chmod +x /usr/local/bin/docker-compose[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m2. **Deploy Application**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   # Clone repository[m
[32m+[m[32m   git clone https://github.com/levihsu/OOTDiffusion.git[m
[32m+[m[32m   cd OOTDiffusion[m
[32m+[m[41m   [m
[32m+[m[32m   # Run setup[m
[32m+[m[32m   chmod +x scripts/setup.sh[m
[32m+[m[32m   ./scripts/setup.sh[m
[32m+[m[41m   [m
[32m+[m[32m   # Download models (see model setup section)[m
[32m+[m[41m   [m
[32m+[m[32m   # Start services[m
[32m+[m[32m   docker-compose up -d[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m3. **Verify Deployment**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   # Check health[m
[32m+[m[32m   curl http://localhost:7865/health[m
[32m+[m[41m   [m
[32m+[m[32m   # Check logs[m
[32m+[m[32m   docker-compose logs -f ootd-api[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m### Multi-Server Deployment[m
[32m+[m
[32m+[m[32m1. **Load Balancer Setup (Nginx)**[m
[32m+[m[32m   ```nginx[m
[32m+[m[32m   upstream ootd_backend {[m
[32m+[m[32m       server ootd-server-1:7865;[m
[32m+[m[32m       server ootd-server-2:7865;[m
[32m+[m[32m       server ootd-server-3:7865;[m
[32m+[m[32m   }[m
[32m+[m[41m   [m
[32m+[m[32m   server {[m
[32m+[m[32m       listen 80;[m
[32m+[m[32m       location / {[m
[32m+[m[32m           proxy_pass http://ootd_backend;[m
[32m+[m[32m           proxy_set_header Host $host;[m
[32m+[m[32m           proxy_set_header X-Real-IP $remote_addr;[m
[32m+[m[32m       }[m
[32m+[m[32m   }[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m2. **Deploy on Each Server**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   # On each server[m
[32m+[m[32m   git clone https://github.com/levihsu/OOTDiffusion.git[m
[32m+[m[32m   cd OOTDiffusion[m
[32m+[m[32m   ./scripts/setup.sh[m
[32m+[m[32m   docker-compose up -d[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m## ☁️ Cloud Deployment[m
[32m+[m
[32m+[m[32m### AWS Deployment[m
[32m+[m
[32m+[m[32m#### Using ECS (Elastic Container Service)[m
[32m+[m
[32m+[m[32m1. **Create ECS Cluster**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   aws ecs create-cluster --cluster-name ootd-cluster[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m2. **Create Task Definition**[m
[32m+[m[32m   ```json[m
[32m+[m[32m   {[m
[32m+[m[32m     "family": "ootd-task",[m
[32m+[m[32m     "networkMode": "awsvpc",[m
[32m+[m[32m     "requiresCompatibilities": ["FARGATE"],[m
[32m+[m[32m     "cpu": "2048",[m
[32m+[m[32m     "memory": "8192",[m
[32m+[m[32m     "executionRoleArn": "arn:aws:iam::account:role/ecsTaskExecutionRole",[m
[32m+[m[32m     "containerDefinitions": [[m
[32m+[m[32m       {[m
[32m+[m[32m         "name": "ootd-api",[m
[32m+[m[32m         "image": "your-account.dkr.ecr.region.amazonaws.com/ootd:latest",[m
[32m+[m[32m         "portMappings": [[m
[32m+[m[32m           {[m
[32m+[m[32m             "containerPort": 7865,[m
[32m+[m[32m             "protocol": "tcp"[m
[32m+[m[32m           }[m
[32m+[m[32m         ],[m
[32m+[m[32m         "environment": [[m
[32m+[m[32m           {[m
[32m+[m[32m             "name": "OOTD_ENVIRONMENT",[m
[32m+[m[32m             "value": "production"[m
[32m+[m[32m           }[m
[32m+[m[32m         ],[m
[32m+[m[32m         "logConfiguration": {[m
[32m+[m[32m           "logDriver": "awslogs",[m
[32m+[m[32m           "options": {[m
[32m+[m[32m             "awslogs-group": "/ecs/ootd",[m
[32m+[m[32m             "awslogs-region": "us-west-2",[m
[32m+[m[32m             "awslogs-stream-prefix": "ecs"[m
[32m+[m[32m           }[m
[32m+[m[32m         }[m
[32m+[m[32m       }[m
[32m+[m[32m     ][m
[32m+[m[32m   }[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m3. **Create Service**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   aws ecs create-service \[m
[32m+[m[32m     --cluster ootd-cluster \[m
[32m+[m[32m     --service-name ootd-service \[m
[32m+[m[32m     --task-definition ootd-task \[m
[32m+[m[32m     --desired-count 2 \[m
[32m+[m[32m     --launch-type FARGATE \[m
[32m+[m[32m     --network-configuration "awsvpcConfiguration={subnets=[subnet-12345],securityGroups=[sg-12345],assignPublicIp=ENABLED}"[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m#### Using EKS (Elastic Kubernetes Service)[m
[32m+[m
[32m+[m[32m1. **Create Kubernetes Deployment**[m
[32m+[m[32m   ```yaml[m
[32m+[m[32m   apiVersion: apps/v1[m
[32m+[m[32m   kind: Deployment[m
[32m+[m[32m   metadata:[m
[32m+[m[32m     name: ootd-api[m
[32m+[m[32m   spec:[m
[32m+[m[32m     replicas: 3[m
[32m+[m[32m     selector:[m
[32m+[m[32m       matchLabels:[m
[32m+[m[32m         app: ootd-api[m
[32m+[m[32m     template:[m
[32m+[m[32m       metadata:[m
[32m+[m[32m         labels:[m
[32m+[m[32m           app: ootd-api[m
[32m+[m[32m       spec:[m
[32m+[m[32m         containers:[m
[32m+[m[32m         - name: ootd-api[m
[32m+[m[32m           image: your-account.dkr.ecr.region.amazonaws.com/ootd:latest[m
[32m+[m[32m           ports:[m
[32m+[m[32m           - containerPort: 7865[m
[32m+[m[32m           env:[m
[32m+[m[32m           - name: OOTD_ENVIRONMENT[m
[32m+[m[32m             value: "production"[m
[32m+[m[32m           resources:[m
[32m+[m[32m             requests:[m
[32m+[m[32m               memory: "4Gi"[m
[32m+[m[32m               cpu: "1000m"[m
[32m+[m[32m               nvidia.com/gpu: 1[m
[32m+[m[32m             limits:[m
[32m+[m[32m               memory: "8Gi"[m
[32m+[m[32m               cpu: "2000m"[m
[32m+[m[32m               nvidia.com/gpu: 1[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m2. **Create Service**[m
[32m+[m[32m   ```yaml[m
[32m+[m[32m   apiVersion: v1[m
[32m+[m[32m   kind: Service[m
[32m+[m[32m   metadata:[m
[32m+[m[32m     name: ootd-service[m
[32m+[m[32m   spec:[m
[32m+[m[32m     selector:[m
[32m+[m[32m       app: ootd-api[m
[32m+[m[32m     ports:[m
[32m+[m[32m     - port: 80[m
[32m+[m[32m       targetPort: 7865[m
[32m+[m[32m     type: LoadBalancer[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m### Google Cloud Platform[m
[32m+[m
[32m+[m[32m#### Using Cloud Run[m
[32m+[m
[32m+[m[32m1. **Build and Push Image**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   # Build image[m
[32m+[m[32m   docker build -t gcr.io/PROJECT_ID/ootd .[m
[32m+[m[41m   [m
[32m+[m[32m   # Push to registry[m
[32m+[m[32m   docker push gcr.io/PROJECT_ID/ootd[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m2. **Deploy to Cloud Run**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   gcloud run deploy ootd-api \[m
[32m+[m[32m     --image gcr.io/PROJECT_ID/ootd \[m
[32m+[m[32m     --platform managed \[m
[32m+[m[32m     --region us-central1 \[m
[32m+[m[32m     --allow-unauthenticated \[m
[32m+[m[32m     --memory 8Gi \[m
[32m+[m[32m     --cpu 2 \[m
[32m+[m[32m     --max-instances 10[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m#### Using GKE (Google Kubernetes Engine)[m
[32m+[m
[32m+[m[32m1. **Create Cluster with GPU**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   gcloud container clusters create ootd-cluster \[m
[32m+[m[32m     --zone us-central1-a \[m
[32m+[m[32m     --machine-type n1-standard-4 \[m
[32m+[m[32m     --accelerator type=nvidia-tesla-t4,count=1 \[m
[32m+[m[32m     --num-nodes 3[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m2. **Deploy Application**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   kubectl apply -f k8s/deployment.yaml[m
[32m+[m[32m   kubectl apply -f k8s/service.yaml[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m### Azure Deployment[m
[32m+[m
[32m+[m[32m#### Using Container Instances[m
[32m+[m
[32m+[m[32m1. **Create Resource Group**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   az group create --name ootd-rg --location eastus[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m2. **Deploy Container**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   az container create \[m
[32m+[m[32m     --resource-group ootd-rg \[m
[32m+[m[32m     --name ootd-api \[m
[32m+[m[32m     --image your-registry.azurecr.io/ootd:latest \[m
[32m+[m[32m     --cpu 2 \[m
[32m+[m[32m     --memory 8 \[m
[32m+[m[32m     --ports 7865 \[m
[32m+[m[32m     --environment-variables OOTD_ENVIRONMENT=production[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m## 🔧 Configuration[m
[32m+[m
[32m+[m[32m### Environment-Specific Configs[m
[32m+[m
[32m+[m[32m#### Development[m
[32m+[m[32m```bash[m
[32m+[m[32mexport OOTD_ENVIRONMENT=development[m
[32m+[m[32mexport OOTD_DEBUG=true[m
[32m+[m[32mexport OOTD_LOG_LEVEL=DEBUG[m
[32m+[m[32mexport OOTD_WORKERS=1[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m#### Staging[m
[32m+[m[32m```bash[m
[32m+[m[32mexport OOTD_ENVIRONMENT=staging[m
[32m+[m[32mexport OOTD_DEBUG=false[m
[32m+[m[32mexport OOTD_LOG_LEVEL=INFO[m
[32m+[m[32mexport OOTD_WORKERS=2[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m#### Production[m
[32m+[m[32m```bash[m
[32m+[m[32mexport OOTD_ENVIRONMENT=production[m
[32m+[m[32mexport OOTD_DEBUG=false[m
[32m+[m[32mexport OOTD_LOG_LEVEL=WARNING[m
[32m+[m[32mexport OOTD_WORKERS=4[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### Model Configuration[m
[32m+[m
[32m+[m[32m#### GPU Configuration[m
[32m+[m[32m```python[m
[32m+[m[32m# config.py[m
[32m+[m[32m@dataclass[m
[32m+[m[32mclass ModelConfig:[m
[32m+[m[32m    device: str = "cuda:0"  # Primary GPU[m
[32m+[m[32m    torch_dtype: str = "float16"  # Memory optimization[m
[32m+[m[32m    enable_attention_slicing: bool = True[m
[32m+[m[32m    enable_memory_efficient_attention: bool = True[m
[32m+[m[32m    enable_cpu_offload: bool = False  # Set to True for large models[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m#### Multi-GPU Setup[m
[32m+[m[32m```python[m
[32m+[m[32m# For multiple GPUs[m
[32m+[m[32m@dataclass[m
[32m+[m[32mclass ModelConfig:[m
[32m+[m[32m    device: str = "cuda:0"[m
[32m+[m[32m    secondary_device: str = "cuda:1"  # For DC models[m
[32m+[m[32m    enable_model_parallelism: bool = True[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m## 📊 Monitoring and Logging[m
[32m+[m
[32m+[m[32m### Prometheus Metrics[m
[32m+[m
[32m+[m[32m1. **Add Prometheus Client**[m
[32m+[m[32m   ```python[m
[32m+[m[32m   from prometheus_client import Counter, Histogram, generate_latest[m
[32m+[m[41m   [m
[32m+[m[32m   # Metrics[m
[32m+[m[32m   request_count = Counter('ootd_requests_total', 'Total requests')[m
[32m+[m[32m   request_duration = Histogram('ootd_request_duration_seconds', 'Request duration')[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m2. **Expose Metrics Endpoint**[m
[32m+[m[32m   ```python[m
[32m+[m[32m   @app.get("/metrics")[m
[32m+[m[32m   async def metrics():[m
[32m+[m[32m       return Response(generate_latest(), media_type="text/plain")[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m### Grafana Dashboard[m
[32m+[m
[32m+[m[32m1. **Create Dashboard**[m
[32m+[m[32m   ```json[m
[32m+[m[32m   {[m
[32m+[m[32m     "dashboard": {[m
[32m+[m[32m       "title": "OOTDiffusion Metrics",[m
[32m+[m[32m       "panels": [[m
[32m+[m[32m         {[m
[32m+[m[32m           "title": "Request Rate",[m
[32m+[m[32m           "type": "graph",[m
[32m+[m[32m           "targets": [[m
[32m+[m[32m             {[m
[32m+[m[32m               "expr": "rate(ootd_requests_total[5m])"[m
[32m+[m[32m             }[m
[32m+[m[32m           ][m
[32m+[m[32m         }[m
[32m+[m[32m       ][m
[32m+[m[32m     }[m
[32m+[m[32m   }[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m### Log Aggregation[m
[32m+[m
[32m+[m[32m#### ELK Stack[m
[32m+[m[32m```yaml[m
[32m+[m[32m# docker-compose.logging.yml[m
[32m+[m[32mversion: '3.8'[m
[32m+[m[32mservices:[m
[32m+[m[32m  elasticsearch:[m
[32m+[m[32m    image: docker.elastic.co/elasticsearch/elasticsearch:7.15.0[m
[32m+[m[32m    environment:[m
[32m+[m[32m      - discovery.type=single-node[m
[32m+[m[32m    ports:[m
[32m+[m[32m      - "9200:9200"[m
[32m+[m[41m  [m
[32m+[m[32m  logstash:[m
[32m+[m[32m    image: docker.elastic.co/logstash/logstash:7.15.0[m
[32m+[m[32m    volumes:[m
[32m+[m[32m      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf[m
[32m+[m[32m    depends_on:[m
[32m+[m[32m      - elasticsearch[m
[32m+[m[41m  [m
[32m+[m[32m  kibana:[m
[32m+[m[32m    image: docker.elastic.co/kibana/kibana:7.15.0[m
[32m+[m[32m    ports:[m
[32m+[m[32m      - "5601:5601"[m
[32m+[m[32m    depends_on:[m
[32m+[m[32m      - elasticsearch[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m## 🔒 Security[m
[32m+[m
[32m+[m[32m### SSL/TLS Configuration[m
[32m+[m
[32m+[m[32m1. **Generate Certificates**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   # Using Let's Encrypt[m
[32m+[m[32m   certbot certonly --standalone -d your-domain.com[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m2. **Update Nginx Config**[m
[32m+[m[32m   ```nginx[m
[32m+[m[32m   server {[m
[32m+[m[32m       listen 443 ssl;[m
[32m+[m[32m       ssl_certificate /etc/letsencrypt/live/your-domain.com/fullchain.pem;[m
[32m+[m[32m       ssl_certificate_key /etc/letsencrypt/live/your-domain.com/privkey.pem;[m
[32m+[m[41m       [m
[32m+[m[32m       location / {[m
[32m+[m[32m           proxy_pass http://ootd_backend;[m
[32m+[m[32m       }[m
[32m+[m[32m   }[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m### Authentication[m
[32m+[m
[32m+[m[32m1. **API Key Authentication**[m
[32m+[m[32m   ```python[m
[32m+[m[32m   from fastapi import HTTPException, Depends[m
[32m+[m[32m   from fastapi.security import HTTPBearer[m
[32m+[m[41m   [m
[32m+[m[32m   security = HTTPBearer()[m
[32m+[m[41m   [m
[32m+[m[32m   def verify_token(token: str = Depends(security)):[m
[32m+[m[32m       if token.credentials != "your-api-key":[m
[32m+[m[32m           raise HTTPException(status_code=401, detail="Invalid API key")[m
[32m+[m[32m       return token[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m2. **JWT Authentication**[m
[32m+[m[32m   ```python[m
[32m+[m[32m   from jose import JWTError, jwt[m
[32m+[m[41m   [m
[32m+[m[32m   def verify_jwt_token(token: str = Depends(security)):[m
[32m+[m[32m       try:[m
[32m+[m[32m           payload = jwt.decode(token.credentials, SECRET_KEY, algorithms=[ALGORITHM])[m
[32m+[m[32m           return payload[m
[32m+[m[32m       except JWTError:[m
[32m+[m[32m           raise HTTPException(status_code=401, detail="Invalid token")[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m## 🚨 Troubleshooting[m
[32m+[m
[32m+[m[32m### Common Issues[m
[32m+[m
[32m+[m[32m#### Out of Memory[m
[32m+[m[32m```bash[m
[32m+[m[32m# Check memory usage[m
[32m+[m[32mdocker stats[m
[32m+[m
[32m+[m[32m# Reduce memory usage[m
[32m+[m[32mexport OOTD_WORKERS=1[m
[32m+[m[32mexport OOTD_ENABLE_CPU_OFFLOAD=true[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m#### GPU Issues[m
[32m+[m[32m```bash[m
[32m+[m[32m# Check GPU availability[m
[32m+[m[32mnvidia-smi[m
[32m+[m
[32m+[m[32m# Test GPU in container[m
[32m+[m[32mdocker run --rm --gpus all nvidia/cuda:11.8-base-ubuntu22.04 nvidia-smi[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m#### Model Loading Issues[m
[32m+[m[32m```bash[m
[32m+[m[32m# Check model paths[m
[32m+[m[32mls -la checkpoints/[m
[32m+[m
[32m+[m[32m# Verify model files[m
[32m+[m[32mpython -c "from config import config; print(config.get_model_paths())"[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### Performance Optimization[m
[32m+[m
[32m+[m[32m#### Horizontal Scaling[m
[32m+[m[32m```yaml[m
[32m+[m[32m# docker-compose.scale.yml[m
[32m+[m[32mversion: '3.8'[m
[32m+[m[32mservices:[m
[32m+[m[32m  ootd-api:[m
[32m+[m[32m    deploy:[m
[32m+[m[32m      replicas: 3[m
[32m+[m[32m    environment:[m
[32m+[m[32m      - OOTD_WORKERS=1[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m#### Vertical Scaling[m
[32m+[m[32m```yaml[m
[32m+[m[32m# Increase resources[m
[32m+[m[32mservices:[m
[32m+[m[32m  ootd-api:[m
[32m+[m[32m    deploy:[m
[32m+[m[32m      resources:[m
[32m+[m[32m        limits:[m
[32m+[m[32m          memory: 16G[m
[32m+[m[32m          cpus: '4'[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m## 📈 Scaling Strategies[m
[32m+[m
[32m+[m[32m### Auto-Scaling[m
[32m+[m
[32m+[m[32m#### Kubernetes HPA[m
[32m+[m[32m```yaml[m
[32m+[m[32mapiVersion: autoscaling/v2[m
[32m+[m[32mkind: HorizontalPodAutoscaler[m
[32m+[m[32mmetadata:[m
[32m+[m[32m  name: ootd-hpa[m
[32m+[m[32mspec:[m
[32m+[m[32m  scaleTargetRef:[m
[32m+[m[32m    apiVersion: apps/v1[m
[32m+[m[32m    kind: Deployment[m
[32m+[m[32m    name: ootd-api[m
[32m+[m[32m  minReplicas: 2[m
[32m+[m[32m  maxReplicas: 10[m
[32m+[m[32m  metrics:[m
[32m+[m[32m  - type: Resource[m
[32m+[m[32m    resource:[m
[32m+[m[32m      name: cpu[m
[32m+[m[32m      target:[m
[32m+[m[32m        type: Utilization[m
[32m+[m[32m        averageUtilization: 70[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m#### Docker Swarm[m
[32m+[m[32m```bash[m
[32m+[m[32m# Create service with scaling[m
[32m+[m[32mdocker service create \[m
[32m+[m[32m  --name ootd-api \[m
[32m+[m[32m  --replicas 3 \[m
[32m+[m[32m  --publish 7865:7865 \[m
[32m+[m[32m  your-registry/ootd:latest[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### Load Balancing[m
[32m+[m
[32m+[m[32m#### Nginx Load Balancer[m
[32m+[m[32m```nginx[m
[32m+[m[32mupstream ootd_backend {[m
[32m+[m[32m    least_conn;[m
[32m+[m[32m    server ootd-1:7865 weight=3;[m
[32m+[m[32m    server ootd-2:7865 weight=2;[m
[32m+[m[32m    server ootd-3:7865 weight=1;[m
[32m+[m[32m}[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m#### HAProxy[m
[32m+[m[32m```haproxy[m
[32m+[m[32mbackend ootd_backend[m
[32m+[m[32m    balance roundrobin[m
[32m+[m[32m    server ootd-1 ootd-1:7865 check[m
[32m+[m[32m    server ootd-2 ootd-2:7865 check[m
[32m+[m[32m    server ootd-3 ootd-3:7865 check[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m## 🔄 Backup and Recovery[m
[32m+[m
[32m+[m[32m### Data Backup[m
[32m+[m
[32m+[m[32m1. **Model Checkpoints**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   # Backup models[m
[32m+[m[32m   tar -czf models-backup-$(date +%Y%m%d).tar.gz checkpoints/[m
[32m+[m[41m   [m
[32m+[m[32m   # Upload to cloud storage[m
[32m+[m[32m   aws s3 cp models-backup-$(date +%Y%m%d).tar.gz s3://your-bucket/backups/[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m2. **Configuration Backup**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   # Backup configuration[m
[32m+[m[32m   tar -czf config-backup-$(date +%Y%m%d).tar.gz config.py .env docker-compose.yml[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m### Disaster Recovery[m
[32m+[m
[32m+[m[32m1. **Restore from Backup**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   # Download backup[m
[32m+[m[32m   aws s3 cp s3://your-bucket/backups/models-backup-20241219.tar.gz .[m
[32m+[m[41m   [m
[32m+[m[32m   # Extract backup[m
[32m+[m[32m   tar -xzf models-backup-20241219.tar.gz[m
[32m+[m[41m   [m
[32m+[m[32m   # Restart services[m
[32m+[m[32m   docker-compose up -d[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m2. **Health Check After Recovery**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   # Verify services[m
[32m+[m[32m   curl http://localhost:7865/health[m
[32m+[m[41m   [m
[32m+[m[32m   # Run tests[m
[32m+[m[32m   pytest tests/ -v[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m## 📞 Support[m
[32m+[m
[32m+[m[32m### Monitoring Alerts[m
[32m+[m
[32m+[m[32m1. **Set up Alerts**[m
[32m+[m[32m   ```yaml[m
[32m+[m[32m   # alertmanager.yml[m
[32m+[m[32m   groups:[m
[32m+[m[32m   - name: ootd[m
[32m+[m[32m     rules:[m
[32m+[m[32m     - alert: OOTDServiceDown[m
[32m+[m[32m       expr: up{job="ootd-api"} == 0[m
[32m+[m[32m       for: 1m[m
[32m+[m[32m       labels:[m
[32m+[m[32m         severity: critical[m
[32m+[m[32m       annotations:[m
[32m+[m[32m         summary: "OOTD API is down"[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m2. **Notification Channels**[m
[32m+[m[32m   - Email alerts[m
[32m+[m[32m   - Slack notifications[m
[32m+[m[32m   - PagerDuty integration[m
[32m+[m
[32m+[m[32m### Maintenance Windows[m
[32m+[m
[32m+[m[32m1. **Scheduled Maintenance**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   # Create maintenance script[m
[32m+[m[32m   #!/bin/bash[m
[32m+[m[32m   echo "Starting maintenance window..."[m
[32m+[m[32m   docker-compose down[m
[32m+[m[32m   # Perform maintenance tasks[m
[32m+[m[32m   docker-compose up -d[m
[32m+[m[32m   echo "Maintenance completed"[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m2. **Zero-Downtime Updates**[m
[32m+[m[32m   ```bash[m
[32m+[m[32m   # Rolling update[m
[32m+[m[32m   docker-compose up -d --no-deps ootd-api[m
[32m+[m[32m   ```[m
[32m+[m
[32m+[m[32m---[m
[32m+[m
[32m+[m[32mThis deployment guide provides comprehensive instructions for deploying OOTDiffusion in various production environments. Choose the approach that best fits your infrastructure and requirements.[m
[1mdiff --git a/Dockerfile b/Dockerfile[m
[1mnew file mode 100644[m
[1mindex 0000000..ef513d5[m
[1m--- /dev/null[m
[1m+++ b/Dockerfile[m
[36m@@ -0,0 +1,90 @@[m
[32m+[m[32m# Multi-stage Dockerfile for OOTDiffusion production deployment[m
[32m+[m[32mFROM nvidia/cuda:11.8-devel-ubuntu22.04 as base[m
[32m+[m
[32m+[m[32m# Set environment variables[m
[32m+[m[32mENV DEBIAN_FRONTEND=noninteractive[m
[32m+[m[32mENV PYTHONUNBUFFERED=1[m
[32m+[m[32mENV CUDA_HOME=/usr/local/cuda[m
[32m+[m[32mENV PATH=${CUDA_HOME}/bin:${PATH}[m
[32m+[m[32mENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}[m
[32m+[m
[32m+[m[32m# Install system dependencies[m
[32m+[m[32mRUN apt-get update && apt-get install -y \[m
[32m+[m[32m    python3.10 \[m
[32m+[m[32m    python3.10-dev \[m
[32m+[m[32m    python3-pip \[m
[32m+[m[32m    python3.10-venv \[m
[32m+[m[32m    git \[m
[32m+[m[32m    wget \[m
[32m+[m[32m    curl \[m
[32m+[m[32m    build-essential \[m
[32m+[m[32m    cmake \[m
[32m+[m[32m    ninja-build \[m
[32m+[m[32m    libgl1-mesa-glx \[m
[32m+[m[32m    libglib2.0-0 \[m
[32m+[m[32m    libsm6 \[m
[32m+[m[32m    libxext6 \[m
[32m+[m[32m    libxrender-dev \[m
[32m+[m[32m    libgomp1 \[m
[32m+[m[32m    libgcc-s1 \[m
[32m+[m[32m    && rm -rf /var/lib/apt/lists/*[m
[32m+[m
[32m+[m[32m# Create symbolic link for python[m
[32m+[m[32mRUN ln -s /usr/bin/python3.10 /usr/bin/python[m
[32m+[m
[32m+[m[32m# Upgrade pip[m
[32m+[m[32mRUN python -m pip install --upgrade pip[m
[32m+[m
[32m+[m[32m# Set working directory[m
[32m+[m[32mWORKDIR /app[m
[32m+[m
[32m+[m[32m# Copy requirements first for better caching[m
[32m+[m[32mCOPY requirements.txt .[m
[32m+[m[32mCOPY requirements-prod.txt .[m
[32m+[m
[32m+[m[32m# Install Python dependencies[m
[32m+[m[32mRUN pip install --no-cache-dir -r requirements-prod.txt[m
[32m+[m
[32m+[m[32m# Copy application code[m
[32m+[m[32mCOPY . .[m
[32m+[m
[32m+[m[32m# Create necessary directories[m
[32m+[m[32mRUN mkdir -p checkpoints temp outputs/logs[m
[32m+[m
[32m+[m[32m# Set permissions[m
[32m+[m[32mRUN chmod +x scripts/*.sh 2>/dev/null || true[m
[32m+[m
[32m+[m[32m# Expose port[m
[32m+[m[32mEXPOSE 7865[m
[32m+[m
[32m+[m[32m# Health check[m
[32m+[m[32mHEALTHCHECK --interval=30s --timeout=30s --start-period=60s --retries=3 \[m
[32m+[m[32m    CMD curl -f http://localhost:7865/health || exit 1[m
[32m+[m
[32m+[m[32m# Default command[m
[32m+[m[32mCMD ["python", "api/app.py"][m
[32m+[m
[32m+[m[32m# Development stage[m
[32m+[m[32mFROM base as development[m
[32m+[m
[32m+[m[32m# Install development dependencies[m
[32m+[m[32mRUN pip install --no-cache-dir -r requirements-dev.txt[m
[32m+[m
[32m+[m[32m# Set environment for development[m
[32m+[m[32mENV OOTD_ENVIRONMENT=development[m
[32m+[m[32mENV OOTD_DEBUG=true[m
[32m+[m
[32m+[m[32m# Production stage[m
[32m+[m[32mFROM base as production[m
[32m+[m
[32m+[m[32m# Set environment for production[m
[32m+[m[32mENV OOTD_ENVIRONMENT=production[m
[32m+[m[32mENV OOTD_DEBUG=false[m
[32m+[m
[32m+[m[32m# Create non-root user for security[m
[32m+[m[32mRUN groupadd -r ootd && useradd -r -g ootd ootd[m
[32m+[m[32mRUN chown -R ootd:ootd /app[m
[32m+[m[32mUSER ootd[m
[32m+[m
[32m+[m[32m# Use production command[m
[32m+[m[32mCMD ["python", "api/app.py"][m
[1mdiff --git a/README-PRODUCTION.md b/README-PRODUCTION.md[m
[1mnew file mode 100644[m
[1mindex 0000000..131a242[m
[1m--- /dev/null[m
[1m+++ b/README-PRODUCTION.md[m
[36m@@ -0,0 +1,529 @@[m
[32m+[m[32m# OOTDiffusion - Production Ready[m
[32m+[m
[32m+[m[32m[![Production Ready](https://img.shields.io/badge/Production-Ready-green.svg)](https://github.com/levihsu/OOTDiffusion)[m
[32m+[m[32m[![Docker](https://img.shields.io/badge/Docker-Supported-blue.svg)](https://www.docker.com/)[m
[32m+[m[32m[![FastAPI](https://img.shields.io/badge/FastAPI-API-red.svg)](https://fastapi.tiangolo.com/)[m
[32m+[m[32m[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org/)[m
[32m+[m
[32m+[m[32mA production-ready implementation of OOTDiffusion: Outfitting Fusion based Latent Diffusion for Controllable Virtual Try-on.[m
[32m+[m
[32m+[m[32m## 🚀 Quick Start[m
[32m+[m
[32m+[m[32m### Prerequisites[m
[32m+[m
[32m+[m[32m- **Docker** and **Docker Compose**[m
[32m+[m[32m- **NVIDIA GPU** with CUDA support (recommended)[m
[32m+[m[32m- **8GB+ RAM** (16GB+ recommended)[m
[32m+[m[32m- **10GB+ free disk space** for models[m
[32m+[m
[32m+[m[32m### 1. Clone and Setup[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32mgit clone https://github.com/levihsu/OOTDiffusion.git[m
[32m+[m[32mcd OOTDiffusion[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### 2. Run Setup Script[m
[32m+[m
[32m+[m[32m**Linux/macOS:**[m
[32m+[m[32m```bash[m
[32m+[m[32mchmod +x scripts/setup.sh[m
[32m+[m[32m./scripts/setup.sh[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m**Windows:**[m
[32m+[m[32m```cmd[m
[32m+[m[32mscripts\setup.bat[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### 3. Download Model Checkpoints[m
[32m+[m
[32m+[m[32mDownload the required model checkpoints:[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32m# Create checkpoints directory[m
[32m+[m[32mmkdir -p checkpoints[m
[32m+[m
[32m+[m[32m# Download OOTDiffusion models[m
[32m+[m[32mcd checkpoints[m
[32m+[m[32mgit lfs install[m
[32m+[m[32mgit clone https://huggingface.co/levihsu/OOTDiffusion ootd[m
[32m+[m[32mgit clone https://huggingface.co/levihsu/OOTDiffusion humanparsing[m
[32m+[m[32mgit clone https://huggingface.co/levihsu/OOTDiffusion openpose[m
[32m+[m[32mgit clone https://huggingface.co/openai/clip-vit-large-patch14[m
[32m+[m[32mcd ..[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### 4. Deploy with Docker[m
[32m+[m
[32m+[m[32m**Production:**[m
[32m+[m[32m```bash[m
[32m+[m[32mdocker-compose up -d[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m**Development:**[m
[32m+[m[32m```bash[m
[32m+[m[32mdocker-compose --profile dev up -d[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m**With Nginx (Production):**[m
[32m+[m[32m```bash[m
[32m+[m[32mdocker-compose --profile nginx up -d[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### 5. Access the API[m
[32m+[m
[32m+[m[32m- **API Documentation:** http://localhost:7865/docs[m
[32m+[m[32m- **Health Check:** http://localhost:7865/health[m
[32m+[m[32m- **With Nginx:** http://localhost[m
[32m+[m
[32m+[m[32m## 📋 API Usage[m
[32m+[m
[32m+[m[32m### Process Images[m
[32m+[m
[32m+[m[32m**Endpoint:** `POST /process`[m
[32m+[m
[32m+[m[32m**Parameters:**[m
[32m+[m[32m- `model_file`: Model image (required)[m
[32m+[m[32m- `cloth_file`: Garment image (required)[m
[32m+[m[32m- `model_type`: "hd" or "dc" (default: "hd")[m
[32m+[m[32m- `category`: 0=upperbody, 1=lowerbody, 2=dress (default: 0)[m
[32m+[m[32m- `samples`: Number of samples (1-4, default: 1)[m
[32m+[m[32m- `steps`: Inference steps (1-40, default: 20)[m
[32m+[m[32m- `scale`: Guidance scale (1.0-5.0, default: 2.0)[m
[32m+[m[32m- `seed`: Random seed (-1 for random, default: -1)[m
[32m+[m
[32m+[m[32m**Example with cURL:**[m
[32m+[m[32m```bash[m
[32m+[m[32mcurl -X POST "http://localhost:7865/process" \[m
[32m+[m[32m  -F "model_file=@model.jpg" \[m
[32m+[m[32m  -F "cloth_file=@cloth.jpg" \[m
[32m+[m[32m  -F "model_type=hd" \[m
[32m+[m[32m  -F "category=0" \[m
[32m+[m[32m  -F "samples=1" \[m
[32m+[m[32m  -F "steps=20" \[m
[32m+[m[32m  -F "scale=2.0" \[m
[32m+[m[32m  -F "seed=42"[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m**Response:**[m
[32m+[m[32m```json[m
[32m+[m[32m{[m
[32m+[m[32m  "success": true,[m
[32m+[m[32m  "message": "Images processed successfully",[m
[32m+[m[32m  "result_paths": ["/static/results/result_20241219_143022_0.png"],[m
[32m+[m[32m  "processing_time": 15.2[m
[32m+[m[32m}[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### Health Check[m
[32m+[m
[32m+[m[32m**Endpoint:** `GET /health`[m
[32m+[m
[32m+[m[32m**Response:**[m
[32m+[m[32m```json[m
[32m+[m[32m{[m
[32m+[m[32m  "status": "healthy",[m
[32m+[m[32m  "timestamp": "2024-12-19T14:30:22.123456",[m
[32m+[m[32m  "version": "1.0.0",[m
[32m+[m[32m  "environment": "production",[m
[32m+[m[32m  "models_loaded": true,[m
[32m+[m[32m  "gpu_available": true[m
[32m+[m[32m}[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m## 🔧 Configuration[m
[32m+[m
[32m+[m[32m### Environment Variables[m
[32m+[m
[32m+[m[32mCreate a `.env` file or set environment variables:[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32m# Basic Configuration[m
[32m+[m[32mOOTD_ENVIRONMENT=production[m
[32m+[m[32mOOTD_DEBUG=false[m
[32m+[m[32mOOTD_HOST=0.0.0.0[m
[32m+[m[32mOOTD_PORT=7865[m
[32m+[m[32mOOTD_WORKERS=1[m
[32m+[m
[32m+[m[32m# Model Configuration[m
[32m+[m[32mOOTD_DEVICE=cuda:0[m
[32m+[m[32mOOTD_TORCH_DTYPE=float16[m
[32m+[m
[32m+[m[32m# Logging[m
[32m+[m[32mOOTD_LOG_LEVEL=INFO[m
[32m+[m[32mOOTD_LOG_FILE=logs/ootd.log[m
[32m+[m
[32m+[m[32m# Security[m
[32m+[m[32mOOTD_SECRET_KEY=your-secret-key-here[m
[32m+[m[32mOOTD_MAX_FILE_SIZE=10485760[m
[32m+[m[32mOOTD_ALLOWED_EXTENSIONS=.jpg,.jpeg,.png,.bmp[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### Model Configuration[m
[32m+[m
[32m+[m[32mEdit `config.py` to customize model settings:[m
[32m+[m
[32m+[m[32m```python[m
[32m+[m[32m@dataclass[m
[32m+[m[32mclass ModelConfig:[m
[32m+[m[32m    device: str = "cuda:0"[m
[32m+[m[32m    torch_dtype: str = "float16"[m
[32m+[m[32m    enable_attention_slicing: bool = True[m
[32m+[m[32m    enable_memory_efficient_attention: bool = True[m
[32m+[m[32m    enable_cpu_offload: bool = False[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m## 🐳 Docker Deployment[m
[32m+[m
[32m+[m[32m### Production Deployment[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32m# Build and run[m
[32m+[m[32mdocker-compose up -d[m
[32m+[m
[32m+[m[32m# Check status[m
[32m+[m[32mdocker-compose ps[m
[32m+[m
[32m+[m[32m# View logs[m
[32m+[m[32mdocker-compose logs -f ootd-api[m
[32m+[m
[32m+[m[32m# Stop services[m
[32m+[m[32mdocker-compose down[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### Development Deployment[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32m# Run with development profile[m
[32m+[m[32mdocker-compose --profile dev up -d[m
[32m+[m
[32m+[m[32m# Access development API at port 7866[m
[32m+[m[32mcurl http://localhost:7866/health[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### Custom Configuration[m
[32m+[m
[32m+[m[32m```yaml[m
[32m+[m[32m# docker-compose.override.yml[m
[32m+[m[32mversion: '3.8'[m
[32m+[m[32mservices:[m
[32m+[m[32m  ootd-api:[m
[32m+[m[32m    environment:[m
[32m+[m[32m      - OOTD_WORKERS=4[m
[32m+[m[32m      - OOTD_DEVICE=cuda:0[m
[32m+[m[32m    deploy:[m
[32m+[m[32m      resources:[m
[32m+[m[32m        reservations:[m
[32m+[m[32m          devices:[m
[32m+[m[32m            - driver: nvidia[m
[32m+[m[32m              count: 2[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m## 📊 Monitoring[m
[32m+[m
[32m+[m[32m### Health Checks[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32m# Check API health[m
[32m+[m[32mcurl http://localhost:7865/health[m
[32m+[m
[32m+[m[32m# Check container status[m
[32m+[m[32mdocker-compose ps[m
[32m+[m
[32m+[m[32m# View resource usage[m
[32m+[m[32mdocker stats[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### Monitoring Script[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32m# Run monitoring script[m
[32m+[m[32m./scripts/monitor.sh  # Linux/macOS[m
[32m+[m[32mscripts\monitor.bat   # Windows[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### Logs[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32m# View API logs[m
[32m+[m[32mdocker-compose logs -f ootd-api[m
[32m+[m
[32m+[m[32m# View all logs[m
[32m+[m[32mdocker-compose logs -f[m
[32m+[m
[32m+[m[32m# Save logs to file[m
[32m+[m[32mdocker-compose logs > logs/ootd.log[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m## 🔒 Security[m
[32m+[m
[32m+[m[32m### Input Validation[m
[32m+[m
[32m+[m[32m- File type verification using MIME type detection[m
[32m+[m[32m- File size limits (configurable, default: 10MB)[m
[32m+[m[32m- Image dimension validation[m
[32m+[m[32m- Parameter range checking[m
[32m+[m[32m- Filename sanitization[m
[32m+[m
[32m+[m[32m### Container Security[m
[32m+[m
[32m+[m[32m- Non-root user execution[m
[32m+[m[32m- Minimal base images[m
[32m+[m[32m- Security headers[m
[32m+[m[32m- Resource limits[m
[32m+[m[32m- No unnecessary packages[m
[32m+[m
[32m+[m[32m### API Security[m
[32m+[m
[32m+[m[32m- Rate limiting (configurable)[m
[32m+[m[32m- CORS configuration[m
[32m+[m[32m- Input sanitization[m
[32m+[m[32m- Error message sanitization[m
[32m+[m[32m- Request size limits[m
[32m+[m
[32m+[m[32m## 🧪 Testing[m
[32m+[m
[32m+[m[32m### Run Tests[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32m# Install test dependencies[m
[32m+[m[32mpip install -r requirements-dev.txt[m
[32m+[m
[32m+[m[32m# Run all tests[m
[32m+[m[32mpytest tests/ -v[m
[32m+[m
[32m+[m[32m# Run specific test file[m
[32m+[m[32mpytest tests/test_api.py -v[m
[32m+[m
[32m+[m[32m# Run with coverage[m
[32m+[m[32mpytest tests/ --cov=api --cov-report=html[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### Test API Endpoints[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32m# Test health endpoint[m
[32m+[m[32mcurl http://localhost:7865/health[m
[32m+[m
[32m+[m[32m# Test with sample images[m
[32m+[m[32mcurl -X POST "http://localhost:7865/process" \[m
[32m+[m[32m  -F "model_file=@run/examples/model/model_1.png" \[m
[32m+[m[32m  -F "cloth_file=@run/examples/garment/03244_00.jpg" \[m
[32m+[m[32m  -F "model_type=hd"[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m## 📈 Performance[m
[32m+[m
[32m+[m[32m### Optimization Tips[m
[32m+[m
[32m+[m[32m1. **GPU Memory:**[m
[32m+[m[32m   - Use `enable_attention_slicing=True`[m
[32m+[m[32m   - Use `enable_memory_efficient_attention=True`[m
[32m+[m[32m   - Consider `enable_cpu_offload=True` for large models[m
[32m+[m
[32m+[m[32m2. **Processing:**[m
[32m+[m[32m   - Reduce `steps` for faster processing[m
[32m+[m[32m   - Use fewer `samples` for quicker results[m
[32m+[m[32m   - Optimize image dimensions[m
[32m+[m
[32m+[m[32m3. **Scaling:**[m
[32m+[m[32m   - Increase `OOTD_WORKERS` for more concurrent requests[m
[32m+[m[32m   - Use multiple GPU devices[m
[32m+[m[32m   - Implement load balancing[m
[32m+[m
[32m+[m[32m### Benchmarking[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32m# Run performance tests[m
[32m+[m[32mpytest tests/test_performance.py -v[m
[32m+[m
[32m+[m[32m# Monitor resource usage[m
[32m+[m[32mdocker stats ootdiffusion-ootd-api-1[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m## 🚨 Troubleshooting[m
[32m+[m
[32m+[m[32m### Common Issues[m
[32m+[m
[32m+[m[32m#### Models Not Loading[m
[32m+[m[32m```bash[m
[32m+[m[32m# Check if checkpoints exist[m
[32m+[m[32mls -la checkpoints/[m
[32m+[m
[32m+[m[32m# Verify model paths in config.py[m
[32m+[m[32mpython -c "from config import config; print(config.get_model_paths())"[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m#### GPU Not Available[m
[32m+[m[32m```bash[m
[32m+[m[32m# Check NVIDIA Docker[m
[32m+[m[32mdocker run --rm --gpus all nvidia/cuda:11.8-base-ubuntu22.04 nvidia-smi[m
[32m+[m
[32m+[m[32m# Check CUDA in container[m
[32m+[m[32mdocker-compose exec ootd-api nvidia-smi[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m#### Out of Memory[m
[32m+[m[32m```bash[m
[32m+[m[32m# Reduce batch size[m
[32m+[m[32mexport OOTD_WORKERS=1[m
[32m+[m
[32m+[m[32m# Enable CPU offload[m
[32m+[m[32m# Edit config.py: enable_cpu_offload=True[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m#### Port Already in Use[m
[32m+[m[32m```bash[m
[32m+[m[32m# Change port in .env[m
[32m+[m[32mecho "OOTD_PORT=7866" >> .env[m
[32m+[m
[32m+[m[32m# Restart services[m
[32m+[m[32mdocker-compose down && docker-compose up -d[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### Debug Mode[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32m# Enable debug mode[m
[32m+[m[32mexport OOTD_DEBUG=true[m
[32m+[m[32mexport OOTD_LOG_LEVEL=DEBUG[m
[32m+[m
[32m+[m[32m# Restart with debug[m
[32m+[m[32mdocker-compose down && docker-compose up -d[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### Log Analysis[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32m# View error logs[m
[32m+[m[32mdocker-compose logs ootd-api | grep ERROR[m
[32m+[m
[32m+[m[32m# View performance logs[m
[32m+[m[32mdocker-compose logs ootd-api | grep "execution_time"[m
[32m+[m
[32m+[m[32m# Export logs[m
[32m+[m[32mdocker-compose logs ootd-api > debug.log[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m## 🔄 Maintenance[m
[32m+[m
[32m+[m[32m### Updates[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32m# Update application[m
[32m+[m[32m./scripts/update.sh  # Linux/macOS[m
[32m+[m[32mscripts\update.bat   # Windows[m
[32m+[m
[32m+[m[32m# Or manually[m
[32m+[m[32mgit pull origin main[m
[32m+[m[32mdocker-compose build --no-cache[m
[32m+[m[32mdocker-compose up -d[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### Backups[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32m# Create backup[m
[32m+[m[32m./scripts/backup.sh  # Linux/macOS[m
[32m+[m[32mscripts\backup.bat   # Windows[m
[32m+[m
[32m+[m[32m# Restore from backup[m
[32m+[m[32mtar -xzf backups/20241219_143022.tar.gz[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### Cleanup[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32m# Clean temporary files[m
[32m+[m[32mdocker-compose exec ootd-api python -c "from utils.error_handling import cleanup_temp_files; cleanup_temp_files()"[m
[32m+[m
[32m+[m[32m# Clean old results[m
[32m+[m[32mfind outputs/results -name "*.png" -mtime +7 -delete[m
[32m+[m
[32m+[m[32m# Clean Docker[m
[32m+[m[32mdocker system prune -f[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m## 📚 API Reference[m
[32m+[m
[32m+[m[32m### Endpoints[m
[32m+[m
[32m+[m[32m| Method | Endpoint | Description |[m
[32m+[m[32m|--------|----------|-------------|[m
[32m+[m[32m| GET | `/` | API information |[m
[32m+[m[32m| GET | `/health` | Health check |[m
[32m+[m[32m| POST | `/process` | Process images |[m
[32m+[m[32m| GET | `/results/{filename}` | Download results |[m
[32m+[m[32m| GET | `/docs` | API documentation |[m
[32m+[m
[32m+[m[32m### Models[m
[32m+[m
[32m+[m[32m| Model Type | Description | Categories |[m
[32m+[m[32m|------------|-------------|------------|[m
[32m+[m[32m| `hd` | Half-body model | 0=upperbody |[m
[32m+[m[32m| `dc` | Full-body model | 0=upperbody, 1=lowerbody, 2=dress |[m
[32m+[m
[32m+[m[32m### Error Codes[m
[32m+[m
[32m+[m[32m| Code | Description |[m
[32m+[m[32m|------|-------------|[m
[32m+[m[32m| 200 | Success |[m
[32m+[m[32m| 400 | Bad Request |[m
[32m+[m[32m| 422 | Validation Error |[m
[32m+[m[32m| 500 | Internal Server Error |[m
[32m+[m[32m| 503 | Service Unavailable |[m
[32m+[m
[32m+[m[32m## 🤝 Contributing[m
[32m+[m
[32m+[m[32m### Development Setup[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32m# Clone repository[m
[32m+[m[32mgit clone https://github.com/levihsu/OOTDiffusion.git[m
[32m+[m[32mcd OOTDiffusion[m
[32m+[m
[32m+[m[32m# Install development dependencies[m
[32m+[m[32mpip install -r requirements-dev.txt[m
[32m+[m
[32m+[m[32m# Install pre-commit hooks[m
[32m+[m[32mpre-commit install[m
[32m+[m
[32m+[m[32m# Run tests[m
[32m+[m[32mpytest tests/ -v[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### Code Style[m
[32m+[m
[32m+[m[32m```bash[m
[32m+[m[32m# Format code[m
[32m+[m[32mblack .[m
[32m+[m[32misort .[m
[32m+[m
[32m+[m[32m# Lint code[m
[32m+[m[32mflake8 .[m
[32m+[m
[32m+[m[32m# Type checking[m
[32m+[m[32mmypy .[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m## 📄 License[m
[32m+[m
[32m+[m[32mThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.[m
[32m+[m
[32m+[m[32m## 🙏 Acknowledgments[m
[32m+[m
[32m+[m[32m- Original OOTDiffusion authors for the research implementation[m
[32m+[m[32m- FastAPI team for the excellent web framework[m
[32m+[m[32m- Docker team for containerization support[m
[32m+[m[32m- Open source community for various dependencies[m
[32m+[m
[32m+[m[32m## 📞 Support[m
[32m+[m
[32m+[m[32m- **Issues:** [GitHub Issues](https://github.com/levihsu/OOTDiffusion/issues)[m
[32m+[m[32m- **Discussions:** [GitHub Discussions](https://github.com/levihsu/OOTDiffusion/discussions)[m
[32m+[m[32m- **Documentation:** [API Docs](http://localhost:7865/docs)[m
[32m+[m
[32m+[m[32m---[m
[32m+[m
[32m+[m[32m**Made with ❤️ for the AI community**[m
[1mdiff --git a/api/app.py b/api/app.py[m
[1mnew file mode 100644[m
[1mindex 0000000..95dbfb8[m
[1m--- /dev/null[m
[1m+++ b/api/app.py[m
[36m@@ -0,0 +1,367 @@[m
[32m+[m[32m"""[m
[32m+[m[32mProduction-ready FastAPI application for OOTDiffusion[m
[32m+[m[32m"""[m
[32m+[m[32mimport os[m
[32m+[m[32mimport sys[m
[32m+[m[32mfrom pathlib import Path[m
[32m+[m[32mfrom typing import List, Optional, Union[m
[32m+[m[32mimport asyncio[m
[32m+[m[32mimport tempfile[m
[32m+[m[32mimport shutil[m
[32m+[m[32mfrom datetime import datetime[m
[32m+[m
[32m+[m[32m# Add project root to path[m
[32m+[m[32mPROJECT_ROOT = Path(__file__).absolute().parents[1][m
[32m+[m[32msys.path.insert(0, str(PROJECT_ROOT))[m
[32m+[m
[32m+[m[32mfrom fastapi import FastAPI, File, UploadFile, HTTPException, Depends, BackgroundTasks[m
[32m+[m[32mfrom fastapi.middleware.cors import CORSMiddleware[m
[32m+[m[32mfrom fastapi.middleware.gzip import GZipMiddleware[m
[32m+[m[32mfrom fastapi.responses import JSONResponse, FileResponse[m
[32m+[m[32mfrom fastapi.staticfiles import StaticFiles[m
[32m+[m[32mfrom pydantic import BaseModel, Field[m
[32m+[m[32mimport uvicorn[m
[32m+[m[32mfrom PIL import Image[m
[32m+[m[32mimport logging[m
[32m+[m
[32m+[m[32m# Import our modules[m
[32m+[m[32mfrom config import config, get_config[m
[32m+[m[32mfrom utils.error_handling import ([m
[32m+[m[32m    OOTDError, ModelLoadError, ProcessingError, ValidationError,[m
[32m+[m[32m    error_handler, performance_monitor, logger, error_tracker[m
[32m+[m[32m)[m
[32m+[m[32mfrom utils.validation import validator, validate_and_convert_category, create_temp_file[m
[32m+[m
[32m+[m[32m# Import OOTDiffusion models[m
[32m+[m[32mfrom ootd.inference_ootd_hd import OOTDiffusionHD[m
[32m+[m[32mfrom ootd.inference_ootd_dc import OOTDiffusionDC[m
[32m+[m[32mfrom preprocess.openpose.run_openpose import OpenPose[m
[32m+[m[32mfrom preprocess.humanparsing.run_parsing import Parsing[m
[32m+[m[32mfrom run.utils_ootd import get_mask_location[m
[32m+[m
[32m+[m[32m# Pydantic models for API[m
[32m+[m[32mclass ProcessRequest(BaseModel):[m
[32m+[m[32m    model_type: str = Field(default="hd", description="Model type: 'hd' or 'dc'")[m
[32m+[m[32m    category: Union[int, str] = Field(default=0, description="Garment category: 0=upperbody, 1=lowerbody, 2=dress")[m
[32m+[m[32m    samples: int = Field(default=1, ge=1, le=4, description="Number of samples to generate")[m
[32m+[m[32m    steps: int = Field(default=20, ge=1, le=40, description="Number of inference steps")[m
[32m+[m[32m    scale: float = Field(default=2.0, ge=1.0, le=5.0, description="Guidance scale")[m
[32m+[m[32m    seed: int = Field(default=-1, ge=-1, le=2147483647, description="Random seed (-1 for random)")[m
[32m+[m
[32m+[m[32mclass ProcessResponse(BaseModel):[m
[32m+[m[32m    success: bool[m
[32m+[m[32m    message: str[m
[32m+[m[32m    result_paths: Optional[List[str]] = None[m
[32m+[m[32m    processing_time: Optional[float] = None[m
[32m+[m[32m    error_code: Optional[str] = None[m
[32m+[m
[32m+[m[32mclass HealthResponse(BaseModel):[m
[32m+[m[32m    status: str[m
[32m+[m[32m    timestamp: str[m
[32m+[m[32m    version: str[m
[32m+[m[32m    environment: str[m
[32m+[m[32m    models_loaded: bool[m
[32m+[m[32m    gpu_available: bool[m
[32m+[m
[32m+[m[32mclass ModelManager:[m
[32m+[m[32m    """Manages model loading and inference"""[m
[32m+[m[41m    [m
[32m+[m[32m    def __init__(self):[m
[32m+[m[32m        self.models = {}[m
[32m+[m[32m        self.models_loaded = False[m
[32m+[m[32m        self.load_models()[m
[32m+[m[41m    [m
[32m+[m[32m    @error_handler(reraise=True)[m
[32m+[m[32m    def load_models(self):[m
[32m+[m[32m        """Load all required models"""[m
[32m+[m[32m        logger.info("Loading OOTDiffusion models...")[m
[32m+[m[41m        [m
[32m+[m[32m        try:[m
[32m+[m[32m            # Load OpenPose and Parsing models[m
[32m+[m[32m            self.models['openpose_hd'] = OpenPose(0)[m
[32m+[m[32m            self.models['parsing_hd'] = Parsing(0)[m
[32m+[m[32m            self.models['ootd_hd'] = OOTDiffusionHD(0)[m
[32m+[m[41m            [m
[32m+[m[32m            # Load DC models on different GPU if available[m
[32m+[m[32m            gpu_id = 1 if self._is_cuda_available() and self._get_gpu_count() > 1 else 0[m
[32m+[m[32m            self.models['openpose_dc'] = OpenPose(gpu_id)[m
[32m+[m[32m            self.models['parsing_dc'] = Parsing(gpu_id)[m
[32m+[m[32m            self.models['ootd_dc'] = OOTDiffusionDC(gpu_id)[m
[32m+[m[41m            [m
[32m+[m[32m            self.models_loaded = True[m
[32m+[m[32m            logger.info("All models loaded successfully")[m
[32m+[m[41m            [m
[32m+[m[32m        except Exception as e:[m
[32m+[m[32m            logger.error(f"Failed to load models: {e}")[m
[32m+[m[32m            raise ModelLoadError(f"Failed to load models: {e}", "all_models")[m
[32m+[m[41m    [m
[32m+[m[32m    def _is_cuda_available(self) -> bool:[m
[32m+[m[32m        """Check if CUDA is available"""[m
[32m+[m[32m        try:[m
[32m+[m[32m            import torch[m
[32m+[m[32m            return torch.cuda.is_available()[m
[32m+[m[32m        except ImportError:[m
[32m+[m[32m            return False[m
[32m+[m[41m    [m
[32m+[m[32m    def _get_gpu_count(self) -> int:[m
[32m+[m[32m        """Get number of available GPUs"""[m
[32m+[m[32m        try:[m
[32m+[m[32m            import torch[m
[32m+[m[32m            return torch.cuda.device_count()[m
[32m+[m[32m        except:[m
[32m+[m[32m            return 0[m
[32m+[m[41m    [m
[32m+[m[32m    @performance_monitor[m
[32m+[m[32m    @error_handler(reraise=True)[m
[32m+[m[32m    def process_image(self, model_path: str, cloth_path: str, request: ProcessRequest) -> List[str]:[m
[32m+[m[32m        """Process image with OOTDiffusion"""[m
[32m+[m[41m        [m
[32m+[m[32m        # Validate inputs[m
[32m+[m[32m        is_valid, errors = validator.validate_request({[m
[32m+[m[32m            'model_path': model_path,[m
[32m+[m[32m            'cloth_path': cloth_path,[m
[32m+[m[32m            'model_type': request.model_type,[m
[32m+[m[32m            'category': request.category,[m
[32m+[m[32m            'samples': request.samples,[m
[32m+[m[32m            'steps': request.steps,[m
[32m+[m[32m            'scale': request.scale,[m
[32m+[m[32m            'seed': request.seed[m
[32m+[m[32m        })[m
[32m+[m[41m        [m
[32m+[m[32m        if not is_valid:[m
[32m+[m[32m            raise ValidationError(f"Invalid request: {', '.join(errors)}", "request")[m
[32m+[m[41m        [m
[32m+[m[32m        # Convert category to integer[m
[32m+[m[32m        category = validate_and_convert_category(request.category, request.model_type)[m
[32m+[m[41m        [m
[32m+[m[32m        # Load and process images[m
[32m+[m[32m        model_img = Image.open(model_path).resize((768, 1024))[m
[32m+[m[32m        cloth_img = Image.open(cloth_path).resize((768, 1024))[m
[32m+[m[41m        [m
[32m+[m[32m        # Get appropriate models[m
[32m+[m[32m        if request.model_type == 'hd':[m
[32m+[m[32m            openpose_model = self.models['openpose_hd'][m
[32m+[m[32m            parsing_model = self.models['parsing_hd'][m
[32m+[m[32m            ootd_model = self.models['ootd_hd'][m
[32m+[m[32m        else:[m
[32m+[m[32m            openpose_model = self.models['openpose_dc'][m
[32m+[m[32m            parsing_model = self.models['parsing_dc'][m
[32m+[m[32m            ootd_model = self.models['ootd_dc'][m
[32m+[m[41m        [m
[32m+[m[32m        # Process with OpenPose and Parsing[m
[32m+[m[32m        keypoints = openpose_model(model_img.resize((384, 512)))[m
[32m+[m[32m        model_parse, _ = parsing_model(model_img.resize((384, 512)))[m
[32m+[m[41m        [m
[32m+[m[32m        # Get mask[m
[32m+[m[32m        category_dict_utils = ['upper_body', 'lower_body', 'dresses'][m
[32m+[m[32m        mask, mask_gray = get_mask_location([m
[32m+[m[32m            request.model_type,[m[41m [m
[32m+[m[32m            category_dict_utils[category],[m[41m [m
[32m+[m[32m            model_parse,[m[41m [m
[32m+[m[32m            keypoints[m
[32m+[m[32m        )[m
[32m+[m[41m        [m
[32m+[m[32m        mask = mask.resize((768, 1024), Image.NEAREST)[m
[32m+[m[32m        mask_gray = mask_gray.resize((768, 1024), Image.NEAREST)[m
[32m+[m[41m        [m
[32m+[m[32m        masked_model_img = Image.composite(mask_gray, model_img, mask)[m
[32m+[m[41m        [m
[32m+[m[32m        # Generate images[m
[32m+[m[32m        category_dict = ['upperbody', 'lowerbody', 'dress'][m
[32m+[m[32m        images = ootd_model([m
[32m+[m[32m            model_type=request.model_type,[m
[32m+[m[32m            category=category_dict[category],[m
[32m+[m[32m            image_garm=cloth_img,[m
[32m+[m[32m            image_vton=masked_model_img,[m
[32m+[m[32m            mask=mask,[m
[32m+[m[32m            image_ori=model_img,[m
[32m+[m[32m            num_samples=request.samples,[m
[32m+[m[32m            num_steps=request.steps,[m
[32m+[m[32m            image_scale=request.scale,[m
[32m+[m[32m            seed=request.seed,[m
[32m+[m[32m        )[m
[32m+[m[41m        [m
[32m+[m[32m        # Save results[m
[32m+[m[32m        result_paths = [][m
[32m+[m[32m        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")[m
[32m+[m[41m        [m
[32m+[m[32m        for i, img in enumerate(images):[m
[32m+[m[32m            result_filename = f"result_{timestamp}_{i}.png"[m
[32m+[m[32m            result_path = config.output_dir / "results" / result_filename[m
[32m+[m[32m            result_path.parent.mkdir(parents=True, exist_ok=True)[m
[32m+[m[41m            [m
[32m+[m[32m            img.save(result_path, "PNG", quality=config.processing.image_quality)[m
[32m+[m[32m            result_paths.append(str(result_path))[m
[32m+[m[41m        [m
[32m+[m[32m        return result_paths[m
[32m+[m
[32m+[m[32m# Initialize FastAPI app[m
[32m+[m[32mapp = FastAPI([m
[32m+[m[32m    title="OOTDiffusion API",[m
[32m+[m[32m    description="Production-ready API for Outfitting Fusion based Latent Diffusion",[m
[32m+[m[32m    version="1.0.0",[m
[32m+[m[32m    docs_url="/docs" if config.debug else None,[m
[32m+[m[32m    redoc_url="/redoc" if config.debug else None[m
[32m+[m[32m)[m
[32m+[m
[32m+[m[32m# Add middleware[m
[32m+[m[32mapp.add_middleware([m
[32m+[m[32m    CORSMiddleware,[m
[32m+[m[32m    allow_origins=config.server.allowed_origins,[m
[32m+[m[32m    allow_credentials=True,[m
[32m+[m[32m    allow_methods=["*"],[m
[32m+[m[32m    allow_headers=["*"],[m
[32m+[m[32m)[m
[32m+[m
[32m+[m[32mapp.add_middleware(GZipMiddleware, minimum_size=1000)[m
[32m+[m
[32m+[m[32m# Mount static files[m
[32m+[m[32mapp.mount("/static", StaticFiles(directory=str(config.output_dir)), name="static")[m
[32m+[m
[32m+[m[32m# Initialize model manager[m
[32m+[m[32mmodel_manager = ModelManager()[m
[32m+[m
[32m+[m[32m# Dependency to get model manager[m
[32m+[m[32mdef get_model_manager() -> ModelManager:[m
[32m+[m[32m    if not model_manager.models_loaded:[m
[32m+[m[32m        raise HTTPException(status_code=503, detail="Models not loaded")[m
[32m+[m[32m    return model_manager[m
[32m+[m
[32m+[m[32m@app.get("/", response_model=dict)[m
[32m+[m[32masync def root():[m
[32m+[m[32m    """Root endpoint"""[m
[32m+[m[32m    return {[m
[32m+[m[32m        "message": "OOTDiffusion API",[m
[32m+[m[32m        "version": "1.0.0",[m
[32m+[m[32m        "docs": "/docs" if config.debug else "disabled",[m
[32m+[m[32m        "health": "/health"[m
[32m+[m[32m    }[m
[32m+[m
[32m+[m[32m@app.get("/health", response_model=HealthResponse)[m
[32m+[m[32masync def health_check():[m
[32m+[m[32m    """Health check endpoint"""[m
[32m+[m[32m    import torch[m
[32m+[m[41m    [m
[32m+[m[32m    return HealthResponse([m
[32m+[m[32m        status="healthy" if model_manager.models_loaded else "unhealthy",[m
[32m+[m[32m        timestamp=datetime.now().isoformat(),[m
[32m+[m[32m        version="1.0.0",[m
[32m+[m[32m        environment=config.environment,[m
[32m+[m[32m        models_loaded=model_manager.models_loaded,[m
[32m+[m[32m        gpu_available=torch.cuda.is_available() if 'torch' in sys.modules else False[m
[32m+[m[32m    )[m
[32m+[m
[32m+[m[32m@app.post("/process", response_model=ProcessResponse)[m
[32m+[m[32masync def process_images([m
[32m+[m[32m    background_tasks: BackgroundTasks,[m
[32m+[m[32m    model_file: UploadFile = File(..., description="Model image file"),[m
[32m+[m[32m    cloth_file: UploadFile = File(..., description="Cloth image file"),[m
[32m+[m[32m    request: ProcessRequest = Depends(),[m
[32m+[m[32m    model_manager: ModelManager = Depends(get_model_manager)[m
[32m+[m[32m):[m
[32m+[m[32m    """Process images with OOTDiffusion"""[m
[32m+[m[41m    [m
[32m+[m[32m    start_time = datetime.now()[m
[32m+[m[32m    model_temp_path = None[m
[32m+[m[32m    cloth_temp_path = None[m
[32m+[m[41m    [m
[32m+[m[32m    try:[m
[32m+[m[32m        # Validate uploaded files[m
[32m+[m[32m        if not model_file.content_type.startswith('image/'):[m
[32m+[m[32m            raise HTTPException(status_code=400, detail="Model file must be an image")[m
[32m+[m[41m        [m
[32m+[m[32m        if not cloth_file.content_type.startswith('image/'):[m
[32m+[m[32m            raise HTTPException(status_code=400, detail="Cloth file must be an image")[m
[32m+[m[41m        [m
[32m+[m[32m        # Create temporary files[m
[32m+[m[32m        model_temp_path = create_temp_file(model_file.filename)[m
[32m+[m[32m        cloth_temp_path = create_temp_file(cloth_file.filename)[m
[32m+[m[41m        [m
[32m+[m[32m        # Save uploaded files[m
[32m+[m[32m        with open(model_temp_path, "wb") as buffer:[m
[32m+[m[32m            shutil.copyfileobj(model_file.file, buffer)[m
[32m+[m[41m        [m
[32m+[m[32m        with open(cloth_temp_path, "wb") as buffer:[m
[32m+[m[32m            shutil.copyfileobj(cloth_file.file, buffer)[m
[32m+[m[41m        [m
[32m+[m[32m        # Process images[m
[32m+[m[32m        result_paths = model_manager.process_image([m
[32m+[m[32m            str(model_temp_path),[m
[32m+[m[32m            str(cloth_temp_path),[m
[32m+[m[32m            request[m
[32m+[m[32m        )[m
[32m+[m[41m        [m
[32m+[m[32m        processing_time = (datetime.now() - start_time).total_seconds()[m
[32m+[m[41m        [m
[32m+[m[32m        # Schedule cleanup[m
[32m+[m[32m        background_tasks.add_task(cleanup_temp_files, [model_temp_path, cloth_temp_path])[m
[32m+[m[41m        [m
[32m+[m[32m        return ProcessResponse([m
[32m+[m[32m            success=True,[m
[32m+[m[32m            message="Images processed successfully",[m
[32m+[m[32m            result_paths=result_paths,[m
[32m+[m[32m            processing_time=processing_time[m
[32m+[m[32m        )[m
[32m+[m[41m        [m
[32m+[m[32m    except ValidationError as e:[m
[32m+[m[32m        logger.error(f"Validation error: {e.message}")[m
[32m+[m[32m        raise HTTPException(status_code=400, detail=e.message)[m
[32m+[m[41m    [m
[32m+[m[32m    except ProcessingError as e:[m
[32m+[m[32m        logger.error(f"Processing error: {e.message}")[m
[32m+[m[32m        raise HTTPException(status_code=500, detail=f"Processing failed: {e.message}")[m
[32m+[m[41m    [m
[32m+[m[32m    except OOTDError as e:[m
[32m+[m[32m        logger.error(f"OOTD error: {e.message}")[m
[32m+[m[32m        raise HTTPException(status_code=500, detail=f"Error: {e.message}")[m
[32m+[m[41m    [m
[32m+[m[32m    except Exception as e:[m
[32m+[m[32m        error_tracker.track_error(e, {[m
[32m+[m[32m            "endpoint": "process",[m
[32m+[m[32m            "model_filename": model_file.filename,[m
[32m+[m[32m            "cloth_filename": cloth_file.filename[m
[32m+[m[32m        })[m
[32m+[m[32m        logger.error(f"Unexpected error: {e}")[m
[32m+[m[32m        raise HTTPException(status_code=500, detail="Internal server error")[m
[32m+[m[41m    [m
[32m+[m[32m    finally:[m
[32m+[m[32m        # Cleanup on error[m
[32m+[m[32m        if model_temp_path and model_temp_path.exists():[m
[32m+[m[32m            model_temp_path.unlink()[m
[32m+[m[32m        if cloth_temp_path and cloth_temp_path.exists():[m
[32m+[m[32m            cloth_temp_path.unlink()[m
[32m+[m
[32m+[m[32m@app.get("/results/{filename}")[m
[32m+[m[32masync def get_result(filename: str):[m
[32m+[m[32m    """Get processed result image"""[m
[32m+[m[32m    result_path = config.output_dir / "results" / filename[m
[32m+[m[41m    [m
[32m+[m[32m    if not result_path.exists():[m
[32m+[m[32m        raise HTTPException(status_code=404, detail="Result not found")[m
[32m+[m[41m    [m
[32m+[m[32m    return FileResponse(result_path)[m
[32m+[m
[32m+[m[32masync def cleanup_temp_files(file_paths: List[Path]):[m
[32m+[m[32m    """Clean up temporary files"""[m
[32m+[m[32m    for file_path in file_paths:[m
[32m+[m[32m        try:[m
[32m+[m[32m            if file_path.exists():[m
[32m+[m[32m                file_path.unlink()[m
[32m+[m[32m        except Exception as e:[m
[32m+[m[32m            logger.error(f"Failed to cleanup {file_path}: {e}")[m
[32m+[m
[32m+[m[32mif __name__ == "__main__":[m
[32m+[m[32m    # Configure logging[m
[32m+[m[32m    logging.basicConfig([m
[32m+[m[32m        level=getattr(logging, config.logging.level.upper()),[m
[32m+[m[32m        format=config.logging.format[m
[32m+[m[32m    )[m
[32m+[m[41m    [m
[32m+[m[32m    # Run server[m
[32m+[m[32m    uvicorn.run([m
[32m+[m[32m        "api.app:app",[m
[32m+[m[32m        host=config.server.host,[m
[32m+[m[32m        port=config.server.port,[m
[32m+[m[32m        workers=config.server.workers,[m
[32m+[m[32m        log_level=config.logging.level.lower()[m
[32m+[m[32m    )[m
[1mdiff --git a/config.py b/config.py[m
[1mnew file mode 100644[m
[1mindex 0000000..91e632c[m
[1m--- /dev/null[m
[1m+++ b/config.py[m
[36m@@ -0,0 +1,229 @@[m
[32m+[m[32m"""[m
[32m+[m[32mProduction-ready configuration management for OOTDiffusion[m
[32m+[m[32m"""[m
[32m+[m[32mimport os[m
[32m+[m[32mfrom pathlib import Path[m
[32m+[m[32mfrom typing import Optional, Dict, Any[m
[32m+[m[32mfrom dataclasses import dataclass, field[m
[32m+[m[32mimport logging[m
[32m+[m
[32m+[m[32m# Set up logging[m
[32m+[m[32mlogging.basicConfig(level=logging.INFO)[m
[32m+[m[32mlogger = logging.getLogger(__name__)[m
[32m+[m
[32m+[m[32m@dataclass[m
[32m+[m[32mclass ModelConfig:[m
[32m+[m[32m    """Configuration for model paths and settings"""[m
[32m+[m[32m    # Model paths[m
[32m+[m[32m    ootd_path: str = "checkpoints/ootd"[m
[32m+[m[32m    humanparsing_path: str = "checkpoints/humanparsing"[m
[32m+[m[32m    openpose_path: str = "checkpoints/openpose"[m
[32m+[m[32m    clip_path: str = "checkpoints/clip-vit-large-patch14"[m
[32m+[m[41m    [m
[32m+[m[32m    # Model settings[m
[32m+[m[32m    device: str = "cuda:0"[m
[32m+[m[32m    torch_dtype: str = "float16"[m
[32m+[m[32m    use_safetensors: bool = True[m
[32m+[m[41m    [m
[32m+[m[32m    # Performance settings[m
[32m+[m[32m    enable_attention_slicing: bool = True[m
[32m+[m[32m    enable_memory_efficient_attention: bool = True[m
[32m+[m[32m    enable_cpu_offload: bool = False[m
[32m+[m
[32m+[m[32m@dataclass[m
[32m+[m[32mclass ServerConfig:[m
[32m+[m[32m    """Configuration for server settings"""[m
[32m+[m[32m    host: str = "0.0.0.0"[m
[32m+[m[32m    port: int = 7865[m
[32m+[m[32m    workers: int = 1[m
[32m+[m[32m    max_request_size: int = 50 * 1024 * 1024  # 50MB[m
[32m+[m[32m    timeout: int = 300  # 5 minutes[m
[32m+[m[41m    [m
[32m+[m[32m    # Security[m
[32m+[m[32m    allowed_origins: list = field(default_factory=lambda: ["*"])[m
[32m+[m[32m    max_file_size: int = 10 * 1024 * 1024  # 10MB[m
[32m+[m[32m    allowed_extensions: list = field(default_factory=lambda: [".jpg", ".jpeg", ".png", ".bmp"])[m
[32m+[m
[32m+[m[32m@dataclass[m
[32m+[m[32mclass ProcessingConfig:[m
[32m+[m[32m    """Configuration for image processing"""[m
[32m+[m[32m    # Image dimensions[m
[32m+[m[32m    hd_width: int = 768[m
[32m+[m[32m    hd_height: int = 1024[m
[32m+[m[32m    dc_width: int = 768[m
[32m+[m[32m    dc_height: int = 1024[m
[32m+[m[41m    [m
[32m+[m[32m    # Processing parameters[m
[32m+[m[32m    default_samples: int = 1[m
[32m+[m[32m    max_samples: int = 4[m
[32m+[m[32m    default_steps: int = 20[m
[32m+[m[32m    max_steps: int = 40[m
[32m+[m[32m    default_scale: float = 2.0[m
[32m+[m[32m    min_scale: float = 1.0[m
[32m+[m[32m    max_scale: float = 5.0[m
[32m+[m[41m    [m
[32m+[m[32m    # Quality settings[m
[32m+[m[32m    image_quality: int = 95[m
[32m+[m[32m    resize_algorithm: str = "LANCZOS"[m
[32m+[m
[32m+[m[32m@dataclass[m
[32m+[m[32mclass LoggingConfig:[m
[32m+[m[32m    """Configuration for logging"""[m
[32m+[m[32m    level: str = "INFO"[m
[32m+[m[32m    format: str = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"[m
[32m+[m[32m    file_path: Optional[str] = None[m
[32m+[m[32m    max_file_size: int = 10 * 1024 * 1024  # 10MB[m
[32m+[m[32m    backup_count: int = 5[m
[32m+[m
[32m+[m[32m@dataclass[m
[32m+[m[32mclass ProductionConfig:[m
[32m+[m[32m    """Main production configuration"""[m
[32m+[m[32m    model: ModelConfig = field(default_factory=ModelConfig)[m
[32m+[m[32m    server: ServerConfig = field(default_factory=ServerConfig)[m
[32m+[m[32m    processing: ProcessingConfig = field(default_factory=ProcessingConfig)[m
[32m+[m[32m    logging: LoggingConfig = field(default_factory=LoggingConfig)[m
[32m+[m[41m    [m
[32m+[m[32m    # Environment[m
[32m+[m[32m    environment: str = "production"[m
[32m+[m[32m    debug: bool = False[m
[32m+[m[41m    [m
[32m+[m[32m    # Paths[m
[32m+[m[32m    project_root: Path = field(default_factory=lambda: Path(__file__).parent)[m
[32m+[m[32m    checkpoints_dir: Path = field(default_factory=lambda: Path("checkpoints"))[m
[32m+[m[32m    temp_dir: Path = field(default_factory=lambda: Path("temp"))[m
[32m+[m[32m    output_dir: Path = field(default_factory=lambda: Path("outputs"))[m
[32m+[m[41m    [m
[32m+[m[32m    def __post_init__(self):[m
[32m+[m[32m        """Initialize configuration after creation"""[m
[32m+[m[32m        # Set up environment variables[m
[32m+[m[32m        self._load_from_env()[m
[32m+[m[41m        [m
[32m+[m[32m        # Create necessary directories[m
[32m+[m[32m        self._create_directories()[m
[32m+[m[41m        [m
[32m+[m[32m        # Validate configuration[m
[32m+[m[32m        self._validate()[m
[32m+[m[41m    [m
[32m+[m[32m    def _load_from_env(self):[m
[32m+[m[32m        """Load configuration from environment variables"""[m
[32m+[m[32m        # Model settings[m
[32m+[m[32m        if os.getenv("OOTD_DEVICE"):[m
[32m+[m[32m            self.model.device = os.getenv("OOTD_DEVICE")[m
[32m+[m[41m        [m
[32m+[m[32m        if os.getenv("OOTD_TORCH_DTYPE"):[m
[32m+[m[32m            self.model.torch_dtype = os.getenv("OOTD_TORCH_DTYPE")[m
[32m+[m[41m        [m
[32m+[m[32m        # Server settings[m
[32m+[m[32m        if os.getenv("OOTD_HOST"):[m
[32m+[m[32m            self.server.host = os.getenv("OOTD_HOST")[m
[32m+[m[41m        [m
[32m+[m[32m        if os.getenv("OOTD_PORT"):[m
[32m+[m[32m            self.server.port = int(os.getenv("OOTD_PORT"))[m
[32m+[m[41m        [m
[32m+[m[32m        if os.getenv("OOTD_WORKERS"):[m
[32m+[m[32m            self.server.workers = int(os.getenv("OOTD_WORKERS"))[m
[32m+[m[41m        [m
[32m+[m[32m        # Environment[m
[32m+[m[32m        if os.getenv("OOTD_ENVIRONMENT"):[m
[32m+[m[32m            self.environment = os.getenv("OOTD_ENVIRONMENT")[m
[32m+[m[41m        [m
[32m+[m[32m        if os.getenv("OOTD_DEBUG"):[m
[32m+[m[32m            self.debug = os.getenv("OOTD_DEBUG").lower() == "true"[m
[32m+[m[41m    [m
[32m+[m[32m    def _create_directories(self):[m
[32m+[m[32m        """Create necessary directories"""[m
[32m+[m[32m        directories = [[m
[32m+[m[32m            self.checkpoints_dir,[m
[32m+[m[32m            self.temp_dir,[m
[32m+[m[32m            self.output_dir,[m
[32m+[m[32m            self.temp_dir / "uploads",[m
[32m+[m[32m            self.temp_dir / "processed",[m
[32m+[m[32m            self.output_dir / "results"[m
[32m+[m[32m        ][m
[32m+[m[41m        [m
[32m+[m[32m        for directory in directories:[m
[32m+[m[32m            directory.mkdir(parents=True, exist_ok=True)[m
[32m+[m[32m            logger.info(f"Created directory: {directory}")[m
[32m+[m[41m    [m
[32m+[m[32m    def _validate(self):[m
[32m+[m[32m        """Validate configuration"""[m
[32m+[m[32m        # Check if checkpoints exist[m
[32m+[m[32m        required_checkpoints = [[m
[32m+[m[32m            self.checkpoints_dir / "ootd",[m
[32m+[m[32m            self.checkpoints_dir / "humanparsing",[m
[32m+[m[32m            self.checkpoints_dir / "openpose",[m
[32m+[m[32m            self.checkpoints_dir / "clip-vit-large-patch14"[m
[32m+[m[32m        ][m
[32m+[m[41m        [m
[32m+[m[32m        missing_checkpoints = [][m
[32m+[m[32m        for checkpoint in required_checkpoints:[m
[32m+[m[32m            if not checkpoint.exists():[m
[32m+[m[32m                missing_checkpoints.append(str(checkpoint))[m
[32m+[m[41m        [m
[32m+[m[32m        if missing_checkpoints:[m
[32m+[m[32m            logger.warning(f"Missing checkpoints: {missing_checkpoints}")[m
[32m+[m[32m            logger.warning("Please download the required model checkpoints from Hugging Face")[m
[32m+[m[41m        [m
[32m+[m[32m        # Validate device[m
[32m+[m[32m        if self.model.device.startswith("cuda") and not self._is_cuda_available():[m
[32m+[m[32m            logger.warning("CUDA not available, falling back to CPU")[m
[32m+[m[32m            self.model.device = "cpu"[m
[32m+[m[41m    [m
[32m+[m[32m    def _is_cuda_available(self) -> bool:[m
[32m+[m[32m        """Check if CUDA is available"""[m
[32m+[m[32m        try:[m
[32m+[m[32m            import torch[m
[32m+[m[32m            return torch.cuda.is_available()[m
[32m+[m[32m        except ImportError:[m
[32m+[m[32m            return False[m
[32m+[m[41m    [m
[32m+[m[32m    def get_model_paths(self) -> Dict[str, str]:[m
[32m+[m[32m        """Get all model paths as a dictionary"""[m
[32m+[m[32m        return {[m
[32m+[m[32m            "ootd": str(self.checkpoints_dir / "ootd"),[m
[32m+[m[32m            "humanparsing": str(self.checkpoints_dir / "humanparsing"),[m
[32m+[m[32m            "openpose": str(self.checkpoints_dir / "openpose"),[m
[32m+[m[32m            "clip": str(self.checkpoints_dir / "clip-vit-large-patch14")[m
[32m+[m[32m        }[m
[32m+[m[41m    [m
[32m+[m[32m    def to_dict(self) -> Dict[str, Any]:[m
[32m+[m[32m        """Convert configuration to dictionary"""[m
[32m+[m[32m        return {[m
[32m+[m[32m            "model": self.model.__dict__,[m
[32m+[m[32m            "server": self.server.__dict__,[m
[32m+[m[32m            "processing": self.processing.__dict__,[m
[32m+[m[32m            "logging": self.logging.__dict__,[m
[32m+[m[32m            "environment": self.environment,[m
[32m+[m[32m            "debug": self.debug,[m
[32m+[m[32m            "project_root": str(self.project_root),[m
[32m+[m[32m            "checkpoints_dir": str(self.checkpoints_dir),[m
[32m+[m[32m            "temp_dir": str(self.temp_dir),[m
[32m+[m[32m            "output_dir": str(self.output_dir)[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m# Global configuration instance[m
[32m+[m[32mconfig = ProductionConfig()[m
[32m+[m
[32m+[m[32m# Environment-specific configurations[m
[32m+[m[32mdef get_config(environment: str = "production") -> ProductionConfig:[m
[32m+[m[32m    """Get configuration for specific environment"""[m
[32m+[m[32m    if environment == "development":[m
[32m+[m[32m        config.environment = "development"[m
[32m+[m[32m        config.debug = True[m
[32m+[m[32m        config.logging.level = "DEBUG"[m
[32m+[m[32m        config.server.workers = 1[m
[32m+[m[32m    elif environment == "testing":[m
[32m+[m[32m        config.environment = "testing"[m
[32m+[m[32m        config.debug = True[m
[32m+[m[32m        config.logging.level = "DEBUG"[m
[32m+[m[32m        config.server.workers = 1[m
[32m+[m[32m        config.model.device = "cpu"  # Use CPU for testing[m
[32m+[m[32m    else:  # production[m
[32m+[m[32m        config.environment = "production"[m
[32m+[m[32m        config.debug = False[m
[32m+[m[32m        config.logging.level = "INFO"[m
[32m+[m[41m    [m
[32m+[m[32m    return config[m
[32m+[m
[32m+[m[32m# Export the main configuration[m
[32m+[m[32m__all__ = ["config", "get_config", "ProductionConfig", "ModelConfig", "ServerConfig", "ProcessingConfig", "LoggingConfig"][m
[1mdiff --git a/docker-compose.yml b/docker-compose.yml[m
[1mnew file mode 100644[m
[1mindex 0000000..8c9cf58[m
[1m--- /dev/null[m
[1m+++ b/docker-compose.yml[m
[36m@@ -0,0 +1,92 @@[m
[32m+[m[32mversion: '3.8'[m
[32m+[m
[32m+[m[32mservices:[m
[32m+[m[32m  ootd-api:[m
[32m+[m[32m    build:[m
[32m+[m[32m      context: .[m
[32m+[m[32m      dockerfile: Dockerfile[m
[32m+[m[32m      target: production[m
[32m+[m[32m    ports:[m
[32m+[m[32m      - "7865:7865"[m
[32m+[m[32m    environment:[m
[32m+[m[32m      - OOTD_ENVIRONMENT=production[m
[32m+[m[32m      - OOTD_DEBUG=false[m
[32m+[m[32m      - OOTD_HOST=0.0.0.0[m
[32m+[m[32m      - OOTD_PORT=7865[m
[32m+[m[32m      - OOTD_WORKERS=1[m
[32m+[m[32m      - OOTD_DEVICE=cuda:0[m
[32m+[m[32m    volumes:[m
[32m+[m[32m      - ./checkpoints:/app/checkpoints:ro[m
[32m+[m[32m      - ./outputs:/app/outputs[m
[32m+[m[32m      - ./logs:/app/logs[m
[32m+[m[32m    deploy:[m
[32m+[m[32m      resources:[m
[32m+[m[32m        reservations:[m
[32m+[m[32m          devices:[m
[32m+[m[32m            - driver: nvidia[m
[32m+[m[32m              count: 1[m
[32m+[m[32m              capabilities: [gpu][m
[32m+[m[32m    restart: unless-stopped[m
[32m+[m[32m    healthcheck:[m
[32m+[m[32m      test: ["CMD", "curl", "-f", "http://localhost:7865/health"][m
[32m+[m[32m      interval: 30s[m
[32m+[m[32m      timeout: 10s[m
[32m+[m[32m      retries: 3[m
[32m+[m[32m      start_period: 60s[m
[32m+[m
[32m+[m[32m  ootd-dev:[m
[32m+[m[32m    build:[m
[32m+[m[32m      context: .[m
[32m+[m[32m      dockerfile: Dockerfile[m
[32m+[m[32m      target: development[m
[32m+[m[32m    ports:[m
[32m+[m[32m      - "7866:7865"[m
[32m+[m[32m    environment:[m
[32m+[m[32m      - OOTD_ENVIRONMENT=development[m
[32m+[m[32m      - OOTD_DEBUG=true[m
[32m+[m[32m      - OOTD_HOST=0.0.0.0[m
[32m+[m[32m      - OOTD_PORT=7865[m
[32m+[m[32m      - OOTD_WORKERS=1[m
[32m+[m[32m      - OOTD_DEVICE=cuda:0[m
[32m+[m[32m    volumes:[m
[32m+[m[32m      - ./:/app[m
[32m+[m[32m      - ./checkpoints:/app/checkpoints:ro[m
[32m+[m[32m      - ./outputs:/app/outputs[m
[32m+[m[32m      - ./logs:/app/logs[m
[32m+[m[32m    deploy:[m
[32m+[m[32m      resources:[m
[32m+[m[32m        reservations:[m
[32m+[m[32m          devices:[m
[32m+[m[32m            - driver: nvidia[m
[32m+[m[32m              count: 1[m
[32m+[m[32m              capabilities: [gpu][m
[32m+[m[32m    restart: unless-stopped[m
[32m+[m[32m    profiles:[m
[32m+[m[32m      - dev[m
[32m+[m
[32m+[m[32m  redis:[m
[32m+[m[32m    image: redis:7-alpine[m
[32m+[m[32m    ports:[m
[32m+[m[32m      - "6379:6379"[m
[32m+[m[32m    volumes:[m
[32m+[m[32m      - redis_data:/data[m
[32m+[m[32m    restart: unless-stopped[m
[32m+[m[32m    profiles:[m
[32m+[m[32m      - cache[m
[32m+[m
[32m+[m[32m  nginx:[m
[32m+[m[32m    image: nginx:alpine[m
[32m+[m[32m    ports:[m
[32m+[m[32m      - "80:80"[m
[32m+[m[32m      - "443:443"[m
[32m+[m[32m    volumes:[m
[32m+[m[32m      - ./nginx.conf:/etc/nginx/nginx.conf:ro[m
[32m+[m[32m      - ./ssl:/etc/nginx/ssl:ro[m
[32m+[m[32m    depends_on:[m
[32m+[m[32m      - ootd-api[m
[32m+[m[32m    restart: unless-stopped[m
[32m+[m[32m    profiles:[m
[32m+[m[32m      - nginx[m
[32m+[m
[32m+[m[32mvolumes:[m
[32m+[m[32m  redis_data:[m
[1mdiff --git a/requirements-dev.txt b/requirements-dev.txt[m
[1mnew file mode 100644[m
[1mindex 0000000..90df273[m
[1m--- /dev/null[m
[1m+++ b/requirements-dev.txt[m
[36m@@ -0,0 +1,38 @@[m
[32m+[m[32m# Development requirements for OOTDiffusion[m
[32m+[m[32m# Include production requirements[m
[32m+[m[32m-r requirements-prod.txt[m
[32m+[m
[32m+[m[32m# Testing[m
[32m+[m[32mpytest==7.4.3[m
[32m+[m[32mpytest-asyncio==0.21.1[m
[32m+[m[32mpytest-cov==4.1.0[m
[32m+[m[32mpytest-mock==3.12.0[m
[32m+[m[32mhttpx==0.25.2[m
[32m+[m
[32m+[m[32m# Code quality[m
[32m+[m[32mblack==23.11.0[m
[32m+[m[32misort==5.12.0[m
[32m+[m[32mflake8==6.1.0[m
[32m+[m[32mmypy==1.7.1[m
[32m+[m[32mpre-commit==3.6.0[m
[32m+[m
[32m+[m[32m# Documentation[m
[32m+[m[32mmkdocs==1.5.3[m
[32m+[m[32mmkdocs-material==9.4.8[m
[32m+[m[32mmkdocs-mermaid2-plugin==1.1.1[m
[32m+[m
[32m+[m[32m# Development tools[m
[32m+[m[32mjupyter==1.0.0[m
[32m+[m[32mipython==8.17.2[m
[32m+[m[32mnotebook==7.0.6[m
[32m+[m
[32m+[m[32m# Debugging[m
[32m+[m[32mpdb++==0.10.3[m
[32m+[m[32mipdb==0.13.13[m
[32m+[m
[32m+[m[32m# Performance profiling[m
[32m+[m[32mmemory-profiler==0.61.0[m
[32m+[m[32mline-profiler==4.1.1[m
[32m+[m
[32m+[m[32m# API testing[m
[32m+[m[32mpostman-collection==0.1.0[m
[1mdiff --git a/requirements-prod.txt b/requirements-prod.txt[m
[1mnew file mode 100644[m
[1mindex 0000000..2c6e628[m
[1m--- /dev/null[m
[1m+++ b/requirements-prod.txt[m
[36m@@ -0,0 +1,58 @@[m
[32m+[m[32m# Production requirements for OOTDiffusion[m
[32m+[m[32m# Base requirements[m
[32m+[m[32mnumpy==1.24.4[m
[32m+[m[32mscipy==1.10.1[m
[32m+[m[32mscikit-image==0.21.0[m
[32m+[m[32mopencv-python==4.7.0.72[m
[32m+[m[32mpillow==9.4.0[m
[32m+[m[32mdiffusers==0.24.0[m
[32m+[m[32mtransformers==4.36.2[m
[32m+[m[32maccelerate==0.26.1[m
[32m+[m[32mmatplotlib==3.7.4[m
[32m+[m[32mtqdm==4.64.1[m
[32m+[m[32meinops==0.7.0[m
[32m+[m[32monnxruntime==1.16.2[m
[32m+[m
[32m+[m[32m# Production web framework[m
[32m+[m[32mfastapi==0.104.1[m
[32m+[m[32muvicorn[standard]==0.24.0[m
[32m+[m[32mpython-multipart==0.0.6[m
[32m+[m
[32m+[m[32m# Additional production dependencies[m
[32m+[m[32mgunicorn==21.2.0[m
[32m+[m[32mpython-magic==0.4.27[m
[32m+[m[32mpydantic==2.5.0[m
[32m+[m[32mpydantic-settings==2.1.0[m
[32m+[m
[32m+[m[32m# Monitoring and logging[m
[32m+[m[32mstructlog==23.2.0[m
[32m+[m[32mprometheus-client==0.19.0[m
[32m+[m
[32m+[m[32m# Security[m
[32m+[m[32mpython-jose[cryptography]==3.3.0[m
[32m+[m[32mpasslib[bcrypt]==1.7.4[m
[32m+[m
[32m+[m[32m# Database (optional)[m
[32m+[m[32msqlalchemy==2.0.23[m
[32m+[m[32malembic==1.13.1[m
[32m+[m
[32m+[m[32m# Caching[m
[32m+[m[32mredis==5.0.1[m
[32m+[m
[32m+[m[32m# File handling[m
[32m+[m[32maiofiles==23.2.1[m
[32m+[m
[32m+[m[32m# HTTP client[m
[32m+[m[32mhttpx==0.25.2[m
[32m+[m
[32m+[m[32m# Configuration management[m
[32m+[m[32mpython-dotenv==1.0.0[m
[32m+[m[32mpyyaml==6.0.1[m
[32m+[m
[32m+[m[32m# Image processing[m
[32m+[m[32mimageio==2.31.6[m
[32m+[m[32mscikit-image==0.21.0[m
[32m+[m
[32m+[m[32m# Utilities[m
[32m+[m[32mclick==8.1.7[m
[32m+[m[32mrich==13.7.0[m
[1mdiff --git a/scripts/setup.bat b/scripts/setup.bat[m
[1mnew file mode 100644[m
[1mindex 0000000..7c794f1[m
[1m--- /dev/null[m
[1m+++ b/scripts/setup.bat[m
[36m@@ -0,0 +1,240 @@[m
[32m+[m[32m@echo off[m
[32m+[m[32mREM OOTDiffusion Production Setup Script for Windows[m
[32m+[m
[32m+[m[32mecho 🚀 Setting up OOTDiffusion for production...[m
[32m+[m
[32m+[m[32mREM Check if Docker is installed[m
[32m+[m[32mdocker --version >nul 2>&1[m
[32m+[m[32mif %errorlevel% neq 0 ([m
[32m+[m[32m    echo [ERROR] Docker is not installed. Please install Docker Desktop first.[m
[32m+[m[32m    exit /b 1[m
[32m+[m[32m)[m
[32m+[m
[32m+[m[32mREM Check if Docker Compose is installed[m
[32m+[m[32mdocker-compose --version >nul 2>&1[m
[32m+[m[32mif %errorlevel% neq 0 ([m
[32m+[m[32m    echo [ERROR] Docker Compose is not installed. Please install Docker Compose first.[m
[32m+[m[32m    exit /b 1[m
[32m+[m[32m)[m
[32m+[m
[32m+[m[32mREM Create necessary directories[m
[32m+[m[32mecho [INFO] Creating necessary directories...[m
[32m+[m[32mif not exist "checkpoints" mkdir checkpoints[m
[32m+[m[32mif not exist "outputs\results" mkdir outputs\results[m
[32m+[m[32mif not exist "temp\uploads" mkdir temp\uploads[m
[32m+[m[32mif not exist "temp\processed" mkdir temp\processed[m
[32m+[m[32mif not exist "logs" mkdir logs[m
[32m+[m[32mif not exist "ssl" mkdir ssl[m
[32m+[m
[32m+[m[32mecho [INFO] Directories created successfully[m
[32m+[m
[32m+[m[32mREM Create environment file[m
[32m+[m[32mecho [INFO] Creating environment configuration...[m
[32m+[m[32m([m
[32m+[m[32mecho # OOTDiffusion Environment Configuration[m
[32m+[m[32mecho OOTD_ENVIRONMENT=production[m
[32m+[m[32mecho OOTD_DEBUG=false[m
[32m+[m[32mecho OOTD_HOST=0.0.0.0[m
[32m+[m[32mecho OOTD_PORT=7865[m
[32m+[m[32mecho OOTD_WORKERS=1[m
[32m+[m[32mecho OOTD_DEVICE=cuda:0[m
[32m+[m[32mecho.[m
[32m+[m[32mecho # Logging[m
[32m+[m[32mecho OOTD_LOG_LEVEL=INFO[m
[32m+[m[32mecho OOTD_LOG_FILE=logs/ootd.log[m
[32m+[m[32mecho.[m
[32m+[m[32mecho # File upload limits[m
[32m+[m[32mecho OOTD_MAX_FILE_SIZE=10485760[m
[32m+[m[32mecho OOTD_ALLOWED_EXTENSIONS=.jpg,.jpeg,.png,.bmp[m
[32m+[m[32mecho.[m
[32m+[m[32mecho # Security[m
[32m+[m[32mecho OOTD_SECRET_KEY=your-secret-key-here[m
[32m+[m[32mecho OOTD_ACCESS_TOKEN_EXPIRE_MINUTES=30[m
[32m+[m[32m) > .env[m
[32m+[m
[32m+[m[32mecho [INFO] Environment file created[m
[32m+[m
[32m+[m[32mREM Check for model checkpoints[m
[32m+[m[32mecho [INFO] Checking for model checkpoints...[m
[32m+[m
[32m+[m[32mif not exist "checkpoints\ootd" ([m
[32m+[m[32m    echo [WARNING] OOTD model checkpoints not found.[m
[32m+[m[32m    echo [WARNING] Please download them from: https://huggingface.co/levihsu/OOTDiffusion[m
[32m+[m[32m    echo [WARNING] Place them in the checkpoints\ directory[m
[32m+[m[32m)[m
[32m+[m
[32m+[m[32mif not exist "checkpoints\humanparsing" ([m
[32m+[m[32m    echo [WARNING] Human parsing model checkpoints not found.[m
[32m+[m[32m    echo [WARNING] Please download them from: https://huggingface.co/levihsu/OOTDiffusion[m
[32m+[m[32m    echo [WARNING] Place them in the checkpoints\ directory[m
[32m+[m[32m)[m
[32m+[m
[32m+[m[32mif not exist "checkpoints\openpose" ([m
[32m+[m[32m    echo [WARNING] OpenPose model checkpoints not found.[m
[32m+[m[32m    echo [WARNING] Please download them from: https://huggingface.co/levihsu/OOTDiffusion[m
[32m+[m[32m    echo [WARNING] Place them in the checkpoints\ directory[m
[32m+[m[32m)[m
[32m+[m
[32m+[m[32mif not exist "checkpoints\clip-vit-large-patch14" ([m
[32m+[m[32m    echo [WARNING] CLIP model checkpoints not found.[m
[32m+[m[32m    echo [WARNING] Please download them from: https://huggingface.co/openai/clip-vit-large-patch14[m
[32m+[m[32m    echo [WARNING] Place them in the checkpoints\ directory[m
[32m+[m[32m)[m
[32m+[m
[32m+[m[32mREM Create nginx configuration[m
[32m+[m[32mecho [INFO] Creating nginx configuration...[m
[32m+[m[32m([m
[32m+[m[32mecho events {[m
[32m+[m[32mecho     worker_connections 1024;[m
[32m+[m[32mecho }[m
[32m+[m[32mecho.[m
[32m+[m[32mecho http {[m
[32m+[m[32mecho     upstream ootd_backend {[m
[32m+[m[32mecho         server ootd-api:7865;[m
[32m+[m[32mecho     }[m
[32m+[m[32mecho.[m
[32m+[m[32mecho     # Rate limiting[m
[32m+[m[32mecho     limit_req_zone $binary_remote_addr zone=api:10m rate=10r/m;[m
[32m+[m[32mecho.[m
[32m+[m[32mecho     server {[m
[32m+[m[32mecho         listen 80;[m
[32m+[m[32mecho         server_name _;[m
[32m+[m[32mecho.[m
[32m+[m[32mecho         # Security headers[m
[32m+[m[32mecho         add_header X-Frame-Options DENY;[m
[32m+[m[32mecho         add_header X-Content-Type-Options nosniff;[m
[32m+[m[32mecho         add_header X-XSS-Protection "1; mode=block";[m
[32m+[m[32mecho.[m
[32m+[m[32mecho         # File upload size[m
[32m+[m[32mecho         client_max_body_size 50M;[m
[32m+[m[32mecho.[m
[32m+[m[32mecho         # API endpoints[m
[32m+[m[32mecho         location / {[m
[32m+[m[32mecho             limit_req zone=api burst=20 nodelay;[m
[32m+[m[32mecho             proxy_pass http://ootd_backend;[m
[32m+[m[32mecho             proxy_set_header Host $host;[m
[32m+[m[32mecho             proxy_set_header X-Real-IP $remote_addr;[m
[32m+[m[32mecho             proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;[m
[32m+[m[32mecho             proxy_set_header X-Forwarded-Proto $scheme;[m
[32m+[m[32mecho[m[41m             [m
[32m+[m[32mecho             # Timeouts[m
[32m+[m[32mecho             proxy_connect_timeout 60s;[m
[32m+[m[32mecho             proxy_send_timeout 60s;[m
[32m+[m[32mecho             proxy_read_timeout 300s;[m
[32m+[m[32mecho         }[m
[32m+[m[32mecho.[m
[32m+[m[32mecho         # Static files[m
[32m+[m[32mecho         location /static/ {[m
[32m+[m[32mecho             proxy_pass http://ootd_backend;[m
[32m+[m[32mecho             expires 1d;[m
[32m+[m[32mecho             add_header Cache-Control "public, immutable";[m
[32m+[m[32mecho         }[m
[32m+[m[32mecho     }[m
[32m+[m[32mecho }[m
[32m+[m[32m) > nginx.conf[m
[32m+[m
[32m+[m[32mecho [INFO] Nginx configuration created[m
[32m+[m
[32m+[m[32mREM Create monitoring script[m
[32m+[m[32mecho [INFO] Creating monitoring script...[m
[32m+[m[32m([m
[32m+[m[32mecho @echo off[m
[32m+[m[32mecho REM OOTDiffusion Monitoring Script[m
[32m+[m[32mecho.[m
[32m+[m[32mecho echo 🔍 Checking OOTDiffusion services...[m
[32m+[m[32mecho.[m
[32m+[m[32mecho REM Check containers[m
[32m+[m[32mecho docker ps --filter "name=ootdiffusion-ootd-api-1" --format "table {{.Names}}\t{{.Status}}"[m
[32m+[m[32mecho docker ps --filter "name=ootdiffusion-redis-1" --format "table {{.Names}}\t{{.Status}}" 2^>nul[m
[32m+[m[32mecho docker ps --filter "name=ootdiffusion-nginx-1" --format "table {{.Names}}\t{{.Status}}" 2^>nul[m
[32m+[m[32mecho.[m
[32m+[m[32mecho REM Check health endpoints[m
[32m+[m[32mecho curl -f -s http://localhost:7865/health ^>nul[m
[32m+[m[32mecho if %errorlevel% equ 0 ^([m
[32m+[m[32mecho     echo ✅ OOTD API health check passed[m
[32m+[m[32mecho ^) else ^([m
[32m+[m[32mecho     echo ❌ OOTD API health check failed[m
[32m+[m[32mecho ^)[m
[32m+[m[32mecho.[m
[32m+[m[32mecho echo 📊 System resources:[m
[32m+[m[32mecho wmic cpu get loadpercentage /value ^| find "LoadPercentage"[m
[32m+[m[32mecho wmic OS get TotalVisibleMemorySize,FreePhysicalMemory /value[m
[32m+[m[32mecho.[m
[32m+[m[32mecho echo 📈 GPU status:[m
[32m+[m[32mecho nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv,noheader,nounits 2^>nul ^|^| echo GPU not available[m
[32m+[m[32m) > scripts\monitor.bat[m
[32m+[m
[32m+[m[32mecho [INFO] Monitoring script created[m
[32m+[m
[32m+[m[32mREM Create backup script[m
[32m+[m[32mecho [INFO] Creating backup script...[m
[32m+[m[32m([m
[32m+[m[32mecho @echo off[m
[32m+[m[32mecho REM OOTDiffusion Backup Script[m
[32m+[m[32mecho.[m
[32m+[m[32mecho set BACKUP_DIR=backups\%date:~-4,4%%date:~-10,2%%date:~-7,2%_%time:~0,2%%time:~3,2%%time:~6,2%[m
[32m+[m[32mecho set BACKUP_DIR=%BACKUP_DIR: =0%[m
[32m+[m[32mecho mkdir %BACKUP_DIR%[m
[32m+[m[32mecho.[m
[32m+[m[32mecho echo 📦 Creating backup in %BACKUP_DIR%...[m
[32m+[m[32mecho.[m
[32m+[m[32mecho REM Backup configuration[m
[32m+[m[32mecho copy config.py %BACKUP_DIR%\[m
[32m+[m[32mecho copy .env %BACKUP_DIR%\[m
[32m+[m[32mecho copy docker-compose.yml %BACKUP_DIR%\[m
[32m+[m[32mecho copy nginx.conf %BACKUP_DIR%\[m
[32m+[m[32mecho.[m
[32m+[m[32mecho REM Backup outputs ^(if any^)[m
[32m+[m[32mecho if exist "outputs" ^([m
[32m+[m[32mecho     xcopy outputs %BACKUP_DIR%\outputs\ /E /I /Q[m
[32m+[m[32mecho ^)[m
[32m+[m[32mecho.[m
[32m+[m[32mecho REM Backup logs[m
[32m+[m[32mecho if exist "logs" ^([m
[32m+[m[32mecho     xcopy logs %BACKUP_DIR%\logs\ /E /I /Q[m
[32m+[m[32mecho ^)[m
[32m+[m[32mecho.[m
[32m+[m[32mecho echo ✅ Backup completed: %BACKUP_DIR%[m
[32m+[m[32m) > scripts\backup.bat[m
[32m+[m
[32m+[m[32mecho [INFO] Backup script created[m
[32m+[m
[32m+[m[32mREM Create update script[m
[32m+[m[32mecho [INFO] Creating update script...[m
[32m+[m[32m([m
[32m+[m[32mecho @echo off[m
[32m+[m[32mecho REM OOTDiffusion Update Script[m
[32m+[m[32mecho.[m
[32m+[m[32mecho echo 🔄 Updating OOTDiffusion...[m
[32m+[m[32mecho.[m
[32m+[m[32mecho REM Pull latest changes[m
[32m+[m[32mecho git pull origin main[m
[32m+[m[32mecho.[m
[32m+[m[32mecho REM Rebuild containers[m
[32m+[m[32mecho docker-compose build --no-cache[m
[32m+[m[32mecho.[m
[32m+[m[32mecho REM Restart services[m
[32m+[m[32mecho docker-compose down[m
[32m+[m[32mecho docker-compose up -d[m
[32m+[m[32mecho.[m
[32m+[m[32mecho echo ✅ Update completed[m
[32m+[m[32m) > scripts\update.bat[m
[32m+[m
[32m+[m[32mecho [INFO] Update script created[m
[32m+[m
[32m+[m[32mecho.[m
[32m+[m[32mecho 🎉 Setup completed successfully![m
[32m+[m[32mecho.[m
[32m+[m[32mecho Next steps:[m
[32m+[m[32mecho 1. Download model checkpoints to the checkpoints\ directory[m
[32m+[m[32mecho 2. Run: docker-compose up -d[m
[32m+[m[32mecho 3. Check status: scripts\monitor.bat[m
[32m+[m[32mecho 4. Access API at: http://localhost:7865[m
[32m+[m[32mecho.[m
[32m+[m[32mecho For development:[m
[32m+[m[32mecho 1. Run: docker-compose --profile dev up -d[m
[32m+[m[32mecho 2. Access dev API at: http://localhost:7866[m
[32m+[m[32mecho.[m
[32m+[m[32mecho For production with nginx:[m
[32m+[m[32mecho 1. Run: docker-compose --profile nginx up -d[m
[32m+[m[32mecho 2. Access via nginx at: http://localhost[m
[1mdiff --git a/scripts/setup.sh b/scripts/setup.sh[m
[1mnew file mode 100644[m
[1mindex 0000000..cb321e2[m
[1m--- /dev/null[m
[1m+++ b/scripts/setup.sh[m
[36m@@ -0,0 +1,326 @@[m
[32m+[m[32m#!/bin/bash[m
[32m+[m
[32m+[m[32m# OOTDiffusion Production Setup Script[m
[32m+[m[32mset -e[m
[32m+[m
[32m+[m[32mecho "🚀 Setting up OOTDiffusion for production..."[m
[32m+[m
[32m+[m[32m# Colors for output[m
[32m+[m[32mRED='\033[0;31m'[m
[32m+[m[32mGREEN='\033[0;32m'[m
[32m+[m[32mYELLOW='\033[1;33m'[m
[32m+[m[32mNC='\033[0m' # No Color[m
[32m+[m
[32m+[m[32m# Function to print colored output[m
[32m+[m[32mprint_status() {[m
[32m+[m[32m    echo -e "${GREEN}[INFO]${NC} $1"[m
[32m+[m[32m}[m
[32m+[m
[32m+[m[32mprint_warning() {[m
[32m+[m[32m    echo -e "${YELLOW}[WARNING]${NC} $1"[m
[32m+[m[32m}[m
[32m+[m
[32m+[m[32mprint_error() {[m
[32m+[m[32m    echo -e "${RED}[ERROR]${NC} $1"[m
[32m+[m[32m}[m
[32m+[m
[32m+[m[32m# Check if running as root[m
[32m+[m[32mif [[ $EUID -eq 0 ]]; then[m
[32m+[m[32m   print_error "This script should not be run as root"[m
[32m+[m[32m   exit 1[m
[32m+[m[32mfi[m
[32m+[m
[32m+[m[32m# Check if Docker is installed[m
[32m+[m[32mif ! command -v docker &> /dev/null; then[m
[32m+[m[32m    print_error "Docker is not installed. Please install Docker first."[m
[32m+[m[32m    exit 1[m
[32m+[m[32mfi[m
[32m+[m
[32m+[m[32m# Check if Docker Compose is installed[m
[32m+[m[32mif ! command -v docker-compose &> /dev/null; then[m
[32m+[m[32m    print_error "Docker Compose is not installed. Please install Docker Compose first."[m
[32m+[m[32m    exit 1[m
[32m+[m[32mfi[m
[32m+[m
[32m+[m[32m# Check if NVIDIA Docker is available[m
[32m+[m[32mif ! docker run --rm --gpus all nvidia/cuda:11.8-base-ubuntu22.04 nvidia-smi &> /dev/null; then[m
[32m+[m[32m    print_warning "NVIDIA Docker runtime not available. GPU acceleration will not work."[m
[32m+[m[32m    print_warning "Please install nvidia-docker2 for GPU support."[m
[32m+[m[32mfi[m
[32m+[m
[32m+[m[32m# Create necessary directories[m
[32m+[m[32mprint_status "Creating necessary directories..."[m
[32m+[m[32mmkdir -p checkpoints[m
[32m+[m[32mmkdir -p outputs/results[m
[32m+[m[32mmkdir -p temp/uploads[m
[32m+[m[32mmkdir -p temp/processed[m
[32m+[m[32mmkdir -p logs[m
[32m+[m[32mmkdir -p ssl[m
[32m+[m
[32m+[m[32m# Set proper permissions[m
[32m+[m[32mchmod 755 checkpoints outputs temp logs ssl[m
[32m+[m[32mchmod 755 outputs/results temp/uploads temp/processed[m
[32m+[m
[32m+[m[32mprint_status "Directories created successfully"[m
[32m+[m
[32m+[m[32m# Create environment file[m
[32m+[m[32mprint_status "Creating environment configuration..."[m
[32m+[m[32mcat > .env << EOF[m
[32m+[m[32m# OOTDiffusion Environment Configuration[m
[32m+[m[32mOOTD_ENVIRONMENT=production[m
[32m+[m[32mOOTD_DEBUG=false[m
[32m+[m[32mOOTD_HOST=0.0.0.0[m
[32m+[m[32mOOTD_PORT=7865[m
[32m+[m[32mOOTD_WORKERS=1[m
[32m+[m[32mOOTD_DEVICE=cuda:0[m
[32m+[m
[32m+[m[32m# Logging[m
[32m+[m[32mOOTD_LOG_LEVEL=INFO[m
[32m+[m[32mOOTD_LOG_FILE=logs/ootd.log[m
[32m+[m
[32m+[m[32m# File upload limits[m
[32m+[m[32mOOTD_MAX_FILE_SIZE=10485760[m
[32m+[m[32mOOTD_ALLOWED_EXTENSIONS=.jpg,.jpeg,.png,.bmp[m
[32m+[m
[32m+[m[32m# Security[m
[32m+[m[32mOOTD_SECRET_KEY=$(openssl rand -hex 32)[m
[32m+[m[32mOOTD_ACCESS_TOKEN_EXPIRE_MINUTES=30[m
[32m+[m[32mEOF[m
[32m+[m
[32m+[m[32mprint_status "Environment file created"[m
[32m+[m
[32m+[m[32m# Download model checkpoints if not present[m
[32m+[m[32mprint_status "Checking for model checkpoints..."[m
[32m+[m
[32m+[m[32mif [ ! -d "checkpoints/ootd" ]; then[m
[32m+[m[32m    print_warning "OOTD model checkpoints not found."[m
[32m+[m[32m    print_warning "Please download them from: https://huggingface.co/levihsu/OOTDiffusion"[m
[32m+[m[32m    print_warning "Place them in the checkpoints/ directory"[m
[32m+[m[32mfi[m
[32m+[m
[32m+[m[32mif [ ! -d "checkpoints/humanparsing" ]; then[m
[32m+[m[32m    print_warning "Human parsing model checkpoints not found."[m
[32m+[m[32m    print_warning "Please download them from: https://huggingface.co/levihsu/OOTDiffusion"[m
[32m+[m[32m    print_warning "Place them in the checkpoints/ directory"[m
[32m+[m[32mfi[m
[32m+[m
[32m+[m[32mif [ ! -d "checkpoints/openpose" ]; then[m
[32m+[m[32m    print_warning "OpenPose model checkpoints not found."[m
[32m+[m[32m    print_warning "Please download them from: https://huggingface.co/levihsu/OOTDiffusion"[m
[32m+[m[32m    print_warning "Place them in the checkpoints/ directory"[m
[32m+[m[32mfi[m
[32m+[m
[32m+[m[32mif [ ! -d "checkpoints/clip-vit-large-patch14" ]; then[m
[32m+[m[32m    print_warning "CLIP model checkpoints not found."[m
[32m+[m[32m    print_warning "Please download them from: https://huggingface.co/openai/clip-vit-large-patch14"[m
[32m+[m[32m    print_warning "Place them in the checkpoints/ directory"[m
[32m+[m[32mfi[m
[32m+[m
[32m+[m[32m# Create systemd service file[m
[32m+[m[32mprint_status "Creating systemd service..."[m
[32m+[m[32msudo tee /etc/systemd/system/ootd.service > /dev/null << EOF[m
[32m+[m[32m[Unit][m
[32m+[m[32mDescription=OOTDiffusion API Service[m
[32m+[m[32mAfter=docker.service[m
[32m+[m[32mRequires=docker.service[m
[32m+[m
[32m+[m[32m[Service][m
[32m+[m[32mType=oneshot[m
[32m+[m[32mRemainAfterExit=yes[m
[32m+[m[32mWorkingDirectory=$(pwd)[m
[32m+[m[32mExecStart=/usr/bin/docker-compose up -d[m
[32m+[m[32mExecStop=/usr/bin/docker-compose down[m
[32m+[m[32mTimeoutStartSec=0[m
[32m+[m
[32m+[m[32m[Install][m
[32m+[m[32mWantedBy=multi-user.target[m
[32m+[m[32mEOF[m
[32m+[m
[32m+[m[32mprint_status "Systemd service created"[m
[32m+[m
[32m+[m[32m# Create nginx configuration[m
[32m+[m[32mprint_status "Creating nginx configuration..."[m
[32m+[m[32mcat > nginx.conf << 'EOF'[m
[32m+[m[32mevents {[m
[32m+[m[32m    worker_connections 1024;[m
[32m+[m[32m}[m
[32m+[m
[32m+[m[32mhttp {[m
[32m+[m[32m    upstream ootd_backend {[m
[32m+[m[32m        server ootd-api:7865;[m
[32m+[m[32m    }[m
[32m+[m
[32m+[m[32m    # Rate limiting[m
[32m+[m[32m    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/m;[m
[32m+[m
[32m+[m[32m    server {[m
[32m+[m[32m        listen 80;[m
[32m+[m[32m        server_name _;[m
[32m+[m
[32m+[m[32m        # Security headers[m
[32m+[m[32m        add_header X-Frame-Options DENY;[m
[32m+[m[32m        add_header X-Content-Type-Options nosniff;[m
[32m+[m[32m        add_header X-XSS-Protection "1; mode=block";[m
[32m+[m
[32m+[m[32m        # File upload size[m
[32m+[m[32m        client_max_body_size 50M;[m
[32m+[m
[32m+[m[32m        # API endpoints[m
[32m+[m[32m        location / {[m
[32m+[m[32m            limit_req zone=api burst=20 nodelay;[m
[32m+[m[32m            proxy_pass http://ootd_backend;[m
[32m+[m[32m            proxy_set_header Host $host;[m
[32m+[m[32m            proxy_set_header X-Real-IP $remote_addr;[m
[32m+[m[32m            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;[m
[32m+[m[32m            proxy_set_header X-Forwarded-Proto $scheme;[m
[32m+[m[41m            [m
[32m+[m[32m            # Timeouts[m
[32m+[m[32m            proxy_connect_timeout 60s;[m
[32m+[m[32m            proxy_send_timeout 60s;[m
[32m+[m[32m            proxy_read_timeout 300s;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        # Static files[m
[32m+[m[32m        location /static/ {[m
[32m+[m[32m            proxy_pass http://ootd_backend;[m
[32m+[m[32m            expires 1d;[m
[32m+[m[32m            add_header Cache-Control "public, immutable";[m
[32m+[m[32m        }[m
[32m+[m[32m    }[m
[32m+[m[32m}[m
[32m+[m[32mEOF[m
[32m+[m
[32m+[m[32mprint_status "Nginx configuration created"[m
[32m+[m
[32m+[m[32m# Create monitoring script[m
[32m+[m[32mprint_status "Creating monitoring script..."[m
[32m+[m[32mcat > scripts/monitor.sh << 'EOF'[m
[32m+[m[32m#!/bin/bash[m
[32m+[m
[32m+[m[32m# OOTDiffusion Monitoring Script[m
[32m+[m
[32m+[m[32mcheck_service() {[m
[32m+[m[32m    local service_name=$1[m
[32m+[m[32m    local container_name=$2[m
[32m+[m[41m    [m
[32m+[m[32m    if docker ps | grep -q $container_name; then[m
[32m+[m[32m        echo "✅ $service_name is running"[m
[32m+[m[32m        return 0[m
[32m+[m[32m    else[m
[32m+[m[32m        echo "❌ $service_name is not running"[m
[32m+[m[32m        return 1[m
[32m+[m[32m    fi[m
[32m+[m[32m}[m
[32m+[m
[32m+[m[32mcheck_health() {[m
[32m+[m[32m    local url=$1[m
[32m+[m[32m    local service_name=$2[m
[32m+[m[41m    [m
[32m+[m[32m    if curl -f -s $url > /dev/null; then[m
[32m+[m[32m        echo "✅ $service_name health check passed"[m
[32m+[m[32m        return 0[m
[32m+[m[32m    else[m
[32m+[m[32m        echo "❌ $service_name health check failed"[m
[32m+[m[32m        return 1[m
[32m+[m[32m    fi[m
[32m+[m[32m}[m
[32m+[m
[32m+[m[32mecho "🔍 Checking OOTDiffusion services..."[m
[32m+[m
[32m+[m[32m# Check containers[m
[32m+[m[32mcheck_service "OOTD API" "ootdiffusion-ootd-api-1"[m
[32m+[m[32mcheck_service "Redis" "ootdiffusion-redis-1" 2>/dev/null || true[m
[32m+[m[32mcheck_service "Nginx" "ootdiffusion-nginx-1" 2>/dev/null || true[m
[32m+[m
[32m+[m[32m# Check health endpoints[m
[32m+[m[32mcheck_health "http://localhost:7865/health" "OOTD API"[m
[32m+[m
[32m+[m[32mecho "📊 System resources:"[m
[32m+[m[32mecho "CPU usage: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1)%"[m
[32m+[m[32mecho "Memory usage: $(free | grep Mem | awk '{printf "%.1f%%", $3/$2 * 100.0}')"[m
[32m+[m[32mecho "Disk usage: $(df -h / | awk 'NR==2{printf "%s", $5}')"[m
[32m+[m
[32m+[m[32mecho "📈 GPU status:"[m
[32m+[m[32mnvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv,noheader,nounits 2>/dev/null || echo "GPU not available"[m
[32m+[m[32mEOF[m
[32m+[m
[32m+[m[32mchmod +x scripts/monitor.sh[m
[32m+[m
[32m+[m[32mprint_status "Monitoring script created"[m
[32m+[m
[32m+[m[32m# Create backup script[m
[32m+[m[32mprint_status "Creating backup script..."[m
[32m+[m[32mcat > scripts/backup.sh << 'EOF'[m
[32m+[m[32m#!/bin/bash[m
[32m+[m
[32m+[m[32m# OOTDiffusion Backup Script[m
[32m+[m
[32m+[m[32mBACKUP_DIR="backups/$(date +%Y%m%d_%H%M%S)"[m
[32m+[m[32mmkdir -p $BACKUP_DIR[m
[32m+[m
[32m+[m[32mecho "📦 Creating backup in $BACKUP_DIR..."[m
[32m+[m
[32m+[m[32m# Backup configuration[m
[32m+[m[32mcp -r config.py $BACKUP_DIR/[m
[32m+[m[32mcp -r .env $BACKUP_DIR/[m
[32m+[m[32mcp -r docker-compose.yml $BACKUP_DIR/[m
[32m+[m[32mcp -r nginx.conf $BACKUP_DIR/[m
[32m+[m
[32m+[m[32m# Backup outputs (if any)[m
[32m+[m[32mif [ -d "outputs" ] && [ "$(ls -A outputs)" ]; then[m
[32m+[m[32m    cp -r outputs $BACKUP_DIR/[m
[32m+[m[32mfi[m
[32m+[m
[32m+[m[32m# Backup logs[m
[32m+[m[32mif [ -d "logs" ] && [ "$(ls -A logs)" ]; then[m
[32m+[m[32m    cp -r logs $BACKUP_DIR/[m
[32m+[m[32mfi[m
[32m+[m
[32m+[m[32mecho "✅ Backup completed: $BACKUP_DIR"[m
[32m+[m[32mEOF[m
[32m+[m
[32m+[m[32mchmod +x scripts/backup.sh[m
[32m+[m
[32m+[m[32mprint_status "Backup script created"[m
[32m+[m
[32m+[m[32m# Create update script[m
[32m+[m[32mprint_status "Creating update script..."[m
[32m+[m[32mcat > scripts/update.sh << 'EOF'[m
[32m+[m[32m#!/bin/bash[m
[32m+[m
[32m+[m[32m# OOTDiffusion Update Script[m
[32m+[m
[32m+[m[32mecho "🔄 Updating OOTDiffusion..."[m
[32m+[m
[32m+[m[32m# Pull latest changes[m
[32m+[m[32mgit pull origin main[m
[32m+[m
[32m+[m[32m# Rebuild containers[m
[32m+[m[32mdocker-compose build --no-cache[m
[32m+[m
[32m+[m[32m# Restart services[m
[32m+[m[32mdocker-compose down[m
[32m+[m[32mdocker-compose up -d[m
[32m+[m
[32m+[m[32mecho "✅ Update completed"[m
[32m+[m[32mEOF[m
[32m+[m
[32m+[m[32mchmod +x scripts/update.sh[m
[32m+[m
[32m+[m[32mprint_status "Update script created"[m
[32m+[m
[32m+[m[32mprint_status "🎉 Setup completed successfully!"[m
[32m+[m[32mprint_status ""[m
[32m+[m[32mprint_status "Next steps:"[m
[32m+[m[32mprint_status "1. Download model checkpoints to the checkpoints/ directory"[m
[32m+[m[32mprint_status "2. Run: docker-compose up -d"[m
[32m+[m[32mprint_status "3. Check status: ./scripts/monitor.sh"[m
[32m+[m[32mprint_status "4. Access API at: http://localhost:7865"[m
[32m+[m[32mprint_status ""[m
[32m+[m[32mprint_status "For development:"[m
[32m+[m[32mprint_status "1. Run: docker-compose --profile dev up -d"[m
[32m+[m[32mprint_status "2. Access dev API at: http://localhost:7866"[m
[32m+[m[32mprint_status ""[m
[32m+[m[32mprint_status "For production with nginx:"[m
[32m+[m[32mprint_status "1. Run: docker-compose --profile nginx up -d"[m
[32m+[m[32mprint_status "2. Access via nginx at: http://localhost"[m
[1mdiff --git a/start.py b/start.py[m
[1mnew file mode 100644[m
[1mindex 0000000..309c458[m
[1m--- /dev/null[m
[1m+++ b/start.py[m
[36m@@ -0,0 +1,121 @@[m
[32m+[m[32m#!/usr/bin/env python3[m
[32m+[m[32m"""[m
[32m+[m[32mOOTDiffusion Production Startup Script[m
[32m+[m[32m"""[m
[32m+[m[32mimport os[m
[32m+[m[32mimport sys[m
[32m+[m[32mimport argparse[m
[32m+[m[32mfrom pathlib import Path[m
[32m+[m
[32m+[m[32m# Add project root to path[m
[32m+[m[32mPROJECT_ROOT = Path(__file__).absolute().parent[m
[32m+[m[32msys.path.insert(0, str(PROJECT_ROOT))[m
[32m+[m
[32m+[m[32mdef main():[m
[32m+[m[32m    """Main startup function"""[m
[32m+[m[32m    parser = argparse.ArgumentParser(description="Start OOTDiffusion in different modes")[m
[32m+[m[32m    parser.add_argument([m
[32m+[m[32m        "--mode",[m[41m [m
[32m+[m[32m        choices=["api", "gradio", "test"],[m[41m [m
[32m+[m[32m        default="api",[m
[32m+[m[32m        help="Startup mode (default: api)"[m
[32m+[m[32m    )[m
[32m+[m[32m    parser.add_argument([m
[32m+[m[32m        "--environment",[m
[32m+[m[32m        choices=["development", "testing", "production"],[m
[32m+[m[32m        default="production",[m
[32m+[m[32m        help="Environment mode (default: production)"[m
[32m+[m[32m    )[m
[32m+[m[32m    parser.add_argument([m
[32m+[m[32m        "--host",[m
[32m+[m[32m        default="0.0.0.0",[m
[32m+[m[32m        help="Host to bind to (default: 0.0.0.0)"[m
[32m+[m[32m    )[m
[32m+[m[32m    parser.add_argument([m
[32m+[m[32m        "--port",[m
[32m+[m[32m        type=int,[m
[32m+[m[32m        default=7865,[m
[32m+[m[32m        help="Port to bind to (default: 7865)"[m
[32m+[m[32m    )[m
[32m+[m[32m    parser.add_argument([m
[32m+[m[32m        "--workers",[m
[32m+[m[32m        type=int,[m
[32m+[m[32m        default=1,[m
[32m+[m[32m        help="Number of workers (default: 1)"[m
[32m+[m[32m    )[m
[32m+[m[41m    [m
[32m+[m[32m    args = parser.parse_args()[m
[32m+[m[41m    [m
[32m+[m[32m    # Set environment variables[m
[32m+[m[32m    os.environ["OOTD_ENVIRONMENT"] = args.environment[m
[32m+[m[32m    os.environ["OOTD_HOST"] = args.host[m
[32m+[m[32m    os.environ["OOTD_PORT"] = str(args.port)[m
[32m+[m[32m    os.environ["OOTD_WORKERS"] = str(args.workers)[m
[32m+[m[41m    [m
[32m+[m[32m    if args.mode == "api":[m
[32m+[m[32m        start_api()[m
[32m+[m[32m    elif args.mode == "gradio":[m
[32m+[m[32m        start_gradio()[m
[32m+[m[32m    elif args.mode == "test":[m
[32m+[m[32m        start_tests()[m
[32m+[m
[32m+[m[32mdef start_api():[m
[32m+[m[32m    """Start FastAPI server"""[m
[32m+[m[32m    print("🚀 Starting OOTDiffusion API server...")[m
[32m+[m[41m    [m
[32m+[m[32m    try:[m
[32m+[m[32m        import uvicorn[m
[32m+[m[32m        from api.app import app[m
[32m+[m[32m        from config import config[m
[32m+[m[41m        [m
[32m+[m[32m        uvicorn.run([m
[32m+[m[32m            app,[m
[32m+[m[32m            host=config.server.host,[m
[32m+[m[32m            port=config.server.port,[m
[32m+[m[32m            workers=config.server.workers,[m
[32m+[m[32m            log_level=config.logging.level.lower()[m
[32m+[m[32m        )[m
[32m+[m[32m    except ImportError as e:[m
[32m+[m[32m        print(f"❌ Error: {e}")[m
[32m+[m[32m        print("Please install production dependencies: pip install -r requirements-prod.txt")[m
[32m+[m[32m        sys.exit(1)[m
[32m+[m[32m    except Exception as e:[m
[32m+[m[32m        print(f"❌ Error starting API: {e}")[m
[32m+[m[32m        sys.exit(1)[m
[32m+[m
[32m+[m[32mdef start_gradio():[m
[32m+[m[32m    """Start Gradio interface (legacy)"""[m
[32m+[m[32m    print("🚀 Starting OOTDiffusion Gradio interface...")[m
[32m+[m[41m    [m
[32m+[m[32m    try:[m
[32m+[m[32m        import subprocess[m
[32m+[m[32m        subprocess.run([[m
[32m+[m[32m            sys.executable,[m[41m [m
[32m+[m[32m            "run/gradio_ootd.py"[m
[32m+[m[32m        ], check=True)[m
[32m+[m[32m    except subprocess.CalledProcessError as e:[m
[32m+[m[32m        print(f"❌ Error starting Gradio: {e}")[m
[32m+[m[32m        sys.exit(1)[m
[32m+[m[32m    except Exception as e:[m
[32m+[m[32m        print(f"❌ Error: {e}")[m
[32m+[m[32m        sys.exit(1)[m
[32m+[m
[32m+[m[32mdef start_tests():[m
[32m+[m[32m    """Run test suite"""[m
[32m+[m[32m    print("🧪 Running OOTDiffusion test suite...")[m
[32m+[m[41m    [m
[32m+[m[32m    try:[m
[32m+[m[32m        import subprocess[m
[32m+[m[32m        subprocess.run([[m
[32m+[m[32m            sys.executable, "-m", "pytest",[m[41m [m
[32m+[m[32m            "tests/", "-v", "--tb=short"[m
[32m+[m[32m        ], check=True)[m
[32m+[m[32m    except subprocess.CalledProcessError as e:[m
[32m+[m[32m        print(f"❌ Tests failed: {e}")[m
[32m+[m[32m        sys.exit(1)[m
[32m+[m[32m    except Exception as e:[m
[32m+[m[32m        print(f"❌ Error running tests: {e}")[m
[32m+[m[32m        sys.exit(1)[m
[32m+[m
[32m+[m[32mif __name__ == "__main__":[m
[32m+[m[32m    main()[m
[1mdiff --git a/test_interface.html b/test_interface.html[m
[1mnew file mode 100644[m
[1mindex 0000000..ef1d916[m
[1m--- /dev/null[m
[1m+++ b/test_interface.html[m
[36m@@ -0,0 +1,716 @@[m
[32m+[m[32m<!DOCTYPE html>[m
[32m+[m[32m<html lang="en">[m
[32m+[m[32m<head>[m
[32m+[m[32m    <meta charset="UTF-8">[m
[32m+[m[32m    <meta name="viewport" content="width=device-width, initial-scale=1.0">[m
[32m+[m[32m    <title>OOTDiffusion Test Interface</title>[m
[32m+[m[32m    <style>[m
[32m+[m[32m        * {[m
[32m+[m[32m            margin: 0;[m
[32m+[m[32m            padding: 0;[m
[32m+[m[32m            box-sizing: border-box;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        body {[m
[32m+[m[32m            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;[m
[32m+[m[32m            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);[m
[32m+[m[32m            min-height: 100vh;[m
[32m+[m[32m            padding: 20px;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .container {[m
[32m+[m[32m            max-width: 1200px;[m
[32m+[m[32m            margin: 0 auto;[m
[32m+[m[32m            background: white;[m
[32m+[m[32m            border-radius: 15px;[m
[32m+[m[32m            box-shadow: 0 20px 40px rgba(0,0,0,0.1);[m
[32m+[m[32m            overflow: hidden;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .header {[m
[32m+[m[32m            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);[m
[32m+[m[32m            color: white;[m
[32m+[m[32m            padding: 30px;[m
[32m+[m[32m            text-align: center;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .header h1 {[m
[32m+[m[32m            font-size: 2.5em;[m
[32m+[m[32m            margin-bottom: 10px;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .header p {[m
[32m+[m[32m            font-size: 1.2em;[m
[32m+[m[32m            opacity: 0.9;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .content {[m
[32m+[m[32m            padding: 30px;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .section {[m
[32m+[m[32m            margin-bottom: 30px;[m
[32m+[m[32m            padding: 20px;[m
[32m+[m[32m            border: 1px solid #e0e0e0;[m
[32m+[m[32m            border-radius: 10px;[m
[32m+[m[32m            background: #f9f9f9;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .section h2 {[m
[32m+[m[32m            color: #333;[m
[32m+[m[32m            margin-bottom: 15px;[m
[32m+[m[32m            font-size: 1.5em;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .form-group {[m
[32m+[m[32m            margin-bottom: 15px;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .form-group label {[m
[32m+[m[32m            display: block;[m
[32m+[m[32m            margin-bottom: 5px;[m
[32m+[m[32m            font-weight: 600;[m
[32m+[m[32m            color: #555;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .form-group input, .form-group select {[m
[32m+[m[32m            width: 100%;[m
[32m+[m[32m            padding: 10px;[m
[32m+[m[32m            border: 1px solid #ddd;[m
[32m+[m[32m            border-radius: 5px;[m
[32m+[m[32m            font-size: 14px;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .file-input {[m
[32m+[m[32m            position: relative;[m
[32m+[m[32m            display: inline-block;[m
[32m+[m[32m            width: 100%;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .file-input input[type="file"] {[m
[32m+[m[32m            position: absolute;[m
[32m+[m[32m            opacity: 0;[m
[32m+[m[32m            width: 100%;[m
[32m+[m[32m            height: 100%;[m
[32m+[m[32m            cursor: pointer;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .file-input-label {[m
[32m+[m[32m            display: block;[m
[32m+[m[32m            padding: 15px;[m
[32m+[m[32m            border: 2px dashed #667eea;[m
[32m+[m[32m            border-radius: 10px;[m
[32m+[m[32m            text-align: center;[m
[32m+[m[32m            cursor: pointer;[m
[32m+[m[32m            transition: all 0.3s ease;[m
[32m+[m[32m            background: #f8f9ff;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .file-input-label:hover {[m
[32m+[m[32m            background: #e8f0ff;[m
[32m+[m[32m            border-color: #5a6fd8;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .file-input-label.has-file {[m
[32m+[m[32m            background: #e8f5e8;[m
[32m+[m[32m            border-color: #4caf50;[m
[32m+[m[32m            color: #2e7d32;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .btn {[m
[32m+[m[32m            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);[m
[32m+[m[32m            color: white;[m
[32m+[m[32m            border: none;[m
[32m+[m[32m            padding: 12px 25px;[m
[32m+[m[32m            border-radius: 25px;[m
[32m+[m[32m            cursor: pointer;[m
[32m+[m[32m            font-size: 16px;[m
[32m+[m[32m            font-weight: 600;[m
[32m+[m[32m            transition: all 0.3s ease;[m
[32m+[m[32m            margin: 5px;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .btn:hover {[m
[32m+[m[32m            transform: translateY(-2px);[m
[32m+[m[32m            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .btn:disabled {[m
[32m+[m[32m            background: #ccc;[m
[32m+[m[32m            cursor: not-allowed;[m
[32m+[m[32m            transform: none;[m
[32m+[m[32m            box-shadow: none;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .btn-secondary {[m
[32m+[m[32m            background: #6c757d;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .btn-success {[m
[32m+[m[32m            background: #28a745;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .btn-danger {[m
[32m+[m[32m            background: #dc3545;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .status {[m
[32m+[m[32m            padding: 15px;[m
[32m+[m[32m            border-radius: 5px;[m
[32m+[m[32m            margin: 10px 0;[m
[32m+[m[32m            font-weight: 600;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .status.success {[m
[32m+[m[32m            background: #d4edda;[m
[32m+[m[32m            color: #155724;[m
[32m+[m[32m            border: 1px solid #c3e6cb;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .status.error {[m
[32m+[m[32m            background: #f8d7da;[m
[32m+[m[32m            color: #721c24;[m
[32m+[m[32m            border: 1px solid #f5c6cb;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .status.info {[m
[32m+[m[32m            background: #d1ecf1;[m
[32m+[m[32m            color: #0c5460;[m
[32m+[m[32m            border: 1px solid #bee5eb;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .status.warning {[m
[32m+[m[32m            background: #fff3cd;[m
[32m+[m[32m            color: #856404;[m
[32m+[m[32m            border: 1px solid #ffeaa7;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .results {[m
[32m+[m[32m            display: grid;[m
[32m+[m[32m            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));[m
[32m+[m[32m            gap: 20px;[m
[32m+[m[32m            margin-top: 20px;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .result-item {[m
[32m+[m[32m            border: 1px solid #ddd;[m
[32m+[m[32m            border-radius: 10px;[m
[32m+[m[32m            overflow: hidden;[m
[32m+[m[32m            background: white;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .result-item img {[m
[32m+[m[32m            width: 100%;[m
[32m+[m[32m            height: 300px;[m
[32m+[m[32m            object-fit: cover;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .result-item .info {[m
[32m+[m[32m            padding: 15px;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .loading {[m
[32m+[m[32m            display: none;[m
[32m+[m[32m            text-align: center;[m
[32m+[m[32m            padding: 20px;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .spinner {[m
[32m+[m[32m            border: 4px solid #f3f3f3;[m
[32m+[m[32m            border-top: 4px solid #667eea;[m
[32m+[m[32m            border-radius: 50%;[m
[32m+[m[32m            width: 40px;[m
[32m+[m[32m            height: 40px;[m
[32m+[m[32m            animation: spin 1s linear infinite;[m
[32m+[m[32m            margin: 0 auto 10px;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        @keyframes spin {[m
[32m+[m[32m            0% { transform: rotate(0deg); }[m
[32m+[m[32m            100% { transform: rotate(360deg); }[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .config-section {[m
[32m+[m[32m            background: #f8f9fa;[m
[32m+[m[32m            border-left: 4px solid #667eea;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .api-info {[m
[32m+[m[32m            background: #e3f2fd;[m
[32m+[m[32m            border-left: 4px solid #2196f3;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .two-column {[m
[32m+[m[32m            display: grid;[m
[32m+[m[32m            grid-template-columns: 1fr 1fr;[m
[32m+[m[32m            gap: 20px;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        @media (max-width: 768px) {[m
[32m+[m[32m            .two-column {[m
[32m+[m[32m                grid-template-columns: 1fr;[m
[32m+[m[32m            }[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .progress-bar {[m
[32m+[m[32m            width: 100%;[m
[32m+[m[32m            height: 20px;[m
[32m+[m[32m            background: #f0f0f0;[m
[32m+[m[32m            border-radius: 10px;[m
[32m+[m[32m            overflow: hidden;[m
[32m+[m[32m            margin: 10px 0;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        .progress-fill {[m
[32m+[m[32m            height: 100%;[m
[32m+[m[32m            background: linear-gradient(90deg, #667eea, #764ba2);[m
[32m+[m[32m            width: 0%;[m
[32m+[m[32m            transition: width 0.3s ease;[m
[32m+[m[32m        }[m
[32m+[m[32m    </style>[m
[32m+[m[32m</head>[m
[32m+[m[32m<body>[m
[32m+[m[32m    <div class="container">[m
[32m+[m[32m        <div class="header">[m
[32m+[m[32m            <h1>🎭 OOTDiffusion Test Interface</h1>[m
[32m+[m[32m            <p>Test all functionalities of your production-ready OOTDiffusion API</p>[m
[32m+[m[32m        </div>[m
[32m+[m
[32m+[m[32m        <div class="content">[m
[32m+[m[32m            <!-- API Configuration Section -->[m
[32m+[m[32m            <div class="section api-info">[m
[32m+[m[32m                <h2>🔧 API Configuration</h2>[m
[32m+[m[32m                <div class="two-column">[m
[32m+[m[32m                    <div class="form-group">[m
[32m+[m[32m                        <label for="apiUrl">API Base URL:</label>[m
[32m+[m[32m                        <input type="text" id="apiUrl" value="http://localhost:7865" placeholder="http://localhost:7865">[m
[32m+[m[32m                    </div>[m
[32m+[m[32m                    <div class="form-group">[m
[32m+[m[32m                        <button class="btn" onclick="testConnection()">Test Connection</button>[m
[32m+[m[32m                        <button class="btn btn-secondary" onclick="checkHealth()">Health Check</button>[m
[32m+[m[32m                    </div>[m
[32m+[m[32m                </div>[m
[32m+[m[32m                <div id="connectionStatus"></div>[m
[32m+[m[32m            </div>[m
[32m+[m
[32m+[m[32m            <!-- Image Processing Section -->[m
[32m+[m[32m            <div class="section">[m
[32m+[m[32m                <h2>🖼️ Image Processing Test</h2>[m
[32m+[m[32m                <div class="two-column">[m
[32m+[m[32m                    <div class="form-group">[m
[32m+[m[32m                        <label>Model Image:</label>[m
[32m+[m[32m                        <div class="file-input">[m
[32m+[m[32m                            <input type="file" id="modelFile" accept="image/*" onchange="handleFileSelect('modelFile', 'modelPreview')">[m
[32m+[m[32m                            <label for="modelFile" class="file-input-label" id="modelLabel">[m
[32m+[m[32m                                📁 Click to select model image[m
[32m+[m[32m                            </label>[m
[32m+[m[32m                        </div>[m
[32m+[m[32m                        <div id="modelPreview" style="margin-top: 10px;"></div>[m
[32m+[m[32m                    </div>[m
[32m+[m[32m                    <div class="form-group">[m
[32m+[m[32m                        <label>Cloth Image:</label>[m
[32m+[m[32m                        <div class="file-input">[m
[32m+[m[32m                            <input type="file" id="clothFile" accept="image/*" onchange="handleFileSelect('clothFile', 'clothPreview')">[m
[32m+[m[32m                            <label for="clothFile" class="file-input-label" id="clothLabel">[m
[32m+[m[32m                                👕 Click to select cloth image[m
[32m+[m[32m                            </label>[m
[32m+[m[32m                        </div>[m
[32m+[m[32m                        <div id="clothPreview" style="margin-top: 10px;"></div>[m
[32m+[m[32m                    </div>[m
[32m+[m[32m                </div>[m
[32m+[m
[32m+[m[32m                <div class="two-column">[m
[32m+[m[32m                    <div class="form-group">[m
[32m+[m[32m                        <label for="modelType">Model Type:</label>[m
[32m+[m[32m                        <select id="modelType" onchange="updateCategoryOptions()">[m
[32m+[m[32m                            <option value="hd">Half-body (HD)</option>[m
[32m+[m[32m                            <option value="dc">Full-body (DC)</option>[m
[32m+[m[32m                        </select>[m
[32m+[m[32m                    </div>[m
[32m+[m[32m                    <div class="form-group">[m
[32m+[m[32m                        <label for="category">Garment Category:</label>[m
[32m+[m[32m                        <select id="category">[m
[32m+[m[32m                            <option value="0">Upper-body</option>[m
[32m+[m[32m                            <option value="1">Lower-body</option>[m
[32m+[m[32m                            <option value="2">Dress</option>[m
[32m+[m[32m                        </select>[m
[32m+[m[32m                    </div>[m
[32m+[m[32m                </div>[m
[32m+[m
[32m+[m[32m                <div class="two-column">[m
[32m+[m[32m                    <div class="form-group">[m
[32m+[m[32m                        <label for="samples">Number of Samples:</label>[m
[32m+[m[32m                        <input type="number" id="samples" value="1" min="1" max="4">[m
[32m+[m[32m                    </div>[m
[32m+[m[32m                    <div class="form-group">[m
[32m+[m[32m                        <label for="steps">Inference Steps:</label>[m
[32m+[m[32m                        <input type="number" id="steps" value="20" min="1" max="40">[m
[32m+[m[32m                    </div>[m
[32m+[m[32m                </div>[m
[32m+[m
[32m+[m[32m                <div class="two-column">[m
[32m+[m[32m                    <div class="form-group">[m
[32m+[m[32m                        <label for="scale">Guidance Scale:</label>[m
[32m+[m[32m                        <input type="number" id="scale" value="2.0" min="1.0" max="5.0" step="0.1">[m
[32m+[m[32m                    </div>[m
[32m+[m[32m                    <div class="form-group">[m
[32m+[m[32m                        <label for="seed">Random Seed:</label>[m
[32m+[m[32m                        <input type="number" id="seed" value="-1" min="-1" max="2147483647">[m
[32m+[m[32m                    </div>[m
[32m+[m[32m                </div>[m
[32m+[m
[32m+[m[32m                <div style="text-align: center; margin-top: 20px;">[m
[32m+[m[32m                    <button class="btn btn-success" onclick="processImages()" id="processBtn">[m
[32m+[m[32m                        🚀 Process Images[m
[32m+[m[32m                    </button>[m
[32m+[m[32m                    <button class="btn btn-secondary" onclick="clearResults()">[m
[32m+[m[32m                        🗑️ Clear Results[m
[32m+[m[32m                    </button>[m
[32m+[m[32m                </div>[m
[32m+[m
[32m+[m[32m                <div class="loading" id="loading">[m
[32m+[m[32m                    <div class="spinner"></div>[m
[32m+[m[32m                    <p>Processing images... This may take a few minutes.</p>[m
[32m+[m[32m                    <div class="progress-bar">[m
[32m+[m[32m                        <div class="progress-fill" id="progressFill"></div>[m
[32m+[m[32m                    </div>[m
[32m+[m[32m                </div>[m
[32m+[m
[32m+[m[32m                <div id="processStatus"></div>[m
[32m+[m[32m                <div id="results" class="results"></div>[m
[32m+[m[32m            </div>[m
[32m+[m
[32m+[m[32m            <!-- API Testing Section -->[m
[32m+[m[32m            <div class="section config-section">[m
[32m+[m[32m                <h2>🧪 API Testing</h2>[m
[32m+[m[32m                <div class="two-column">[m
[32m+[m[32m                    <div>[m
[32m+[m[32m                        <h3>Quick Tests</h3>[m
[32m+[m[32m                        <button class="btn" onclick="testRootEndpoint()">Test Root Endpoint</button>[m
[32m+[m[32m                        <button class="btn" onclick="testHealthEndpoint()">Test Health Endpoint</button>[m
[32m+[m[32m                        <button class="btn" onclick="testDocsEndpoint()">Test Docs Endpoint</button>[m
[32m+[m[32m                    </div>[m
[32m+[m[32m                    <div>[m
[32m+[m[32m                        <h3>Error Testing</h3>[m
[32m+[m[32m                        <button class="btn btn-danger" onclick="testInvalidFile()">Test Invalid File</button>[m
[32m+[m[32m                        <button class="btn btn-danger" onclick="testMissingFiles()">Test Missing Files</button>[m
[32m+[m[32m                        <button class="btn btn-danger" onclick="testLargeFile()">Test Large File</button>[m
[32m+[m[32m                    </div>[m
[32m+[m[32m                </div>[m
[32m+[m[32m                <div id="testResults"></div>[m
[32m+[m[32m            </div>[m
[32m+[m
[32m+[m[32m            <!-- System Information -->[m
[32m+[m[32m            <div class="section">[m
[32m+[m[32m                <h2>📊 System Information</h2>[m
[32m+[m[32m                <div id="systemInfo">[m
[32m+[m[32m                    <p>Click "Check Health" to get system information</p>[m
[32m+[m[32m                </div>[m
[32m+[m[32m            </div>[m
[32m+[m[32m        </div>[m
[32m+[m[32m    </div>[m
[32m+[m
[32m+[m[32m    <script>[m
[32m+[m[32m        let selectedFiles = {[m
[32m+[m[32m            model: null,[m
[32m+[m[32m            cloth: null[m
[32m+[m[32m        };[m
[32m+[m
[32m+[m[32m        // Handle file selection[m
[32m+[m[32m        function handleFileSelect(inputId, previewId) {[m
[32m+[m[32m            const input = document.getElementById(inputId);[m
[32m+[m[32m            const label = document.getElementById(inputId.replace('File', 'Label'));[m
[32m+[m[32m            const preview = document.getElementById(previewId);[m
[32m+[m[41m            [m
[32m+[m[32m            if (input.files && input.files[0]) {[m
[32m+[m[32m                const file = input.files[0];[m
[32m+[m[32m                selectedFiles[inputId.replace('File', '')] = file;[m
[32m+[m[41m                [m
[32m+[m[32m                // Update label[m
[32m+[m[32m                label.textContent = `✅ ${file.name}`;[m
[32m+[m[32m                label.classList.add('has-file');[m
[32m+[m[41m                [m
[32m+[m[32m                // Show preview[m
[32m+[m[32m                const reader = new FileReader();[m
[32m+[m[32m                reader.onload = function(e) {[m
[32m+[m[32m                    preview.innerHTML = `<img src="${e.target.result}" style="max-width: 200px; max-height: 200px; border-radius: 5px;">`;[m
[32m+[m[32m                };[m
[32m+[m[32m                reader.readAsDataURL(file);[m
[32m+[m[32m            }[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        // Update category options based on model type[m
[32m+[m[32m        function updateCategoryOptions() {[m
[32m+[m[32m            const modelType = document.getElementById('modelType').value;[m
[32m+[m[32m            const categorySelect = document.getElementById('category');[m
[32m+[m[41m            [m
[32m+[m[32m            if (modelType === 'hd') {[m
[32m+[m[32m                categorySelect.innerHTML = '<option value="0">Upper-body</option>';[m
[32m+[m[32m            } else {[m
[32m+[m[32m                categorySelect.innerHTML = `[m
[32m+[m[32m                    <option value="0">Upper-body</option>[m
[32m+[m[32m                    <option value="1">Lower-body</option>[m
[32m+[m[32m                    <option value="2">Dress</option>[m
[32m+[m[32m                `;[m
[32m+[m[32m            }[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        // Test API connection[m
[32m+[m[32m        async function testConnection() {[m
[32m+[m[32m            const apiUrl = document.getElementById('apiUrl').value;[m
[32m+[m[32m            const statusDiv = document.getElementById('connectionStatus');[m
[32m+[m[41m            [m
[32m+[m[32m            try {[m
[32m+[m[32m                const response = await fetch(`${apiUrl}/health`);[m
[32m+[m[32m                if (response.ok) {[m
[32m+[m[32m                    const data = await response.json();[m
[32m+[m[32m                    statusDiv.innerHTML = `[m
[32m+[m[32m                        <div class="status success">[m
[32m+[m[32m                            ✅ Connected successfully!<br>[m
[32m+[m[32m                            Status: ${data.status}<br>[m
[32m+[m[32m                            Version: ${data.version}<br>[m
[32m+[m[32m                            Environment: ${data.environment}[m
[32m+[m[32m                        </div>[m
[32m+[m[32m                    `;[m
[32m+[m[32m                } else {[m
[32m+[m[32m                    throw new Error(`HTTP ${response.status}`);[m
[32m+[m[32m                }[m
[32m+[m[32m            } catch (error) {[m
[32m+[m[32m                statusDiv.innerHTML = `[m
[32m+[m[32m                    <div class="status error">[m
[32m+[m[32m                        ❌ Connection failed: ${error.message}<br>[m
[32m+[m[32m                        Make sure the API is running on ${apiUrl}[m
[32m+[m[32m                    </div>[m
[32m+[m[32m                `;[m
[32m+[m[32m            }[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        // Check health endpoint[m
[32m+[m[32m        async function checkHealth() {[m
[32m+[m[32m            const apiUrl = document.getElementById('apiUrl').value;[m
[32m+[m[32m            const systemInfo = document.getElementById('systemInfo');[m
[32m+[m[41m            [m
[32m+[m[32m            try {[m
[32m+[m[32m                const response = await fetch(`${apiUrl}/health`);[m
[32m+[m[32m                const data = await response.json();[m
[32m+[m[41m                [m
[32m+[m[32m                systemInfo.innerHTML = `[m
[32m+[m[32m                    <div class="status success">[m
[32m+[m[32m                        <h3>System Status: ${data.status}</h3>[m
[32m+[m[32m                        <p><strong>Timestamp:</strong> ${data.timestamp}</p>[m
[32m+[m[32m                        <p><strong>Version:</strong> ${data.version}</p>[m
[32m+[m[32m                        <p><strong>Environment:</strong> ${data.environment}</p>[m
[32m+[m[32m                        <p><strong>Models Loaded:</strong> ${data.models_loaded ? '✅ Yes' : '❌ No'}</p>[m
[32m+[m[32m                        <p><strong>GPU Available:</strong> ${data.gpu_available ? '✅ Yes' : '❌ No'}</p>[m
[32m+[m[32m                    </div>[m
[32m+[m[32m                `;[m
[32m+[m[32m            } catch (error) {[m
[32m+[m[32m                systemInfo.innerHTML = `[m
[32m+[m[32m                    <div class="status error">[m
[32m+[m[32m                        ❌ Health check failed: ${error.message}[m
[32m+[m[32m                    </div>[m
[32m+[m[32m                `;[m
[32m+[m[32m            }[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        // Process images[m
[32m+[m[32m        async function processImages() {[m
[32m+[m[32m            if (!selectedFiles.model || !selectedFiles.cloth) {[m
[32m+[m[32m                showStatus('error', 'Please select both model and cloth images');[m
[32m+[m[32m                return;[m
[32m+[m[32m            }[m
[32m+[m
[32m+[m[32m            const apiUrl = document.getElementById('apiUrl').value;[m
[32m+[m[32m            const formData = new FormData();[m
[32m+[m[41m            [m
[32m+[m[32m            formData.append('model_file', selectedFiles.model);[m
[32m+[m[32m            formData.append('cloth_file', selectedFiles.cloth);[m
[32m+[m[32m            formData.append('model_type', document.getElementById('modelType').value);[m
[32m+[m[32m            formData.append('category', document.getElementById('category').value);[m
[32m+[m[32m            formData.append('samples', document.getElementById('samples').value);[m
[32m+[m[32m            formData.append('steps', document.getElementById('steps').value);[m
[32m+[m[32m            formData.append('scale', document.getElementById('scale').value);[m
[32m+[m[32m            formData.append('seed', document.getElementById('seed').value);[m
[32m+[m
[32m+[m[32m            // Show loading[m
[32m+[m[32m            document.getElementById('loading').style.display = 'block';[m
[32m+[m[32m            document.getElementById('processBtn').disabled = true;[m
[32m+[m[41m            [m
[32m+[m[32m            // Simulate progress[m
[32m+[m[32m            let progress = 0;[m
[32m+[m[32m            const progressInterval = setInterval(() => {[m
[32m+[m[32m                progress += Math.random() * 10;[m
[32m+[m[32m                if (progress > 90) progress = 90;[m
[32m+[m[32m                document.getElementById('progressFill').style.width = progress + '%';[m
[32m+[m[32m            }, 500);[m
[32m+[m
[32m+[m[32m            try {[m
[32m+[m[32m                const response = await fetch(`${apiUrl}/process`, {[m
[32m+[m[32m                    method: 'POST',[m
[32m+[m[32m                    body: formData[m
[32m+[m[32m                });[m
[32m+[m
[32m+[m[32m                const data = await response.json();[m
[32m+[m[41m                [m
[32m+[m[32m                clearInterval(progressInterval);[m
[32m+[m[32m                document.getElementById('progressFill').style.width = '100%';[m
[32m+[m
[32m+[m[32m                if (data.success) {[m
[32m+[m[32m                    showStatus('success', `Images processed successfully in ${data.processing_time?.toFixed(2)}s`);[m
[32m+[m[32m                    displayResults(data.result_paths, apiUrl);[m
[32m+[m[32m                } else {[m
[32m+[m[32m                    showStatus('error', data.message || 'Processing failed');[m
[32m+[m[32m                }[m
[32m+[m[32m            } catch (error) {[m
[32m+[m[32m                clearInterval(progressInterval);[m
[32m+[m[32m                showStatus('error', `Processing failed: ${error.message}`);[m
[32m+[m[32m            } finally {[m
[32m+[m[32m                document.getElementById('loading').style.display = 'none';[m
[32m+[m[32m                document.getElementById('processBtn').disabled = false;[m
[32m+[m[32m                document.getElementById('progressFill').style.width = '0%';[m
[32m+[m[32m            }[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        // Display results[m
[32m+[m[32m        function displayResults(resultPaths, apiUrl) {[m
[32m+[m[32m            const resultsDiv = document.getElementById('results');[m
[32m+[m[32m            resultsDiv.innerHTML = '';[m
[32m+[m[41m            [m
[32m+[m[32m            resultPaths.forEach((path, index) => {[m
[32m+[m[32m                const resultItem = document.createElement('div');[m
[32m+[m[32m                resultItem.className = 'result-item';[m
[32m+[m[32m                resultItem.innerHTML = `[m
[32m+[m[32m                    <img src="${apiUrl}${path}" alt="Result ${index + 1}" onerror="this.src='data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzAwIiBoZWlnaHQ9IjMwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIiBmaWxsPSIjZGRkIi8+PHRleHQgeD0iNTAlIiB5PSI1MCUiIGZvbnQtZmFtaWx5PSJBcmlhbCIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzk5OSIgdGV4dC1hbmNob3I9Im1pZGRsZSIgZHk9Ii4zZW0iPkltYWdlIG5vdCBmb3VuZDwvdGV4dD48L3N2Zz4='">[m
[32m+[m[32m                    <div class="info">[m
[32m+[m[32m                        <h4>Result ${index + 1}</h4>[m
[32m+[m[32m                        <p><a href="${apiUrl}${path}" target="_blank">Download Image</a></p>[m
[32m+[m[32m                    </div>[m
[32m+[m[32m                `;[m
[32m+[m[32m                resultsDiv.appendChild(resultItem);[m
[32m+[m[32m            });[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        // Show status message[m
[32m+[m[32m        function showStatus(type, message) {[m
[32m+[m[32m            const statusDiv = document.getElementById('processStatus');[m
[32m+[m[32m            statusDiv.innerHTML = `<div class="status ${type}">${message}</div>`;[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        // Clear results[m
[32m+[m[32m        function clearResults() {[m
[32m+[m[32m            document.getElementById('results').innerHTML = '';[m
[32m+[m[32m            document.getElementById('processStatus').innerHTML = '';[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        // Test endpoints[m
[32m+[m[32m        async function testRootEndpoint() {[m
[32m+[m[32m            await testEndpoint('GET', '/', 'Root Endpoint');[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        async function testHealthEndpoint() {[m
[32m+[m[32m            await testEndpoint('GET', '/health', 'Health Endpoint');[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        async function testDocsEndpoint() {[m
[32m+[m[32m            await testEndpoint('GET', '/docs', 'Docs Endpoint');[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        async function testEndpoint(method, path, name) {[m
[32m+[m[32m            const apiUrl = document.getElementById('apiUrl').value;[m
[32m+[m[32m            const testResults = document.getElementById('testResults');[m
[32m+[m[41m            [m
[32m+[m[32m            try {[m
[32m+[m[32m                const response = await fetch(`${apiUrl}${path}`);[m
[32m+[m[32m                const status = response.ok ? 'success' : 'error';[m
[32m+[m[32m                const message = response.ok ?[m[41m [m
[32m+[m[32m                    `✅ ${name}: OK (${response.status})` :[m[41m [m
[32m+[m[32m                    `❌ ${name}: Failed (${response.status})`;[m
[32m+[m[41m                [m
[32m+[m[32m                testResults.innerHTML += `<div class="status ${status}">${message}</div>`;[m
[32m+[m[32m            } catch (error) {[m
[32m+[m[32m                testResults.innerHTML += `<div class="status error">❌ ${name}: Error - ${error.message}</div>`;[m
[32m+[m[32m            }[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        // Test error cases[m
[32m+[m[32m        async function testInvalidFile() {[m
[32m+[m[32m            const apiUrl = document.getElementById('apiUrl').value;[m
[32m+[m[32m            const formData = new FormData();[m
[32m+[m[41m            [m
[32m+[m[32m            // Create a text file[m
[32m+[m[32m            const textBlob = new Blob(['This is not an image'], { type: 'text/plain' });[m
[32m+[m[32m            formData.append('model_file', textBlob, 'test.txt');[m
[32m+[m[32m            formData.append('cloth_file', textBlob, 'test.txt');[m
[32m+[m[41m            [m
[32m+[m[32m            try {[m
[32m+[m[32m                const response = await fetch(`${apiUrl}/process`, {[m
[32m+[m[32m                    method: 'POST',[m
[32m+[m[32m                    body: formData[m
[32m+[m[32m                });[m
[32m+[m[41m                [m
[32m+[m[32m                const data = await response.json();[m
[32m+[m[32m                const status = response.status === 400 ? 'success' : 'error';[m
[32m+[m[32m                const message = response.status === 400 ?[m[41m [m
[32m+[m[32m                    '✅ Invalid file test passed (400 error as expected)' :[m[41m [m
[32m+[m[32m                    `❌ Invalid file test failed (got ${response.status})`;[m
[32m+[m[41m                [m
[32m+[m[32m                document.getElementById('testResults').innerHTML += `<div class="status ${status}">${message}</div>`;[m
[32m+[m[32m            } catch (error) {[m
[32m+[m[32m                document.getElementById('testResults').innerHTML += `<div class="status error">❌ Invalid file test error: ${error.message}</div>`;[m
[32m+[m[32m            }[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        async function testMissingFiles() {[m
[32m+[m[32m            const apiUrl = document.getElementById('apiUrl').value;[m
[32m+[m[41m            [m
[32m+[m[32m            try {[m
[32m+[m[32m                const response = await fetch(`${apiUrl}/process`, {[m
[32m+[m[32m                    method: 'POST',[m
[32m+[m[32m                    body: new FormData()[m
[32m+[m[32m                });[m
[32m+[m[41m                [m
[32m+[m[32m                const status = response.status === 422 ? 'success' : 'error';[m
[32m+[m[32m                const message = response.status === 422 ?[m[41m [m
[32m+[m[32m                    '✅ Missing files test passed (422 error as expected)' :[m[41m [m
[32m+[m[32m                    `❌ Missing files test failed (got ${response.status})`;[m
[32m+[m[41m                [m
[32m+[m[32m                document.getElementById('testResults').innerHTML += `<div class="status ${status}">${message}</div>`;[m
[32m+[m[32m            } catch (error) {[m
[32m+[m[32m                document.getElementById('testResults').innerHTML += `<div class="status error">❌ Missing files test error: ${error.message}</div>`;[m
[32m+[m[32m            }[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        async function testLargeFile() {[m
[32m+[m[32m            const apiUrl = document.getElementById('apiUrl').value;[m
[32m+[m[32m            const formData = new FormData();[m
[32m+[m[41m            [m
[32m+[m[32m            // Create a large file (simulate)[m
[32m+[m[32m            const largeBlob = new Blob([new ArrayBuffer(50 * 1024 * 1024)], { type: 'image/png' });[m
[32m+[m[32m            formData.append('model_file', largeBlob, 'large.png');[m
[32m+[m[32m            formData.append('cloth_file', largeBlob, 'large.png');[m
[32m+[m[41m            [m
[32m+[m[32m            try {[m
[32m+[m[32m                const response = await fetch(`${apiUrl}/process`, {[m
[32m+[m[32m                    method: 'POST',[m
[32m+[m[32m                    body: formData[m
[32m+[m[32m                });[m
[32m+[m[41m                [m
[32m+[m[32m                const status = response.status >= 400 ? 'success' : 'warning';[m
[32m+[m[32m                const message = response.status >= 400 ?[m[41m [m
[32m+[m[32m                    `✅ Large file test passed (${response.status} error as expected)` :[m[41m [m
[32m+[m[32m                    `⚠️ Large file test: File was accepted (${response.status})`;[m
[32m+[m[41m                [m
[32m+[m[32m                document.getElementById('testResults').innerHTML += `<div class="status ${status}">${message}</div>`;[m
[32m+[m[32m            } catch (error) {[m
[32m+[m[32m                document.getElementById('testResults').innerHTML += `<div class="status error">❌ Large file test error: ${error.message}</div>`;[m
[32m+[m[32m            }[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        // Initialize[m
[32m+[m[32m        document.addEventListener('DOMContentLoaded', function() {[m
[32m+[m[32m            updateCategoryOptions();[m
[32m+[m[32m            testConnection();[m
[32m+[m[32m        });[m
[32m+[m[32m    </script>[m
[32m+[m[32m</body>[m
[32m+[m[32m</html>[m
[1mdiff --git a/tests/test_api.py b/tests/test_api.py[m
[1mnew file mode 100644[m
[1mindex 0000000..76b1f8e[m
[1m--- /dev/null[m
[1m+++ b/tests/test_api.py[m
[36m@@ -0,0 +1,332 @@[m
[32m+[m[32m"""[m
[32m+[m[32mTest suite for OOTDiffusion API[m
[32m+[m[32m"""[m
[32m+[m[32mimport pytest[m
[32m+[m[32mimport asyncio[m
[32m+[m[32mimport tempfile[m
[32m+[m[32mimport os[m
[32m+[m[32mfrom pathlib import Path[m
[32m+[m[32mfrom PIL import Image[m
[32m+[m[32mimport numpy as np[m
[32m+[m[32mfrom fastapi.testclient import TestClient[m
[32m+[m[32mimport sys[m
[32m+[m
[32m+[m[32m# Add project root to path[m
[32m+[m[32mPROJECT_ROOT = Path(__file__).absolute().parents[1][m
[32m+[m[32msys.path.insert(0, str(PROJECT_ROOT))[m
[32m+[m
[32m+[m[32mfrom api.app import app, model_manager[m
[32m+[m[32mfrom config import get_config[m
[32m+[m
[32m+[m[32m# Test configuration[m
[32m+[m[32mtest_config = get_config("testing")[m
[32m+[m
[32m+[m[32mclass TestAPIBasic:[m
[32m+[m[32m    """Basic API functionality tests"""[m
[32m+[m[41m    [m
[32m+[m[32m    def setup_method(self):[m
[32m+[m[32m        """Setup for each test method"""[m
[32m+[m[32m        self.client = TestClient(app)[m
[32m+[m[32m        self.test_image_size = (256, 256)  # Smaller for testing[m
[32m+[m[41m    [m
[32m+[m[32m    def create_test_image(self, filename: str, size: tuple = None) -> Path:[m
[32m+[m[32m        """Create a test image file"""[m
[32m+[m[32m        if size is None:[m
[32m+[m[32m            size = self.test_image_size[m
[32m+[m[41m        [m
[32m+[m[32m        # Create a simple test image[m
[32m+[m[32m        img = Image.new('RGB', size, color='red')[m
[32m+[m[32m        temp_file = tempfile.NamedTemporaryFile(suffix='.png', delete=False)[m
[32m+[m[32m        img.save(temp_file.name)[m
[32m+[m[32m        return Path(temp_file.name)[m
[32m+[m[41m    [m
[32m+[m[32m    def test_root_endpoint(self):[m
[32m+[m[32m        """Test root endpoint"""[m
[32m+[m[32m        response = self.client.get("/")[m
[32m+[m[32m        assert response.status_code == 200[m
[32m+[m[32m        data = response.json()[m
[32m+[m[32m        assert "message" in data[m
[32m+[m[32m        assert data["message"] == "OOTDiffusion API"[m
[32m+[m[41m    [m
[32m+[m[32m    def test_health_check(self):[m
[32m+[m[32m        """Test health check endpoint"""[m
[32m+[m[32m        response = self.client.get("/health")[m
[32m+[m[32m        assert response.status_code == 200[m
[32m+[m[32m        data = response.json()[m
[32m+[m[32m        assert "status" in data[m
[32m+[m[32m        assert "timestamp" in data[m
[32m+[m[32m        assert "version" in data[m
[32m+[m[32m        assert "environment" in data[m
[32m+[m[41m    [m
[32m+[m[32m    def test_docs_endpoint(self):[m
[32m+[m[32m        """Test API documentation endpoint"""[m
[32m+[m[32m        response = self.client.get("/docs")[m
[32m+[m[32m        # Should return 200 in debug mode, 404 in production[m
[32m+[m[32m        assert response.status_code in [200, 404][m
[32m+[m
[32m+[m[32mclass TestImageProcessing:[m
[32m+[m[32m    """Image processing tests"""[m
[32m+[m[41m    [m
[32m+[m[32m    def setup_method(self):[m
[32m+[m[32m        """Setup for each test method"""[m
[32m+[m[32m        self.client = TestClient(app)[m
[32m+[m[32m        self.test_image_size = (256, 256)[m
[32m+[m[41m    [m
[32m+[m[32m    def create_test_image(self, filename: str, size: tuple = None) -> Path:[m
[32m+[m[32m        """Create a test image file"""[m
[32m+[m[32m        if size is None:[m
[32m+[m[32m            size = self.test_image_size[m
[32m+[m[41m        [m
[32m+[m[32m        img = Image.new('RGB', size, color='red')[m
[32m+[m[32m        temp_file = tempfile.NamedTemporaryFile(suffix='.png', delete=False)[m
[32m+[m[32m        img.save(temp_file.name)[m
[32m+[m[32m        return Path(temp_file.name)[m
[32m+[m[41m    [m
[32m+[m[32m    def test_process_images_hd(self):[m
[32m+[m[32m        """Test HD model image processing"""[m
[32m+[m[32m        # Create test images[m
[32m+[m[32m        model_img = self.create_test_image("model.png")[m
[32m+[m[32m        cloth_img = self.create_test_image("cloth.png")[m
[32m+[m[41m        [m
[32m+[m[32m        try:[m
[32m+[m[32m            # Test with HD model[m
[32m+[m[32m            with open(model_img, "rb") as f1, open(cloth_img, "rb") as f2:[m
[32m+[m[32m                files = {[m
[32m+[m[32m                    "model_file": ("model.png", f1, "image/png"),[m
[32m+[m[32m                    "cloth_file": ("cloth.png", f2, "image/png")[m
[32m+[m[32m                }[m
[32m+[m[32m                data = {[m
[32m+[m[32m                    "model_type": "hd",[m
[32m+[m[32m                    "category": 0,[m
[32m+[m[32m                    "samples": 1,[m
[32m+[m[32m                    "steps": 5,  # Reduced for testing[m
[32m+[m[32m                    "scale": 2.0,[m
[32m+[m[32m                    "seed": 42[m
[32m+[m[32m                }[m
[32m+[m[41m                [m
[32m+[m[32m                response = self.client.post("/process", files=files, data=data)[m
[32m+[m[41m                [m
[32m+[m[32m                # Should return 200 or 503 (if models not loaded)[m
[32m+[m[32m                assert response.status_code in [200, 503][m
[32m+[m[41m                [m
[32m+[m[32m                if response.status_code == 200:[m
[32m+[m[32m                    data = response.json()[m
[32m+[m[32m                    assert data["success"] is True[m
[32m+[m[32m                    assert "result_paths" in data[m
[32m+[m[32m                    assert len(data["result_paths"]) == 1[m
[32m+[m[41m        [m
[32m+[m[32m        finally:[m
[32m+[m[32m            # Cleanup[m
[32m+[m[32m            if model_img.exists():[m
[32m+[m[32m                model_img.unlink()[m
[32m+[m[32m            if cloth_img.exists():[m
[32m+[m[32m                cloth_img.unlink()[m
[32m+[m[41m    [m
[32m+[m[32m    def test_process_images_dc(self):[m
[32m+[m[32m        """Test DC model image processing"""[m
[32m+[m[32m        # Create test images[m
[32m+[m[32m        model_img = self.create_test_image("model.png")[m
[32m+[m[32m        cloth_img = self.create_test_image("cloth.png")[m
[32m+[m[41m        [m
[32m+[m[32m        try:[m
[32m+[m[32m            # Test with DC model[m
[32m+[m[32m            with open(model_img, "rb") as f1, open(cloth_img, "rb") as f2:[m
[32m+[m[32m                files = {[m
[32m+[m[32m                    "model_file": ("model.png", f1, "image/png"),[m
[32m+[m[32m                    "cloth_file": ("cloth.png", f2, "image/png")[m
[32m+[m[32m                }[m
[32m+[m[32m                data = {[m
[32m+[m[32m                    "model_type": "dc",[m
[32m+[m[32m                    "category": "upperbody",[m
[32m+[m[32m                    "samples": 1,[m
[32m+[m[32m                    "steps": 5,  # Reduced for testing[m
[32m+[m[32m                    "scale": 2.0,[m
[32m+[m[32m                    "seed": 42[m
[32m+[m[32m                }[m
[32m+[m[41m                [m
[32m+[m[32m                response = self.client.post("/process", files=files, data=data)[m
[32m+[m[41m                [m
[32m+[m[32m                # Should return 200 or 503 (if models not loaded)[m
[32m+[m[32m                assert response.status_code in [200, 503][m
[32m+[m[41m        [m
[32m+[m[32m        finally:[m
[32m+[m[32m            # Cleanup[m
[32m+[m[32m            if model_img.exists():[m
[32m+[m[32m                model_img.unlink()[m
[32m+[m[32m            if cloth_img.exists():[m
[32m+[m[32m                cloth_img.unlink()[m
[32m+[m[41m    [m
[32m+[m[32m    def test_invalid_file_type(self):[m
[32m+[m[32m        """Test with invalid file type"""[m
[32m+[m[32m        # Create a text file instead of image[m
[32m+[m[32m        temp_file = tempfile.NamedTemporaryFile(suffix='.txt', delete=False)[m
[32m+[m[32m        temp_file.write(b"This is not an image")[m
[32m+[m[32m        temp_file.close()[m
[32m+[m[41m        [m
[32m+[m[32m        try:[m
[32m+[m[32m            with open(temp_file.name, "rb") as f:[m
[32m+[m[32m                files = {[m
[32m+[m[32m                    "model_file": ("test.txt", f, "text/plain"),[m
[32m+[m[32m                    "cloth_file": ("test.txt", f, "text/plain")[m
[32m+[m[32m                }[m
[32m+[m[32m                data = {[m
[32m+[m[32m                    "model_type": "hd",[m
[32m+[m[32m                    "category": 0[m
[32m+[m[32m                }[m
[32m+[m[41m                [m
[32m+[m[32m                response = self.client.post("/process", files=files, data=data)[m
[32m+[m[32m                assert response.status_code == 400[m
[32m+[m[41m        [m
[32m+[m[32m        finally:[m
[32m+[m[32m            if os.path.exists(temp_file.name):[m
[32m+[m[32m                os.unlink(temp_file.name)[m
[32m+[m[41m    [m
[32m+[m[32m    def test_missing_files(self):[m
[32m+[m[32m        """Test with missing files"""[m
[32m+[m[32m        data = {[m
[32m+[m[32m            "model_type": "hd",[m
[32m+[m[32m            "category": 0[m
[32m+[m[32m        }[m
[32m+[m[41m        [m
[32m+[m[32m        response = self.client.post("/process", data=data)[m
[32m+[m[32m        assert response.status_code == 422  # Validation error[m
[32m+[m
[32m+[m[32mclass TestValidation:[m
[32m+[m[32m    """Input validation tests"""[m
[32m+[m[41m    [m
[32m+[m[32m    def setup_method(self):[m
[32m+[m[32m        """Setup for each test method"""[m
[32m+[m[32m        self.client = TestClient(app)[m
[32m+[m[41m    [m
[32m+[m[32m    def test_invalid_model_type(self):[m
[32m+[m[32m        """Test invalid model type"""[m
[32m+[m[32m        model_img = self.create_test_image("model.png")[m
[32m+[m[32m        cloth_img = self.create_test_image("cloth.png")[m
[32m+[m[41m        [m
[32m+[m[32m        try:[m
[32m+[m[32m            with open(model_img, "rb") as f1, open(cloth_img, "rb") as f2:[m
[32m+[m[32m                files = {[m
[32m+[m[32m                    "model_file": ("model.png", f1, "image/png"),[m
[32m+[m[32m                    "cloth_file": ("cloth.png", f2, "image/png")[m
[32m+[m[32m                }[m
[32m+[m[32m                data = {[m
[32m+[m[32m                    "model_type": "invalid",[m
[32m+[m[32m                    "category": 0[m
[32m+[m[32m                }[m
[32m+[m[41m                [m
[32m+[m[32m                response = self.client.post("/process", files=files, data=data)[m
[32m+[m[32m                assert response.status_code == 400[m
[32m+[m[41m        [m
[32m+[m[32m        finally:[m
[32m+[m[32m            if model_img.exists():[m
[32m+[m[32m                model_img.unlink()[m
[32m+[m[32m            if cloth_img.exists():[m
[32m+[m[32m                cloth_img.unlink()[m
[32m+[m[41m    [m
[32m+[m[32m    def test_invalid_category(self):[m
[32m+[m[32m        """Test invalid category"""[m
[32m+[m[32m        model_img = self.create_test_image("model.png")[m
[32m+[m[32m        cloth_img = self.create_test_image("cloth.png")[m
[32m+[m[41m        [m
[32m+[m[32m        try:[m
[32m+[m[32m            with open(model_img, "rb") as f1, open(cloth_img, "rb") as f2:[m
[32m+[m[32m                files = {[m
[32m+[m[32m                    "model_file": ("model.png", f1, "image/png"),[m
[32m+[m[32m                    "cloth_file": ("cloth.png", f2, "image/png")[m
[32m+[m[32m                }[m
[32m+[m[32m                data = {[m
[32m+[m[32m                    "model_type": "hd",[m
[32m+[m[32m                    "category": 5  # Invalid category for HD[m
[32m+[m[32m                }[m
[32m+[m[41m                [m
[32m+[m[32m                response = self.client.post("/process", files=files, data=data)[m
[32m+[m[32m                assert response.status_code == 400[m
[32m+[m[41m        [m
[32m+[m[32m        finally:[m
[32m+[m[32m            if model_img.exists():[m
[32m+[m[32m                model_img.unlink()[m
[32m+[m[32m            if cloth_img.exists():[m
[32m+[m[32m                cloth_img.unlink()[m
[32m+[m[41m    [m
[32m+[m[32m    def test_invalid_samples(self):[m
[32m+[m[32m        """Test invalid samples count"""[m
[32m+[m[32m        model_img = self.create_test_image("model.png")[m
[32m+[m[32m        cloth_img = self.create_test_image("cloth.png")[m
[32m+[m[41m        [m
[32m+[m[32m        try:[m
[32m+[m[32m            with open(model_img, "rb") as f1, open(cloth_img, "rb") as f2:[m
[32m+[m[32m                files = {[m
[32m+[m[32m                    "model_file": ("model.png", f1, "image/png"),[m
[32m+[m[32m                    "cloth_file": ("cloth.png", f2, "image/png")[m
[32m+[m[32m                }[m
[32m+[m[32m                data = {[m
[32m+[m[32m                    "model_type": "hd",[m
[32m+[m[32m                    "category": 0,[m
[32m+[m[32m                    "samples": 10  # Too many samples[m
[32m+[m[32m                }[m
[32m+[m[41m                [m
[32m+[m[32m                response = self.client.post("/process", files=files, data=data)[m
[32m+[m[32m                assert response.status_code == 400[m
[32m+[m[41m        [m
[32m+[m[32m        finally:[m
[32m+[m[32m            if model_img.exists():[m
[32m+[m[32m                model_img.unlink()[m
[32m+[m[32m            if cloth_img.exists():[m
[32m+[m[32m                cloth_img.unlink()[m
[32m+[m[41m    [m
[32m+[m[32m    def create_test_image(self, filename: str) -> Path:[m
[32m+[m[32m        """Create a test image file"""[m
[32m+[m[32m        img = Image.new('RGB', (256, 256), color='red')[m
[32m+[m[32m        temp_file = tempfile.NamedTemporaryFile(suffix='.png', delete=False)[m
[32m+[m[32m        img.save(temp_file.name)[m
[32m+[m[32m        return Path(temp_file.name)[m
[32m+[m
[32m+[m[32mclass TestErrorHandling:[m
[32m+[m[32m    """Error handling tests"""[m
[32m+[m[41m    [m
[32m+[m[32m    def setup_method(self):[m
[32m+[m[32m        """Setup for each test method"""[m
[32m+[m[32m        self.client = TestClient(app)[m
[32m+[m[41m    [m
[32m+[m[32m    def test_large_file(self):[m
[32m+[m[32m        """Test with file too large"""[m
[32m+[m[32m        # Create a large file (simulate)[m
[32m+[m[32m        large_file = tempfile.NamedTemporaryFile(suffix='.png', delete=False)[m
[32m+[m[32m        large_file.write(b'x' * (50 * 1024 * 1024))  # 50MB[m
[32m+[m[32m        large_file.close()[m
[32m+[m[41m        [m
[32m+[m[32m        try:[m
[32m+[m[32m            with open(large_file.name, "rb") as f:[m
[32m+[m[32m                files = {[m
[32m+[m[32m                    "model_file": ("large.png", f, "image/png"),[m
[32m+[m[32m                    "cloth_file": ("large.png", f, "image/png")[m
[32m+[m[32m                }[m
[32m+[m[32m                data = {[m
[32m+[m[32m                    "model_type": "hd",[m
[32m+[m[32m                    "category": 0[m
[32m+[m[32m                }[m
[32m+[m[41m                [m
[32m+[m[32m                response = self.client.post("/process", files=files, data=data)[m
[32m+[m[32m                # Should handle large files gracefully[m
[32m+[m[32m                assert response.status_code in [200, 400, 413][m
[32m+[m[41m        [m
[32m+[m[32m        finally:[m
[32m+[m[32m            if os.path.exists(large_file.name):[m
[32m+[m[32m                os.unlink(large_file.name)[m
[32m+[m[41m    [m
[32m+[m[32m    def test_malformed_request(self):[m
[32m+[m[32m        """Test malformed request"""[m
[32m+[m[32m        response = self.client.post("/process", json={"invalid": "data"})[m
[32m+[m[32m        assert response.status_code == 422[m
[32m+[m
[32m+[m[32m# Pytest configuration[m
[32m+[m[32m@pytest.fixture(scope="session")[m
[32m+[m[32mdef event_loop():[m
[32m+[m[32m    """Create an instance of the default event loop for the test session."""[m
[32m+[m[32m    loop = asyncio.get_event_loop_policy().new_event_loop()[m
[32m+[m[32m    yield loop[m
[32m+[m[32m    loop.close()[m
[32m+[m
[32m+[m[32m# Run tests[m
[32m+[m[32mif __name__ == "__main__":[m
[32m+[m[32m    pytest.main([__file__, "-v"])[m
[1mdiff --git a/utils/error_handling.py b/utils/error_handling.py[m
[1mnew file mode 100644[m
[1mindex 0000000..b30d626[m
[1m--- /dev/null[m
[1m+++ b/utils/error_handling.py[m
[36m@@ -0,0 +1,292 @@[m
[32m+[m[32m"""[m
[32m+[m[32mProduction-ready error handling and logging utilities for OOTDiffusion[m
[32m+[m[32m"""[m
[32m+[m[32mimport logging[m
[32m+[m[32mimport traceback[m
[32m+[m[32mimport functools[m
[32m+[m[32mimport time[m
[32m+[m[32mfrom typing import Any, Callable, Optional, Dict, Union[m
[32m+[m[32mfrom pathlib import Path[m
[32m+[m[32mimport json[m
[32m+[m[32mfrom datetime import datetime[m
[32m+[m
[32m+[m[32mfrom config import config[m
[32m+[m
[32m+[m[32mclass OOTDError(Exception):[m
[32m+[m[32m    """Base exception for OOTDiffusion errors"""[m
[32m+[m[32m    def __init__(self, message: str, error_code: str = "UNKNOWN_ERROR", details: Optional[Dict] = None):[m
[32m+[m[32m        self.message = message[m
[32m+[m[32m        self.error_code = error_code[m
[32m+[m[32m        self.details = details or {}[m
[32m+[m[32m        super().__init__(self.message)[m
[32m+[m
[32m+[m[32mclass ModelLoadError(OOTDError):[m
[32m+[m[32m    """Error when loading models"""[m
[32m+[m[32m    def __init__(self, message: str, model_name: str, details: Optional[Dict] = None):[m
[32m+[m[32m        super().__init__(message, "MODEL_LOAD_ERROR", details)[m
[32m+[m[32m        self.model_name = model_name[m
[32m+[m
[32m+[m[32mclass ProcessingError(OOTDError):[m
[32m+[m[32m    """Error during image processing"""[m
[32m+[m[32m    def __init__(self, message: str, step: str, details: Optional[Dict] = None):[m
[32m+[m[32m        super().__init__(message, "PROCESSING_ERROR", details)[m
[32m+[m[32m        self.step = step[m
[32m+[m
[32m+[m[32mclass ValidationError(OOTDError):[m
[32m+[m[32m    """Error during input validation"""[m
[32m+[m[32m    def __init__(self, message: str, field: str, details: Optional[Dict] = None):[m
[32m+[m[32m        super().__init__(message, "VALIDATION_ERROR", details)[m
[32m+[m[32m        self.field = field[m
[32m+[m
[32m+[m[32mclass ResourceError(OOTDError):[m
[32m+[m[32m    """Error when resources are not available"""[m
[32m+[m[32m    def __init__(self, message: str, resource_type: str, details: Optional[Dict] = None):[m
[32m+[m[32m        super().__init__(message, "RESOURCE_ERROR", details)[m
[32m+[m[32m        self.resource_type = resource_type[m
[32m+[m
[32m+[m[32mclass Logger:[m
[32m+[m[32m    """Enhanced logger with structured logging"""[m
[32m+[m[41m    [m
[32m+[m[32m    def __init__(self, name: str, log_file: Optional[str] = None):[m
[32m+[m[32m        self.logger = logging.getLogger(name)[m
[32m+[m[32m        self.logger.setLevel(getattr(logging, config.logging.level.upper()))[m
[32m+[m[41m        [m
[32m+[m[32m        # Create formatter[m
[32m+[m[32m        formatter = logging.Formatter(config.logging.format)[m
[32m+[m[41m        [m
[32m+[m[32m        # Console handler[m
[32m+[m[32m        console_handler = logging.StreamHandler()[m
[32m+[m[32m        console_handler.setFormatter(formatter)[m
[32m+[m[32m        self.logger.addHandler(console_handler)[m
[32m+[m[41m        [m
[32m+[m[32m        # File handler if specified[m
[32m+[m[32m        if log_file:[m
[32m+[m[32m            file_handler = logging.FileHandler(log_file)[m
[32m+[m[32m            file_handler.setFormatter(formatter)[m
[32m+[m[32m            self.logger.addHandler(file_handler)[m
[32m+[m[41m        [m
[32m+[m[32m        # Prevent duplicate logs[m
[32m+[m[32m        self.logger.propagate = False[m
[32m+[m[41m    [m
[32m+[m[32m    def info(self, message: str, **kwargs):[m
[32m+[m[32m        """Log info message with additional context"""[m
[32m+[m[32m        self.logger.info(self._format_message(message, **kwargs))[m
[32m+[m[41m    [m
[32m+[m[32m    def warning(self, message: str, **kwargs):[m
[32m+[m[32m        """Log warning message with additional context"""[m
[32m+[m[32m        self.logger.warning(self._format_message(message, **kwargs))[m
[32m+[m[41m    [m
[32m+[m[32m    def error(self, message: str, **kwargs):[m
[32m+[m[32m        """Log error message with additional context"""[m
[32m+[m[32m        self.logger.error(self._format_message(message, **kwargs))[m
[32m+[m[41m    [m
[32m+[m[32m    def debug(self, message: str, **kwargs):[m
[32m+[m[32m        """Log debug message with additional context"""[m
[32m+[m[32m        self.logger.debug(self._format_message(message, **kwargs))[m
[32m+[m[41m    [m
[32m+[m[32m    def _format_message(self, message: str, **kwargs) -> str:[m
[32m+[m[32m        """Format message with additional context"""[m
[32m+[m[32m        if kwargs:[m
[32m+[m[32m            context = json.dumps(kwargs, default=str)[m
[32m+[m[32m            return f"{message} | Context: {context}"[m
[32m+[m[32m        return message[m
[32m+[m
[32m+[m[32m# Global logger instance[m
[32m+[m[32mlogger = Logger("ootd")[m
[32m+[m
[32m+[m[32mdef error_handler([m
[32m+[m[32m    reraise: bool = False,[m
[32m+[m[32m    return_value: Any = None,[m
[32m+[m[32m    log_error: bool = True[m
[32m+[m[32m):[m
[32m+[m[32m    """[m
[32m+[m[32m    Decorator for error handling[m
[32m+[m[41m    [m
[32m+[m[32m    Args:[m
[32m+[m[32m        reraise: Whether to reraise the exception[m
[32m+[m[32m        return_value: Value to return if an error occurs[m
[32m+[m[32m        log_error: Whether to log the error[m
[32m+[m[32m    """[m
[32m+[m[32m    def decorator(func: Callable) -> Callable:[m
[32m+[m[32m        @functools.wraps(func)[m
[32m+[m[32m        def wrapper(*args, **kwargs):[m
[32m+[m[32m            try:[m
[32m+[m[32m                return func(*args, **kwargs)[m
[32m+[m[32m            except OOTDError as e:[m
[32m+[m[32m                if log_error:[m
[32m+[m[32m                    logger.error([m
[32m+[m[32m                        f"OOTD Error in {func.__name__}: {e.message}",[m
[32m+[m[32m                        error_code=e.error_code,[m
[32m+[m[32m                        details=e.details,[m
[32m+[m[32m                        function=func.__name__[m
[32m+[m[32m                    )[m
[32m+[m[32m                if reraise:[m
[32m+[m[32m                    raise[m
[32m+[m[32m                return return_value[m
[32m+[m[32m            except Exception as e:[m
[32m+[m[32m                if log_error:[m
[32m+[m[32m                    logger.error([m
[32m+[m[32m                        f"Unexpected error in {func.__name__}: {str(e)}",[m
[32m+[m[32m                        error_type=type(e).__name__,[m
[32m+[m[32m                        traceback=traceback.format_exc(),[m
[32m+[m[32m                        function=func.__name__[m
[32m+[m[32m                    )[m
[32m+[m[32m                if reraise:[m
[32m+[m[32m                    raise[m
[32m+[m[32m                return return_value[m
[32m+[m[32m        return wrapper[m
[32m+[m[32m    return decorator[m
[32m+[m
[32m+[m[32mdef performance_monitor(func: Callable) -> Callable:[m
[32m+[m[32m    """Decorator to monitor function performance"""[m
[32m+[m[32m    @functools.wraps(func)[m
[32m+[m[32m    def wrapper(*args, **kwargs):[m
[32m+[m[32m        start_time = time.time()[m
[32m+[m[32m        try:[m
[32m+[m[32m            result = func(*args, **kwargs)[m
[32m+[m[32m            execution_time = time.time() - start_time[m
[32m+[m[32m            logger.info([m
[32m+[m[32m                f"Function {func.__name__} completed successfully",[m
[32m+[m[32m                execution_time=execution_time,[m
[32m+[m[32m                function=func.__name__[m
[32m+[m[32m            )[m
[32m+[m[32m            return result[m
[32m+[m[32m        except Exception as e:[m
[32m+[m[32m            execution_time = time.time() - start_time[m
[32m+[m[32m            logger.error([m
[32m+[m[32m                f"Function {func.__name__} failed after {execution_time:.2f}s",[m
[32m+[m[32m                error=str(e),[m
[32m+[m[32m                execution_time=execution_time,[m
[32m+[m[32m                function=func.__name__[m
[32m+[m[32m            )[m
[32m+[m[32m            raise[m
[32m+[m[32m    return wrapper[m
[32m+[m
[32m+[m[32mdef validate_input(func: Callable) -> Callable:[m
[32m+[m[32m    """Decorator to validate function inputs"""[m
[32m+[m[32m    @functools.wraps(func)[m
[32m+[m[32m    def wrapper(*args, **kwargs):[m
[32m+[m[32m        # Basic validation[m
[32m+[m[32m        if not args and not kwargs:[m
[32m+[m[32m            raise ValidationError("No arguments provided", "args")[m
[32m+[m[41m        [m
[32m+[m[32m        # Log function call[m
[32m+[m[32m        logger.debug([m
[32m+[m[32m            f"Calling {func.__name__}",[m
[32m+[m[32m            args_count=len(args),[m
[32m+[m[32m            kwargs_keys=list(kwargs.keys()),[m
[32m+[m[32m            function=func.__name__[m
[32m+[m[32m        )[m
[32m+[m[41m        [m
[32m+[m[32m        return func(*args, **kwargs)[m
[32m+[m[32m    return wrapper[m
[32m+[m
[32m+[m[32mclass ErrorTracker:[m
[32m+[m[32m    """Track and analyze errors"""[m
[32m+[m[41m    [m
[32m+[m[32m    def __init__(self, log_file: str = "error_tracker.json"):[m
[32m+[m[32m        self.log_file = Path(log_file)[m
[32m+[m[32m        self.errors = [][m
[32m+[m[32m        self.load_errors()[m
[32m+[m[41m    [m
[32m+[m[32m    def track_error(self, error: Exception, context: Optional[Dict] = None):[m
[32m+[m[32m        """Track an error with context"""[m
[32m+[m[32m        error_data = {[m
[32m+[m[32m            "timestamp": datetime.now().isoformat(),[m
[32m+[m[32m            "error_type": type(error).__name__,[m
[32m+[m[32m            "error_message": str(error),[m
[32m+[m[32m            "context": context or {},[m
[32m+[m[32m            "traceback": traceback.format_exc()[m
[32m+[m[32m        }[m
[32m+[m[41m        [m
[32m+[m[32m        self.errors.append(error_data)[m
[32m+[m[32m        self.save_errors()[m
[32m+[m[41m        [m
[32m+[m[32m        logger.error([m
[32m+[m[32m            "Error tracked",[m
[32m+[m[32m            error_type=error_data["error_type"],[m
[32m+[m[32m            error_message=error_data["error_message"],[m
[32m+[m[32m            context=context[m
[32m+[m[32m        )[m
[32m+[m[41m    [m
[32m+[m[32m    def load_errors(self):[m
[32m+[m[32m        """Load errors from file"""[m
[32m+[m[32m        if self.log_file.exists():[m
[32m+[m[32m            try:[m
[32m+[m[32m                with open(self.log_file, 'r') as f:[m
[32m+[m[32m                    self.errors = json.load(f)[m
[32m+[m[32m            except (json.JSONDecodeError, FileNotFoundError):[m
[32m+[m[32m                self.errors = [][m
[32m+[m[41m    [m
[32m+[m[32m    def save_errors(self):[m
[32m+[m[32m        """Save errors to file"""[m
[32m+[m[32m        try:[m
[32m+[m[32m            with open(self.log_file, 'w') as f:[m
[32m+[m[32m                json.dump(self.errors, f, indent=2)[m
[32m+[m[32m        except Exception as e:[m
[32m+[m[32m            logger.error(f"Failed to save errors: {e}")[m
[32m+[m[41m    [m
[32m+[m[32m    def get_error_summary(self) -> Dict[str, Any]:[m
[32m+[m[32m        """Get summary of tracked errors"""[m
[32m+[m[32m        if not self.errors:[m
[32m+[m[32m            return {"total_errors": 0}[m
[32m+[m[41m        [m
[32m+[m[32m        error_types = {}[m
[32m+[m[32m        for error in self.errors:[m
[32m+[m[32m            error_type = error["error_type"][m
[32m+[m[32m            error_types[error_type] = error_types.get(error_type, 0) + 1[m
[32m+[m[41m        [m
[32m+[m[32m        return {[m
[32m+[m[32m            "total_errors": len(self.errors),[m
[32m+[m[32m            "error_types": error_types,[m
[32m+[m[32m            "recent_errors": self.errors[-10:]  # Last 10 errors[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m# Global error tracker[m
[32m+[m[32merror_tracker = ErrorTracker()[m
[32m+[m
[32m+[m[32mdef safe_execute(func: Callable, *args, **kwargs) -> tuple[bool, Any]:[m
[32m+[m[32m    """[m
[32m+[m[32m    Safely execute a function and return success status and result[m
[32m+[m[41m    [m
[32m+[m[32m    Returns:[m
[32m+[m[32m        tuple: (success: bool, result: Any)[m
[32m+[m[32m    """[m
[32m+[m[32m    try:[m
[32m+[m[32m        result = func(*args, **kwargs)[m
[32m+[m[32m        return True, result[m
[32m+[m[32m    except Exception as e:[m
[32m+[m[32m        error_tracker.track_error(e, {[m
[32m+[m[32m            "function": func.__name__,[m
[32m+[m[32m            "args": str(args)[:100],  # Truncate long args[m
[32m+[m[32m            "kwargs": str(kwargs)[:100][m
[32m+[m[32m        })[m
[32m+[m[32m        return False, e[m
[32m+[m
[32m+[m[32mdef cleanup_temp_files(temp_dir: Union[str, Path] = None):[m
[32m+[m[32m    """Clean up temporary files"""[m
[32m+[m[32m    if temp_dir is None:[m
[32m+[m[32m        temp_dir = config.temp_dir[m
[32m+[m[32m    else:[m
[32m+[m[32m        temp_dir = Path(temp_dir)[m
[32m+[m[41m    [m
[32m+[m[32m    if not temp_dir.exists():[m
[32m+[m[32m        return[m
[32m+[m[41m    [m
[32m+[m[32m    try:[m
[32m+[m[32m        import shutil[m
[32m+[m[32m        for item in temp_dir.iterdir():[m
[32m+[m[32m            if item.is_file():[m
[32m+[m[32m                item.unlink()[m
[32m+[m[32m            elif item.is_dir():[m
[32m+[m[32m                shutil.rmtree(item)[m
[32m+[m[32m        logger.info(f"Cleaned up temporary files in {temp_dir}")[m
[32m+[m[32m    except Exception as e:[m
[32m+[m[32m        logger.error(f"Failed to cleanup temp files: {e}")[m
[32m+[m
[32m+[m[32m# Export main utilities[m
[32m+[m[32m__all__ = [[m
[32m+[m[32m    "OOTDError", "ModelLoadError", "ProcessingError", "ValidationError", "ResourceError",[m
[32m+[m[32m    "Logger", "logger", "error_handler", "performance_monitor", "validate_input",[m
[32m+[m[32m    "ErrorTracker", "error_tracker", "safe_execute", "cleanup_temp_files"[m
[32m+[m[32m][m
[1mdiff --git a/utils/validation.py b/utils/validation.py[m
[1mnew file mode 100644[m
[1mindex 0000000..9333209[m
[1m--- /dev/null[m
[1m+++ b/utils/validation.py[m
[36m@@ -0,0 +1,304 @@[m
[32m+[m[32m"""[m
[32m+[m[32mInput validation utilities for OOTDiffusion[m
[32m+[m[32m"""[m
[32m+[m[32mimport os[m
[32m+[m[32mfrom pathlib import Path[m
[32m+[m[32mfrom typing import Union, List, Optional, Tuple[m
[32m+[m[32mfrom PIL import Image[m
[32m+[m[32mimport magic[m
[32m+[m[32mimport logging[m
[32m+[m
[32m+[m[32mfrom config import config[m
[32m+[m[32mfrom utils.error_handling import ValidationError, logger[m
[32m+[m
[32m+[m[32mclass InputValidator:[m
[32m+[m[32m    """Comprehensive input validation for OOTDiffusion"""[m
[32m+[m[41m    [m
[32m+[m[32m    def __init__(self):[m
[32m+[m[32m        self.allowed_extensions = config.server.allowed_extensions[m
[32m+[m[32m        self.max_file_size = config.server.max_file_size[m
[32m+[m[32m        self.max_dimensions = (4096, 4096)  # Maximum image dimensions[m
[32m+[m[32m        self.min_dimensions = (64, 64)      # Minimum image dimensions[m
[32m+[m[41m    [m
[32m+[m[32m    def validate_image_file(self, file_path: Union[str, Path]) -> Tuple[bool, str]:[m
[32m+[m[32m        """[m
[32m+[m[32m        Validate image file[m
[32m+[m[41m        [m
[32m+[m[32m        Returns:[m
[32m+[m[32m            tuple: (is_valid: bool, error_message: str)[m
[32m+[m[32m        """[m
[32m+[m[32m        try:[m
[32m+[m[32m            file_path = Path(file_path)[m
[32m+[m[41m            [m
[32m+[m[32m            # Check if file exists[m
[32m+[m[32m            if not file_path.exists():[m
[32m+[m[32m                return False, f"File does not exist: {file_path}"[m
[32m+[m[41m            [m
[32m+[m[32m            # Check file size[m
[32m+[m[32m            file_size = file_path.stat().st_size[m
[32m+[m[32m            if file_size > self.max_file_size:[m
[32m+[m[32m                return False, f"File too large: {file_size} bytes (max: {self.max_file_size})"[m
[32m+[m[41m            [m
[32m+[m[32m            # Check file extension[m
[32m+[m[32m            if file_path.suffix.lower() not in self.allowed_extensions:[m
[32m+[m[32m                return False, f"Invalid file extension: {file_path.suffix} (allowed: {self.allowed_extensions})"[m
[32m+[m[41m            [m
[32m+[m[32m            # Check MIME type[m
[32m+[m[32m            mime_type = magic.from_file(str(file_path), mime=True)[m
[32m+[m[32m            if not mime_type.startswith('image/'):[m
[32m+[m[32m                return False, f"File is not an image: {mime_type}"[m
[32m+[m[41m            [m
[32m+[m[32m            # Try to open as image[m
[32m+[m[32m            try:[m
[32m+[m[32m                with Image.open(file_path) as img:[m
[32m+[m[32m                    # Check image dimensions[m
[32m+[m[32m                    width, height = img.size[m
[32m+[m[32m                    if width < self.min_dimensions[0] or height < self.min_dimensions[1]:[m
[32m+[m[32m                        return False, f"Image too small: {width}x{height} (min: {self.min_dimensions[0]}x{self.min_dimensions[1]})"[m
[32m+[m[41m                    [m
[32m+[m[32m                    if width > self.max_dimensions[0] or height > self.max_dimensions[1]:[m
[32m+[m[32m                        return False, f"Image too large: {width}x{height} (max: {self.max_dimensions[0]}x{self.max_dimensions[1]})"[m
[32m+[m[41m                    [m
[32m+[m[32m                    # Check if image can be loaded[m
[32m+[m[32m                    img.verify()[m
[32m+[m[41m                [m
[32m+[m[32m                return True, "Valid image file"[m
[32m+[m[41m                [m
[32m+[m[32m            except Exception as e:[m
[32m+[m[32m                return False, f"Invalid image file: {str(e)}"[m
[32m+[m[41m                [m
[32m+[m[32m        except Exception as e:[m
[32m+[m[32m            return False, f"Validation error: {str(e)}"[m
[32m+[m[41m    [m
[32m+[m[32m    def validate_model_path(self, model_path: Union[str, Path]) -> Tuple[bool, str]:[m
[32m+[m[32m        """Validate model image path"""[m
[32m+[m[32m        return self.validate_image_file(model_path)[m
[32m+[m[41m    [m
[32m+[m[32m    def validate_cloth_path(self, cloth_path: Union[str, Path]) -> Tuple[bool, str]:[m
[32m+[m[32m        """Validate cloth image path"""[m
[32m+[m[32m        return self.validate_image_file(cloth_path)[m
[32m+[m[41m    [m
[32m+[m[32m    def validate_model_type(self, model_type: str) -> Tuple[bool, str]:[m
[32m+[m[32m        """Validate model type"""[m
[32m+[m[32m        valid_types = ['hd', 'dc'][m
[32m+[m[32m        if model_type not in valid_types:[m
[32m+[m[32m            return False, f"Invalid model type: {model_type} (valid: {valid_types})"[m
[32m+[m[32m        return True, "Valid model type"[m
[32m+[m[41m    [m
[32m+[m[32m    def validate_category(self, category: Union[int, str], model_type: str = 'dc') -> Tuple[bool, str]:[m
[32m+[m[32m        """Validate garment category"""[m
[32m+[m[32m        if model_type == 'hd':[m
[32m+[m[32m            # HD model only supports upperbody (category 0)[m
[32m+[m[32m            if category != 0 and category != 'upperbody':[m
[32m+[m[32m                return False, "HD model only supports upperbody garments"[m
[32m+[m[32m            return True, "Valid category for HD model"[m
[32m+[m[41m        [m
[32m+[m[32m        elif model_type == 'dc':[m
[32m+[m[32m            # DC model supports 0=upperbody, 1=lowerbody, 2=dress[m
[32m+[m[32m            valid_categories = [0, 1, 2, 'upperbody', 'lowerbody', 'dress'][m
[32m+[m[32m            if category not in valid_categories:[m
[32m+[m[32m                return False, f"Invalid category: {category} (valid: {valid_categories})"[m
[32m+[m[32m            return True, "Valid category for DC model"[m
[32m+[m[41m        [m
[32m+[m[32m        return False, f"Unknown model type: {model_type}"[m
[32m+[m[41m    [m
[32m+[m[32m    def validate_samples(self, samples: int) -> Tuple[bool, str]:[m
[32m+[m[32m        """Validate number of samples"""[m
[32m+[m[32m        if not isinstance(samples, int):[m
[32m+[m[32m            return False, f"Samples must be an integer, got: {type(samples)}"[m
[32m+[m[41m        [m
[32m+[m[32m        if samples < 1:[m
[32m+[m[32m            return False, f"Samples must be at least 1, got: {samples}"[m
[32m+[m[41m        [m
[32m+[m[32m        if samples > config.processing.max_samples:[m
[32m+[m[32m            return False, f"Samples too high: {samples} (max: {config.processing.max_samples})"[m
[32m+[m[41m        [m
[32m+[m[32m        return True, "Valid samples count"[m
[32m+[m[41m    [m
[32m+[m[32m    def validate_steps(self, steps: int) -> Tuple[bool, str]:[m
[32m+[m[32m        """Validate number of inference steps"""[m
[32m+[m[32m        if not isinstance(steps, int):[m
[32m+[m[32m            return False, f"Steps must be an integer, got: {type(steps)}"[m
[32m+[m[41m        [m
[32m+[m[32m        if steps < 1:[m
[32m+[m[32m            return False, f"Steps must be at least 1, got: {steps}"[m
[32m+[m[41m        [m
[32m+[m[32m        if steps > config.processing.max_steps:[m
[32m+[m[32m            return False, f"Steps too high: {steps} (max: {config.processing.max_steps})"[m
[32m+[m[41m        [m
[32m+[m[32m        return True, "Valid steps count"[m
[32m+[m[41m    [m
[32m+[m[32m    def validate_scale(self, scale: float) -> Tuple[bool, str]:[m
[32m+[m[32m        """Validate guidance scale"""[m
[32m+[m[32m        if not isinstance(scale, (int, float)):[m
[32m+[m[32m            return False, f"Scale must be a number, got: {type(scale)}"[m
[32m+[m[41m        [m
[32m+[m[32m        if scale < config.processing.min_scale:[m
[32m+[m[32m            return False, f"Scale too low: {scale} (min: {config.processing.min_scale})"[m
[32m+[m[41m        [m
[32m+[m[32m        if scale > config.processing.max_scale:[m
[32m+[m[32m            return False, f"Scale too high: {scale} (max: {config.processing.max_scale})"[m
[32m+[m[41m        [m
[32m+[m[32m        return True, "Valid scale value"[m
[32m+[m[41m    [m
[32m+[m[32m    def validate_seed(self, seed: int) -> Tuple[bool, str]:[m
[32m+[m[32m        """Validate random seed"""[m
[32m+[m[32m        if not isinstance(seed, int):[m
[32m+[m[32m            return False, f"Seed must be an integer, got: {type(seed)}"[m
[32m+[m[41m        [m
[32m+[m[32m        if seed < -1:[m
[32m+[m[32m            return False, f"Seed must be -1 or positive, got: {seed}"[m
[32m+[m[41m        [m
[32m+[m[32m        if seed > 2147483647:  # Max 32-bit integer[m
[32m+[m[32m            return False, f"Seed too large: {seed} (max: 2147483647)"[m
[32m+[m[41m        [m
[32m+[m[32m        return True, "Valid seed value"[m
[32m+[m[41m    [m
[32m+[m[32m    def validate_request(self, request_data: dict) -> Tuple[bool, List[str]]:[m
[32m+[m[32m        """[m
[32m+[m[32m        Validate complete request data[m
[32m+[m[41m        [m
[32m+[m[32m        Returns:[m
[32m+[m[32m            tuple: (is_valid: bool, error_messages: List[str])[m
[32m+[m[32m        """[m
[32m+[m[32m        errors = [][m
[32m+[m[41m        [m
[32m+[m[32m        # Required fields[m
[32m+[m[32m        required_fields = ['model_path', 'cloth_path'][m
[32m+[m[32m        for field in required_fields:[m
[32m+[m[32m            if field not in request_data:[m
[32m+[m[32m                errors.append(f"Missing required field: {field}")[m
[32m+[m[41m        [m
[32m+[m[32m        if errors:[m
[32m+[m[32m            return False, errors[m
[32m+[m[41m        [m
[32m+[m[32m        # Validate model path[m
[32m+[m[32m        is_valid, error_msg = self.validate_model_path(request_data['model_path'])[m
[32m+[m[32m        if not is_valid:[m
[32m+[m[32m            errors.append(f"Model path: {error_msg}")[m
[32m+[m[41m        [m
[32m+[m[32m        # Validate cloth path[m
[32m+[m[32m        is_valid, error_msg = self.validate_cloth_path(request_data['cloth_path'])[m
[32m+[m[32m        if not is_valid:[m
[32m+[m[32m            errors.append(f"Cloth path: {error_msg}")[m
[32m+[m[41m        [m
[32m+[m[32m        # Validate model type[m
[32m+[m[32m        model_type = request_data.get('model_type', 'hd')[m
[32m+[m[32m        is_valid, error_msg = self.validate_model_type(model_type)[m
[32m+[m[32m        if not is_valid:[m
[32m+[m[32m            errors.append(f"Model type: {error_msg}")[m
[32m+[m[41m        [m
[32m+[m[32m        # Validate category[m
[32m+[m[32m        category = request_data.get('category', 0)[m
[32m+[m[32m        is_valid, error_msg = self.validate_category(category, model_type)[m
[32m+[m[32m        if not is_valid:[m
[32m+[m[32m            errors.append(f"Category: {error_msg}")[m
[32m+[m[41m        [m
[32m+[m[32m        # Validate optional parameters[m
[32m+[m[32m        if 'samples' in request_data:[m
[32m+[m[32m            is_valid, error_msg = self.validate_samples(request_data['samples'])[m
[32m+[m[32m            if not is_valid:[m
[32m+[m[32m                errors.append(f"Samples: {error_msg}")[m
[32m+[m[41m        [m
[32m+[m[32m        if 'steps' in request_data:[m
[32m+[m[32m            is_valid, error_msg = self.validate_steps(request_data['steps'])[m
[32m+[m[32m            if not is_valid:[m
[32m+[m[32m                errors.append(f"Steps: {error_msg}")[m
[32m+[m[41m        [m
[32m+[m[32m        if 'scale' in request_data:[m
[32m+[m[32m            is_valid, error_msg = self.validate_scale(request_data['scale'])[m
[32m+[m[32m            if not is_valid:[m
[32m+[m[32m                errors.append(f"Scale: {error_msg}")[m
[32m+[m[41m        [m
[32m+[m[32m        if 'seed' in request_data:[m
[32m+[m[32m            is_valid, error_msg = self.validate_seed(request_data['seed'])[m
[32m+[m[32m            if not is_valid:[m
[32m+[m[32m                errors.append(f"Seed: {error_msg}")[m
[32m+[m[41m        [m
[32m+[m[32m        return len(errors) == 0, errors[m
[32m+[m
[32m+[m[32mdef validate_and_convert_category(category: Union[int, str], model_type: str = 'dc') -> int:[m
[32m+[m[32m    """[m
[32m+[m[32m    Validate and convert category to integer[m
[32m+[m[41m    [m
[32m+[m[32m    Returns:[m
[32m+[m[32m        int: Category as integer (0=upperbody, 1=lowerbody, 2=dress)[m
[32m+[m[32m    """[m
[32m+[m[32m    validator = InputValidator()[m
[32m+[m[41m    [m
[32m+[m[32m    # Validate category[m
[32m+[m[32m    is_valid, error_msg = validator.validate_category(category, model_type)[m
[32m+[m[32m    if not is_valid:[m
[32m+[m[32m        raise ValidationError(f"Invalid category: {error_msg}", "category")[m
[32m+[m[41m    [m
[32m+[m[32m    # Convert to integer[m
[32m+[m[32m    if isinstance(category, str):[m
[32m+[m[32m        category_map = {[m
[32m+[m[32m            'upperbody': 0,[m
[32m+[m[32m            'lowerbody': 1,[m
[32m+[m[32m            'dress': 2[m
[32m+[m[32m        }[m
[32m+[m[32m        return category_map[category.lower()][m
[32m+[m[41m    [m
[32m+[m[32m    return int(category)[m
[32m+[m
[32m+[m[32mdef sanitize_filename(filename: str) -> str:[m
[32m+[m[32m    """[m
[32m+[m[32m    Sanitize filename for safe storage[m
[32m+[m[41m    [m
[32m+[m[32m    Args:[m
[32m+[m[32m        filename: Original filename[m
[32m+[m[41m        [m
[32m+[m[32m    Returns:[m
[32m+[m[32m        str: Sanitized filename[m
[32m+[m[32m    """[m
[32m+[m[32m    import re[m
[32m+[m[41m    [m
[32m+[m[32m    # Remove or replace dangerous characters[m
[32m+[m[32m    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)[m
[32m+[m[41m    [m
[32m+[m[32m    # Remove leading/trailing dots and spaces[m
[32m+[m[32m    filename = filename.strip('. ')[m
[32m+[m[41m    [m
[32m+[m[32m    # Limit length[m
[32m+[m[32m    if len(filename) > 255:[m
[32m+[m[32m        name, ext = os.path.splitext(filename)[m
[32m+[m[32m        filename = name[:255-len(ext)] + ext[m
[32m+[m[41m    [m
[32m+[m[32m    return filename[m
[32m+[m
[32m+[m[32mdef create_temp_file(original_filename: str, temp_dir: Optional[Path] = None) -> Path:[m
[32m+[m[32m    """[m
[32m+[m[32m    Create a temporary file with sanitized name[m
[32m+[m[41m    [m
[32m+[m[32m    Args:[m
[32m+[m[32m        original_filename: Original filename[m
[32m+[m[32m        temp_dir: Temporary directory (defaults to config temp dir)[m
[32m+[m[41m        [m
[32m+[m[32m    Returns:[m
[32m+[m[32m        Path: Path to temporary file[m
[32m+[m[32m    """[m
[32m+[m[32m    if temp_dir is None:[m
[32m+[m[32m        temp_dir = config.temp_dir[m
[32m+[m[41m    [m
[32m+[m[32m    # Sanitize filename[m
[32m+[m[32m    safe_filename = sanitize_filename(original_filename)[m
[32m+[m[41m    [m
[32m+[m[32m    # Create unique filename[m
[32m+[m[32m    import uuid[m
[32m+[m[32m    name, ext = os.path.splitext(safe_filename)[m
[32m+[m[32m    unique_filename = f"{name}_{uuid.uuid4().hex[:8]}{ext}"[m
[32m+[m[41m    [m
[32m+[m[32m    temp_file = temp_dir / "uploads" / unique_filename[m
[32m+[m[32m    temp_file.parent.mkdir(parents=True, exist_ok=True)[m
[32m+[m[41m    [m
[32m+[m[32m    return temp_file[m
[32m+[m
[32m+[m[32m# Global validator instance[m
[32m+[m[32mvalidator = InputValidator()[m
[32m+[m
[32m+[m[32m# Export main utilities[m
[32m+[m[32m__all__ = [[m
[32m+[m[32m    "InputValidator", "validator", "validate_and_convert_category",[m
[32m+[m[32m    "sanitize_filename", "create_temp_file"[m
[32m+[m[32m][m
